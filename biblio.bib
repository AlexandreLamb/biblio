
@inproceedings{gao_fatigue_2017,
	address = {Hangzhou},
	title = {Fatigue state detection from multi-feature of eyes},
	isbn = {978-1-5386-1107-4},
	url = {http://ieeexplore.ieee.org/document/8248285/},
	doi = {10.1109/ICSAI.2017.8248285},
	abstract = {In recent years, the problem of fatigue driving has attracted more and more attention. Methods of fatigue detection are no longer just by the way of questionnaires. This paper presents an algorithm of fatigue state detection from multi-feature of eyes, which can determine whether a driver is in a state of fatigue by analyzing the behavior of the driver's eyes. Firstly, image preprocessing, face detection based on AdaBoost and active shape model of human eye positioning will be done in sequence to improve the accuracy of identification. After that, according to the P80 standard, the eyes state of opening and closing is identified by the area of eyes, which can obtain the percentage of eye closure time, the average time of eye closure and the frequency of blinking as eye multi-feature parameters. Finally, the support vector machine of fatigue state detection model is built with these three types of eye multi-feature parameters, and then the driver's driving state can be determined. Experiment results show the efficiency of the proposed method.},
	language = {en},
	urldate = {2022-01-14},
	booktitle = {2017 4th {International} {Conference} on {Systems} and {Informatics} ({ICSAI})},
	publisher = {IEEE},
	author = {Gao, Yuan and Wang, Changyuan},
	month = nov,
	year = {2017},
	keywords = {Physical, SVM, AddaBoost, Landmarks, Machine Learning, Eye features},
	pages = {177--181},
	file = {Gao and Wang - 2017 - Fatigue state detection from multi-feature of eyes.pdf:/home/simeon/Zotero/storage/AEEZ95QS/Gao and Wang - 2017 - Fatigue state detection from multi-feature of eyes.pdf:application/pdf},
}

@article{wan_multi-feature_2019,
	title = {Multi-feature analysis fatigue driving based on {Conditional} {Local} {Neural} {Fields} algorithm detection method},
	volume = {1237},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1237/2/022157},
	doi = {10.1088/1742-6596/1237/2/022157},
	abstract = {In order to effectively strengthen the monitoring technology of fatigue driving and reduce the incidence of traffic accidents, this paper proposes a new method based on conditional local neural fields algorithm for comprehensive evaluation of fatigue driving state. At present, most of the fatigue driving detection algorithms are based on extracting a single characteristic index, which is strict in environmental requirements and not high in detection. In this paper, the HOG feature is combined with the CLNF algorithm to implement face detection and feature point localization. Then, the EPnP algorithm is used to estimate the head anomaly frequency based on the feature point information, and the blink frequency is calculated according to the EAR eye length aspect ratio concept according to the feature points around the eye. Finally the threshold set by the P80 fatigue detection standard in the PERCLOS method is integrated, and the distributed information fusion strategy is used for fatigue evaluation. Experimental results confirm the effectiveness of the method.},
	language = {en},
	number = {2},
	urldate = {2022-01-14},
	journal = {Journal of Physics: Conference Series},
	author = {Wan, Yan and Liu, Min and Fan, Jinghua and Zhao, Yingbin and Jiang, Jiangpeng and Yao, Li},
	month = jun,
	year = {2019},
	keywords = {Physical, Landmarks, Machine Learning, Eye features},
	pages = {022157},
	file = {Wan et al. - 2019 - Multi-feature analysis fatigue driving based on Co.pdf:/home/simeon/Zotero/storage/NAJZ942L/Wan et al. - 2019 - Multi-feature analysis fatigue driving based on Co.pdf:application/pdf},
}

@article{jia_fatigue_2021,
	title = {Fatigue {Driving} {Detection} {Based} on {Deep} {Learning} and {Multi}-{Index} {Fusion}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9590571/},
	doi = {10.1109/ACCESS.2021.3123388},
	abstract = {In order to reduce trafﬁc accidents caused by fatigue driving, a fatigue driving detection algorithm is proposed based on deep learning and facial multi-index fusion from the driver s facial features. Because the scene in the actual driving process is very complex and changeable, this algorithm ﬁrst improves the multi-task cascaded convolutional neural network (MTCNN) so that it can quickly and accurately locate the face and detect the facial key points. According to the facial key points, the driver’s eyes and mouth regions are determined. Second, these regions are input into the eyes and mouth state recognition network (E-MSR Net) for state recognition. The E-MSR Net is a depth separable convolution neural network that is improved and optimized based on MobilenetV2. Finally, the three facial features of eye closure rate (ECR), mouth opening rate (MOR), and head non-positive face rate (HNFR) are fused to judge the driver’s fatigue state. This algorithm can quickly and accurately make judgments in the face of complex and changeable scenes. At the same time, it can avoid the failure of the algorithm caused by the occlusion of the eyes or mouth due to wearing sunglasses or masks during driving. The accuracy of the proposed algorithm on the self-made data set achieved 97.5\%, which proved the feasibility of the algorithm.},
	language = {en},
	urldate = {2022-01-14},
	journal = {IEEE Access},
	author = {Jia, Huijie and Xiao, Zhongjun and Ji, Peng},
	year = {2021},
	keywords = {Physical, Eye features, Deep learning, cnn, mtcnn, Mouth Features},
	pages = {147054--147062},
	file = {Jia et al. - 2021 - Fatigue Driving Detection Based on Deep Learning a.pdf:/home/simeon/Zotero/storage/XCH8SDIB/Jia et al. - 2021 - Fatigue Driving Detection Based on Deep Learning a.pdf:application/pdf},
}

@inproceedings{hong_towards_2020,
	address = {Shenzhen, China},
	title = {Towards {Drowsiness} {Driving} {Detection} {Based} on {Multi}-{Feature} {Fusion} and {LSTM} {Networks}},
	isbn = {978-1-72817-709-0},
	url = {https://ieeexplore.ieee.org/document/9305393/},
	doi = {10.1109/ICARCV50220.2020.9305393},
	abstract = {Drowsiness driving poses a huge threat to the trafﬁc safety. In this paper, a novel drowsiness driving detection method based on multi-feature fusion and long short-term memory (LSTM) recurrent neural networks is proposed to reduce trafﬁc accidents caused by drowsiness driving. Firstly, we collect steering wheel angles (SWAs) of vehicles and facial videos of drivers by a driving simulator. Secondly, the drowsiness driving-related steering features and facial expression features are respectively extracted from the collected SWAs and facial videos by the One Way ANOVA method and the FEFENet network, and then they are fused by concatenation operation. Considering that the generation of drowsiness is a long-term dynamic process and the degree of drowsiness accumulates over time, we design LSTM networks to cope with the fused feature sequence in a ﬁxed duration, thereby establishing a effective drowsiness driving detection model. Some experiments are conducted to validate the performance of the proposed method, and the results demonstrate that our method can get robust and high accuracy performance in many challenging driving scenarios.},
	language = {en},
	urldate = {2022-01-14},
	booktitle = {2020 16th {International} {Conference} on {Control}, {Automation}, {Robotics} and {Vision} ({ICARCV})},
	publisher = {IEEE},
	author = {Hong, Lin and Wang, Xin},
	month = dec,
	year = {2020},
	keywords = {Physical, Eye features, Deep learning, cnn, features exctraction, lstm},
	pages = {732--736},
	file = {Hong and Wang - 2020 - Towards Drowsiness Driving Detection Based on Mult.pdf:/home/simeon/Zotero/storage/4YFY8X7Z/Hong and Wang - 2020 - Towards Drowsiness Driving Detection Based on Mult.pdf:application/pdf},
}

@article{du_intelligent_2021,
	title = {Intelligent {Fatigue} {Detection} {Method} in {Industrial} {System} {Based} on {Facial} {Multi}-feature {Fusion}},
	volume = {2005},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2005/1/012094},
	doi = {10.1088/1742-6596/2005/1/012094},
	abstract = {With the development of science and technology, the complexity of industrial production system has been significantly improved, and higher requirements have been put forward for human safety. Aiming at the contradiction between the intrusiveness and the accuracy of fatigue behavior detection in human factor safety, a multi-feature fusion intelligent fatigue state detection method was proposed. Firstly, the image recognition algorithm was used to accurately obtain the information of facial expression feature points. By analyzing the dynamic characteristics of all the feature points, the facial fatigue features were extracted. Secondly, an experimental scheme was designed to collect and process facial expression feature data, and a dynamic marker model of fatigue characteristics was constructed to form a fatigue index that directly reflected the fatigue degree of the working process. Finally, the neural network regression model was established to fit the characteristic data. Through the comparative analysis of different schemes and various evaluation indexes, the rationality of the fitting results of this method was proved. The experimental results show that this method can reasonably quantify the fatigue index of people under different conditions, and realize the intelligent detection of facial fatigue state.},
	language = {en},
	number = {1},
	urldate = {2022-01-14},
	journal = {Journal of Physics: Conference Series},
	author = {Du, Xinfei and Xie, Juntai and Chen, Kun and Gao, Jianmin and Liu, Yang},
	month = aug,
	year = {2021},
	keywords = {Landmarks, Eye features, Deep learning, Mouth Features, features exctraction, ann},
	pages = {012094},
	file = {Du et al. - 2021 - Intelligent Fatigue Detection Method in Industrial.pdf:/home/simeon/Zotero/storage/MH3W6A3F/Du et al. - 2021 - Intelligent Fatigue Detection Method in Industrial.pdf:application/pdf},
}

@inproceedings{jie_analysis_2018,
	address = {Xi'an},
	title = {Analysis of {Yawning} {Behaviour} in {Spontaneous} {Expressions} of {Drowsy} {Drivers}},
	isbn = {978-1-5386-2335-0},
	url = {https://ieeexplore.ieee.org/document/8373884/},
	doi = {10.1109/FG.2018.00091},
	abstract = {Driver fatigue is one of the main causes of road accidents. It is essential to develop a reliable driver drowsiness detection system which can alert drivers without disturbing them and is robust to environmental changes. This paper explores yawning behaviour as a sign of drowsiness in spontaneous expressions of drowsy drivers in simulated driving scenarios. We analyse a labelled dataset of videos of sleep-deprived versus alert drivers and demonstrate the correlation between handover-face touches, face occlusions and yawning. We propose that face touches can be used as a novel cue in automated drowsiness detection alongside yawning and eye behaviour. Moreover, we present an automatic approach to detect yawning based on extracting geometric and appearance features of both mouth and eye regions. Our approach successfully detects both hand-covered and uncovered yawns with an accuracy of 95\%. Ultimately, our goal is to use these results in designing a hybrid drowsiness-detection system.},
	language = {en},
	urldate = {2022-01-14},
	booktitle = {2018 13th {IEEE} {International} {Conference} on {Automatic} {Face} \& {Gesture} {Recognition} ({FG} 2018)},
	publisher = {IEEE},
	author = {Jie, Zhuoni and Mahmoud, Marwa and Stafford-Fraser, Quentin and Robinson, Peter and Dias, Eduardo and Skrypchuk, Lee},
	month = may,
	year = {2018},
	keywords = {Physical, Machine Learning, Mouth Features, features exctraction},
	pages = {571--576},
	file = {Jie et al. - 2018 - Analysis of Yawning Behaviour in Spontaneous Expre.pdf:/home/simeon/Zotero/storage/LGECEUKK/Jie et al. - 2018 - Analysis of Yawning Behaviour in Spontaneous Expre.pdf:application/pdf},
}

@article{zhao_intelligent_2020,
	title = {Intelligent {Recognition} of {Fatigue} and {Sleepiness} {Based} on {InceptionV3}-{LSTM} via {Multi}-{Feature} {Fusion}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9159583/},
	doi = {10.1109/ACCESS.2020.3014508},
	abstract = {Fatigue is a common state of mankind characterized by a reduction in the level of consciousness and alertness. Therefore, the recognition of fatigue and sleepiness has become indispensable in many alertness-dependent situations, such as when driving vehicles on public roads, performing demanding tasks in the workplace, or monitoring intensive care unit patients. This study proposes a method based on novel multi-feature fusion to detect fatigue and sleepiness by using traditional image processing and heart rate variability (HRV). The proposed method performs initial feature extraction using InceptionV3 (a convolutional neural network (CNN)), following which the second decision is made by a long short-term memory network (LSTM) using the features collected by InceptionV3 to process the sequence of video data for recognition. The LSTM provides coherent and precise sequence recognition that avoids static distortions. Then, the ﬁnal decision is made by the blood volume pulse vector (PBV) method after the features are fused. Because fatigue recognition is usually employed to monitor driver fatigue, we veriﬁed the feasibility of our method by testing its ability to successfully recognize driver fatigue. Following the experiments, we compared the different steps in the proposed method with those in existing methods. We selected four other methods to perform the comparison tests and used the same videos for training networks. In comparison with state-of-the-art methods, our method in its entirety achieved an average increase of 5\% in terms of both accuracy and stability.},
	language = {en},
	urldate = {2022-01-14},
	journal = {IEEE Access},
	author = {Zhao, Yifei and Xie, Kai and Zou, Zizhuang and He, Jian-Biao},
	year = {2020},
	keywords = {Physical, Eye features, Deep learning, cnn, features exctraction, lstm, rPPG, Physiological},
	pages = {144205--144217},
	file = {Zhao et al. - 2020 - Intelligent Recognition of Fatigue and Sleepiness .pdf:/home/simeon/Zotero/storage/33C7NHUG/Zhao et al. - 2020 - Intelligent Recognition of Fatigue and Sleepiness .pdf:application/pdf;Zhao et al. - 2020 - Intelligent Recognition of Fatigue and Sleepiness .pdf:/home/simeon/Zotero/storage/FZIHGW6E/Zhao et al. - 2020 - Intelligent Recognition of Fatigue and Sleepiness .pdf:application/pdf},
}

@article{gu_hierarchical_2018,
	title = {Hierarchical {CNN}‐based real‐time fatigue detection system by visual‐based technologies using {MSP} model},
	volume = {12},
	issn = {1751-9667, 1751-9667},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2018.5245},
	doi = {10.1049/iet-ipr.2018.5245},
	abstract = {Visual-based technologies are very useful and meaningful to driver's fatigue detection. In this study, the authors present a multi-task hierarchical CNN scheme for fatigue detection system and propose a convolutional neural network (CNN) model with multi-scale pooling (MSP-Net). ‘Multi-task’ includes three tasks: face detection, eye and mouth state detection and fatigue detection. First, they use a pre-trained network – multi-task CNN for face detection extracting eye and mouth regions. Then, the main work of this study, eye and mouth state detection is processed by MSP-Net, which can fit multi-resolution input images captured from variant cameras excellently. For the third step, the percentage of eyelid closure over the pupil over time (PERCLOS) parameters and the frequency of open mouth (FOM) parameters are used to detect fatigue, and the FOM parameters are proposed by ourselves. Besides, they successfully port the system to the embedded platform (the NVIDIA JETSON TX2 development board) and test on real driving scene. The results show that their system performs well and is robust to complex environments and is in line with the demand of real-time system.},
	language = {en},
	number = {12},
	urldate = {2022-01-17},
	journal = {IET Image Processing},
	author = {Gu, Wang Huan and Zhu, Yu and Chen, Xu Dong and He, Lin Fei and Zheng, Bing Bing},
	month = dec,
	year = {2018},
	keywords = {Physical, Deep learning, cnn, mtcnn, Mouth Features, features exctraction},
	pages = {2319--2329},
	file = {Gu et al. - 2018 - Hierarchical CNN‐based real‐time fatigue detection.pdf:/home/simeon/Zotero/storage/ACNQSU8V/Gu et al. - 2018 - Hierarchical CNN‐based real‐time fatigue detection.pdf:application/pdf},
}

@article{li_fatigue_2020,
	title = {A {Fatigue} {Driving} {Detection} {Algorithm} {Based} on {Facial} {Multi}-{Feature} {Fusion}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9104692/},
	doi = {10.1109/ACCESS.2020.2998363},
	abstract = {Researches on machine vision-based driver fatigue detection algorithm have improved trafﬁc safety signiﬁcantly. Generally, many algorithms do not analyze driving state from driver characteristics. It results in some inaccuracy. The paper proposes a fatigue driving detection algorithm based on facial multifeature fusion combining driver characteristics. First, we introduce an improved YOLOv3-tiny convolutional neural network to capture the facial regions under complex driving conditions, eliminating the inaccuracy and affections caused by artiﬁcial feature extraction. Second, on the basis of the Dlib toolkit, we introduce the Eye Feature Vector(EFV) and Mouth Feature Vector(MFV), which are the evaluation parameters of the driver’s eye state and mouth state, respectively. Then, the driver identity information library is constructed by ofﬂine training, including driver eye state classiﬁer library, driver mouth state classiﬁer library, and driver biometric library. Finally, we construct the driver identity veriﬁcation model and the driver fatigue assessment model by online assessment. After passing the identity veriﬁcation, calculate the driver’s closed eyes time, blink frequency and yawn frequency to evaluate the driver’s fatigue state. In simulated driving applications, our algorithm detects the fatigue state at a speed of over 20fps with an accuracy of 95.10\%.},
	language = {en},
	urldate = {2022-01-17},
	journal = {IEEE Access},
	author = {Li, Kening and Gong, Yunbo and Ren, Ziliang},
	year = {2020},
	keywords = {Physical, SVM, Landmarks, Deep learning, cnn, features exctraction, identity recognition},
	pages = {101244--101259},
	file = {Li et al. - 2020 - A Fatigue Driving Detection Algorithm Based on Fac.pdf:/home/simeon/Zotero/storage/4PXY96NR/Li et al. - 2020 - A Fatigue Driving Detection Algorithm Based on Fac.pdf:application/pdf},
}

@inproceedings{ma_real-time_2015,
	address = {Phoenix Park, PyeongChang, South Korea},
	title = {A real-time fatigue driving detection system design and implementation},
	isbn = {978-89-968650-5-6},
	url = {http://ieeexplore.ieee.org/document/7224842/},
	doi = {10.1109/ICACT.2015.7224842},
	abstract = {A reliable and real-time fatigue driving detection system is very important for traffic safety. Till now, various methods have been presented to improve the accuracy and robustness, however, few papers showed the efficiency of the system or the feasibility of real-time processing in embedded system. Considering the efficiency and reliability, a real-time fatigue driving detection system is presented in this paper. Firstly, Haar-like features and AdaBoosted classifiers are adopted for real-time face detection. The selection of the optimal sampling ratio and the minimum possible object size is discussed for high detection accuracy and computational efficiency. Secondly, eye location and iris positioning are applied to detected faces. We propose to use the area proportion that the iris takes in its minimum circumscribed circle as the indicator for judging the state of the eye, which is more convenient and has good robustness to distance. Finally, the percentage of eye closure (PERCLOS) is used as the criteria to determine whether the driver is tired. The embedded platform implementation of the proposed system turns out to be efficient.},
	language = {en},
	urldate = {2022-01-18},
	booktitle = {2015 17th {International} {Conference} on {Advanced} {Communication} {Technology} ({ICACT})},
	publisher = {IEEE},
	author = {Ma, Zhao-Bin and Yang, Yang and Zhou, Fengyu and Jian-Hua, Xu},
	month = jul,
	year = {2015},
	keywords = {Eye features, iris tracking},
	pages = {483--488},
	file = {Ma et al. - 2015 - A real-time fatigue driving detection system desig.pdf:/home/simeon/Zotero/storage/GUFADUGB/Ma et al. - 2015 - A real-time fatigue driving detection system desig.pdf:application/pdf},
}

@article{wang_eye_2019,
	title = {Eye gaze pattern analysis for fatigue detection based on {GP}-{BCNN} with {ESM}},
	volume = {123},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016786551830744X},
	doi = {10.1016/j.patrec.2019.03.013},
	language = {en},
	urldate = {2022-01-18},
	journal = {Pattern Recognition Letters},
	author = {Wang, Yan and Huang, Rui and Guo, Lei},
	month = may,
	year = {2019},
	keywords = {Physical, Eye features, cnn, features exctraction, multiple cnn, multi stream channel},
	pages = {61--74},
	file = {Wang et al. - 2019 - Eye gaze pattern analysis for fatigue detection ba.pdf:/home/simeon/Zotero/storage/2ATPCKCI/Wang et al. - 2019 - Eye gaze pattern analysis for fatigue detection ba.pdf:application/pdf},
}

@article{daza_mebal_2020,
	title = {{mEBAL}: {A} {Multimodal} {Database} for {Eye} {Blink} {Detection} and {Attention} {Level} {Estimation}},
	shorttitle = {{mEBAL}},
	url = {http://arxiv.org/abs/2006.05327},
	abstract = {This work presents mEBAL1, a multimodal database for eye blink detection and attention level estimation. The eye blink frequency is related to the cognitive activity and automatic detectors of eye blinks have been proposed for many tasks including attention level estimation, analysis of neuro-degenerative diseases, deception recognition, drive fatigue detection, or face anti-spoofing. However, most existing databases and algorithms in this area are limited to experiments involving only a few hundred samples and individual sensors like face cameras. The proposed mEBAL improves previous databases in terms of acquisition sensors and samples. In particular, three different sensors are simultaneously considered: Near Infrared (NIR) and RGB cameras to capture the face gestures and an Electroencephalography (EEG) band to capture the cognitive activity of the user and blinking events. Regarding the size of mEBAL, it comprises 6,000 samples and the corresponding attention level from 38 different students while conducting a number of e-learning tasks of varying difficulty. In addition to presenting mEBAL, we also include preliminary experiments on: i) eye blink detection using Convolutional Neural Networks (CNN) with the facial images, and ii) attention level estimation of the students based on their eye blink frequency.},
	language = {en},
	urldate = {2022-01-18},
	journal = {arXiv:2006.05327 [cs]},
	author = {Daza, Roberto and Morales, Aythami and Fierrez, Julian and Tolosana, Ruben},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.05327},
	keywords = {Eye features, eye blink detection, blink database},
	file = {Daza et al. - 2020 - mEBAL A Multimodal Database for Eye Blink Detecti.pdf:/home/simeon/Zotero/storage/V4PMXKSJ/Daza et al. - 2020 - mEBAL A Multimodal Database for Eye Blink Detecti.pdf:application/pdf},
}

@article{riquelme_hypo-driver_2022,
	title = {Hypo-{Driver}: {A} {Multiview} {Driver} {Fatigue} and {Distraction} {Level} {Detection} {System}},
	volume = {71},
	issn = {1546-2226},
	shorttitle = {Hypo-{Driver}},
	url = {https://www.techscience.com/cmc/v71n1/45469},
	doi = {10.32604/cmc.2022.022553},
	abstract = {Traffic accidents are caused by driver fatigue or distraction in many cases. To prevent accidents, several low-cost hypovigilance (hypo-V) systems were developed in the past based on a multimodal-hybrid (physiological and behavioral) feature set. Similarly in this paper, real-time driver inattention and fatigue (Hypo-Driver) detection system is proposed through multi-view cameras and biosignal sensors to extract hybrid features. The considered features are derived from non-intrusive sensors that are related to the changes in driving behavior and visual facial expressions. To get enhanced visual facial features in uncontrolled environment, three cameras are deployed on multiview points (0◦, 45◦, and 90◦) of the drivers. To develop a Hypo-Driver system, the physiological signals (electroencephalography (EEG), electrocardiography (ECG), electro-myography (sEMG), and electrooculography (EOG)) and behavioral information (PERCLOS70-80-90\%, mouth aspect ratio (MAR), eye aspect ratio (EAR), blinking frequency (BF), head-titled ratio (HT-R)) are collected and pre-processed, then followed by feature selection and fusion techniques. The driver behaviors are classified into five stages such as normal, fatigue, visual inattention, cognitive inattention, and drowsy. This improved hypo-Driver system utilized trained behavioral features by a convolutional neural network (CNNs), recurrent neural network and long short-term memory (RNN-LSTM) model is used to extract physiological features. After fusion of these features, the Hypo-Driver system is classified hypo-V into five stages based on trained layers and dropout-layer in the deep-residual neural network (DRNN) model. To test the performance of a hypo-Driver system, data from 20 drivers are acquired. The results of Hypo-Driver compared to state-of-theart methods are presented. Compared to the state-of-the-art Hypo-V system, on average, the Hypo-Driver system achieved a detection accuracy (AC) of 96.5\%. The obtained results indicate that the Hypo-Driver system based on multimodal and multiview features outperforms other state-of-the-art driver Hypo-V systems by handling many anomalies.},
	language = {en},
	number = {1},
	urldate = {2022-01-18},
	journal = {Computers, Materials \& Continua},
	author = {Riquelme, Fabi醤 and Olivares, Rodrigo and Mu駉z, Francisco and Molinero, Xavier and Serna, Maria},
	year = {2022},
	keywords = {Physical, cnn, lstm, Physiological},
	pages = {1999--2007},
	file = {Riquelme et al. - 2022 - Hypo-Driver A Multiview Driver Fatigue and Distra.pdf:/home/simeon/Zotero/storage/UBNLAC3N/Riquelme et al. - 2022 - Hypo-Driver A Multiview Driver Fatigue and Distra.pdf:application/pdf},
}

@inproceedings{tamba_improvement_2016,
	address = {Washington, DC, USA},
	title = {Improvement of {Blink} {Detection} {Using} a {Doppler} {Sensor} {Based} on {CFAR} {Processing}},
	isbn = {978-1-5090-1328-9},
	url = {http://ieeexplore.ieee.org/document/7841887/},
	doi = {10.1109/GLOCOM.2016.7841887},
	abstract = {A blink is one of physiological signals that indicates a consciousness level or a drowsiness. Using a Doppler sensor is one solution to realize non-contact blink detection without cameras. However, it is difﬁcult to detect blinks using a Doppler sensor because of low signal to noise power ratio (SNR) of reﬂected signal from an eyelid. We previously proposed the blink detection method based on machine learning and show that the method provides high probability of detection of blinks. However, it is necessary for the method to do a prior learning process for each person or environment. In this paper, we propose a high accuracy blink detection method without prior learning process. By applying constant false alarm rate (CFAR) processing to the blink signal detection, the method can be robust against the ﬂuctuation of a body or noise, and the probability of detection can be improved. Moreover, we apply two kinds of classiﬁcation based on the characteristic of the signal waveform of the blink. Thereby, a subtle body movement that is easy to be wrongly detected as a blink is excluded, and false positive in detection can be reduced. We conducted three experiments to evaluate the detection accuracy. As a result, we show that our proposal achieved high detection accuracy of around 99 \%.},
	language = {en},
	urldate = {2022-01-19},
	booktitle = {2016 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Tamba, Chihiro and Hayashi, Hirotaka and Ohtsuki, Tomoaki},
	month = dec,
	year = {2016},
	pages = {1--6},
	file = {Tamba et al. - 2016 - Improvement of Blink Detection Using a Doppler Sen.pdf:/home/simeon/Zotero/storage/TRWI747C/Tamba et al. - 2016 - Improvement of Blink Detection Using a Doppler Sen.pdf:application/pdf;Tamba et al. - 2016 - Improvement of Blink Detection Using a Doppler Sen.pdf:/home/simeon/Zotero/storage/XXYP4ZCZ/Tamba et al. - 2016 - Improvement of Blink Detection Using a Doppler Sen.pdf:application/pdf},
}

@inproceedings{ayachi_drivers_2021,
	address = {Monastir, Tunisia},
	title = {Drivers {Fatigue} {Detection} {Using} {EfficientDet} {In} {Advanced} {Driver} {Assistance} {Systems}},
	isbn = {978-1-66541-493-7},
	url = {https://ieeexplore.ieee.org/document/9429294/},
	doi = {10.1109/SSD52085.2021.9429294},
	urldate = {2022-01-20},
	booktitle = {2021 18th {International} {Multi}-{Conference} on {Systems}, {Signals} \& {Devices} ({SSD})},
	publisher = {IEEE},
	author = {Ayachi, Riadh and Afif, Mouna and Said, Yahia and Ben Abdelali, Abdessalem},
	month = mar,
	year = {2021},
	keywords = {Physical, Eye features, cnn, Mouth Features},
	pages = {738--742},
	file = {Ayachi et al. - 2021 - Drivers Fatigue Detection Using EfficientDet In Ad.pdf:/home/simeon/Zotero/storage/D5D45MZS/Ayachi et al. - 2021 - Drivers Fatigue Detection Using EfficientDet In Ad.pdf:application/pdf;Ayachi et al. - 2021 - Drivers Fatigue Detection Using EfficientDet In Ad.pdf:/home/simeon/Zotero/storage/S4FNMV4K/Ayachi et al. - 2021 - Drivers Fatigue Detection Using EfficientDet In Ad.pdf:application/pdf},
}

@article{liu_fusion_2017,
	title = {Fusion of color histogram and {LBP}-based features for texture image retrieval and classification},
	volume = {390},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025517301159},
	doi = {10.1016/j.ins.2017.01.025},
	language = {en},
	urldate = {2022-01-27},
	journal = {Information Sciences},
	author = {Liu, Peizhong and Guo, Jing-Ming and Chamnongthai, Kosin and Prasetyo, Heri},
	month = jun,
	year = {2017},
	pages = {95--111},
	file = {Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:/home/simeon/Zotero/storage/ZGDD5PAD/Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:application/pdf;Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:/home/simeon/Zotero/storage/55ZHBCCQ/Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:application/pdf;Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:/home/simeon/Zotero/storage/A7AB8IKW/Liu et al. - 2017 - Fusion of color histogram and LBP-based features f.pdf:application/pdf},
}

@inproceedings{sharan_multi-level_2021,
	address = {Hubli, India},
	title = {Multi-level {Drowsiness} {Detection} using {Multi}-{Contrast} {Convolutional} {Neural} {Networks} and {Single} {Shot} {Detector}},
	isbn = {978-1-72818-583-5},
	url = {https://ieeexplore.ieee.org/document/9498568/},
	doi = {10.1109/CONIT51480.2021.9498568},
	abstract = {The number of automobiles around the world is increasing day by day. With the number of increasing automobiles, there is also a surge in road accidents annually. The primary causes of most of these accidents are drivers' drowsiness and distraction. Even Today's Autonomous vehicles need drivers' attention to avoid accidents at times of emergency or system failure. So a real-time detection of drivers' drowsiness level plays a pivotal role in reducing road accidents. In this paper, we present two algorithms for performing real-time detection of drivers' drowsiness levels. The algorithms used are Multi-Contrast Convolution Neural Networks (MC-CNN) and Single Shot Multibox Detector (SSD). Our study can also be extrapolated into various other applications, such as real-time customer satisfaction detection through facial expressions in shopping malls.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2021 {International} {Conference} on {Intelligent} {Technologies} ({CONIT})},
	publisher = {IEEE},
	author = {Sharan, Sai and Reddy, Rahul and Reddy, Preetham},
	month = jun,
	year = {2021},
	pages = {1--6},
	file = {Sharan et al. - 2021 - Multi-level Drowsiness Detection using Multi-Contr.pdf:/home/simeon/Zotero/storage/9DUSDDEU/Sharan et al. - 2021 - Multi-level Drowsiness Detection using Multi-Contr.pdf:application/pdf},
}

@article{knapik_drivers_2019,
	title = {Driver’s fatigue recognition based on yawn detection in thermal images},
	volume = {338},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231219302280},
	doi = {10.1016/j.neucom.2019.02.014},
	language = {en},
	urldate = {2022-01-27},
	journal = {Neurocomputing},
	author = {Knapik, Mateusz and Cyganek, Bogusław},
	month = apr,
	year = {2019},
	pages = {274--292},
	file = {Knapik and Cyganek - 2019 - Driver’s fatigue recognition based on yawn detecti.pdf:/home/simeon/Zotero/storage/L52CAKAT/Knapik and Cyganek - 2019 - Driver’s fatigue recognition based on yawn detecti.pdf:application/pdf},
}

@inproceedings{murugan_driver_2020,
	address = {Coimbatore, India},
	title = {Driver {Hypovigilance} {Detection} for {Safe} {Driving} using {Infrared} {Camera}},
	isbn = {978-1-72814-685-0},
	url = {https://ieeexplore.ieee.org/document/9112568/},
	doi = {10.1109/ICICT48043.2020.9112568},
	abstract = {Driver safety can be made possible by continually monitoring the hypovigilance of the driver. Researchers have worked on analysing the driver drowsiness or inattention detection by using the camera mounted on the vehicle. This paper works on Infrared camera based monitoring of the hypovigilance (normal, fatigue, drowsy, visual and cognitive inattention) which is nothing but monitoring the state of the driver during different timings of the day. The simulator based environment was used to monitor and record the behaviour of the driver continuously for a period of two hours. The raw video is filtered and the features were extracted and classified using S upport Vector Machine (S VM), k-Nearest Neighbour (KNN) and Ensemble classifier algorithm. The average accuracy of fusion of hypovigilance state for Behavioural measure is 64.1\%.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2020 {International} {Conference} on {Inventive} {Computation} {Technologies} ({ICICT})},
	publisher = {IEEE},
	author = {Murugan, Suganiya and Selvaraj, Jerritta and Sahayadhas, Arun},
	month = feb,
	year = {2020},
	pages = {413--418},
	file = {Murugan et al. - 2020 - Driver Hypovigilance Detection for Safe Driving us.pdf:/home/simeon/Zotero/storage/XMR9KYW3/Murugan et al. - 2020 - Driver Hypovigilance Detection for Safe Driving us.pdf:application/pdf},
}

@article{liu_convolutional_2019,
	title = {Convolutional {Two}-{Stream} {Network} {Using} {Multi}-{Facial} {Feature} {Fusion} for {Driver} {Fatigue} {Detection}},
	volume = {11},
	issn = {1999-5903},
	url = {https://www.mdpi.com/1999-5903/11/5/115},
	doi = {10.3390/fi11050115},
	abstract = {Road traﬃc accidents caused by fatigue driving are common causes of human casualties. In this paper, we present a driver fatigue detection algorithm using two-stream network models with multi-facial features. The algorithm consists of four parts: (1) Positioning mouth and eye with multi-task cascaded convolutional neural networks (MTCNNs). (2) Extracting the static features from a partial facial image. (3) Extracting the dynamic features from a partial facial optical ﬂow. (4) Combining both static and dynamic features using a two-stream neural network to make the classiﬁcation. The main contribution of this paper is the combination of a two-stream network and multi-facial features for driver fatigue detection. Two-stream networks can combine static and dynamic image information, while partial facial images as network inputs can focus on fatigue-related information, which brings better performance. Moreover, we applied gamma correction to enhance image contrast, which can help our method achieve better results, noted by an increased accuracy of 2\% in night environments. Finally, an accuracy of 97.06\% was achieved on the National Tsing Hua University Driver Drowsiness Detection (NTHU-DDD) dataset.},
	language = {en},
	number = {5},
	urldate = {2022-01-27},
	journal = {Future Internet},
	author = {Liu, Weihuang and Qian, Jinhao and Yao, Zengwei and Jiao, Xintao and Pan, Jiahui},
	month = may,
	year = {2019},
	pages = {115},
	file = {Liu et al. - 2019 - Convolutional Two-Stream Network Using Multi-Facia.pdf:/home/simeon/Zotero/storage/YV9WA2M7/Liu et al. - 2019 - Convolutional Two-Stream Network Using Multi-Facia.pdf:application/pdf},
}

@article{bjorheim_review_2022,
	title = {A review of fatigue damage detection and measurement techniques},
	volume = {154},
	issn = {01421123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0142112321004096},
	doi = {10.1016/j.ijfatigue.2021.106556},
	abstract = {A vast amount of research has been carried out towards the goal of quantifying changes related to the fatigue damaging process in materials throughout the fatigue life. However, no recommended practice has been developed for the experimental measurement of fatigue damage before a macroscopic crack has been initiated. Therefore, this paper reviews the existing fatigue damage detection and measurement techniques on the basis of both momentum within the research field and their being considered non-destructive. The techniques are separated into two categories, namely, fatigue crack monitoring and fatigue damage monitoring. The parameters of these techniques, which quantify the physical and mechanical changes of the materials during the fatigue life, were critically reviewed in regard to the mechanism behind the change, limitations, shortcomings, etc. The acoustic emission, hardness, ultrasonic, magnetic and potential drop methods are applicable for in-situ mea­ surements while positron annihilation and X-ray diffraction are more suitable for laboratory assessments. Even though all the revived methods are applicable for metals, acoustic emissions, X-ray diffraction, ultrasonic, strainbased and thermometric methods are also suitable for composites. The reliability, advantages, weaknesses, case/ material dependency and applicability of each method are compared and tabulated for making a framework for choosing suitable technique for fatigue crack or damage detection of material or components.},
	language = {en},
	urldate = {2022-01-27},
	journal = {International Journal of Fatigue},
	author = {Bjørheim, Fredrik and Siriwardane, Sudath C. and Pavlou, Dimitrios},
	month = jan,
	year = {2022},
	pages = {106556},
	file = {Bjørheim et al. - 2022 - A review of fatigue damage detection and measureme.pdf:/home/simeon/Zotero/storage/7NEH52YH/Bjørheim et al. - 2022 - A review of fatigue damage detection and measureme.pdf:application/pdf},
}

@article{golz_feature_2007,
	title = {Feature {Fusion} for the {Detection} of {Microsleep} {Events}},
	volume = {49},
	issn = {0922-5773, 1573-109X},
	url = {http://link.springer.com/10.1007/s11265-007-0083-4},
	doi = {10.1007/s11265-007-0083-4},
	abstract = {A combination of linear and nonlinear methods for feature fusion is introduced and the performance of this methodology is illustrated on a real-world problem: the detection of sudden and non-anticipated lapses of attention in car drivers due to drowsiness. To achieve this, signals coming from heterogeneous sources are processed, namely the brain electric activity, variation in the pupil size, and eye and eyelid movements. For all the signals considered, the features are extracted both in the spectral domain and in state space. Linear features are obtained by the modiﬁed periodogram, whereas the nonlinear features are based on the recently introduced method of delay vector variance (DVV). The decision process based on such fused features is achieved by support vector machines (SVM) and learning vector quantization (LVQ) neural networks. For the latter also methods of metrics adaptation in the input space are applied. The parameters of all utilized algorithms are optimized empirically in order to gain maximal classiﬁcation accuracy. It is also shown that metrics adaptation by weighting the input features can improve the classiﬁcation accuracy, but only to a limited extent. Limited improvements are also obtained when fusing features of selected signals, but highest improvements are gained by fusion of features of all available signals. In this case test errors are reduced down to 9\% in the mean, which clearly illustrates the potential of our methodology to establish a reference standard of drowsiness and microsleep detection devices for future online driver monitoring.},
	language = {en},
	number = {2},
	urldate = {2022-01-27},
	journal = {The Journal of VLSI Signal Processing Systems for Signal, Image, and Video Technology},
	author = {Golz, Martin and Sommer, David and Chen, Mo and Trutschel, Udo and Mandic, Danilo},
	month = nov,
	year = {2007},
	pages = {329--342},
	file = {Golz et al. - 2007 - Feature Fusion for the Detection of Microsleep Eve.pdf:/home/simeon/Zotero/storage/ZQM3SZ3Z/Golz et al. - 2007 - Feature Fusion for the Detection of Microsleep Eve.pdf:application/pdf},
}

@article{alexandre_assurance_nodate,
	title = {{ASSURANCE} {MALADIE} {DE} {PARIS} 75948 {PARIS} {CEDEX} 19},
	language = {fr},
	author = {Alexandre, M Lambert},
	pages = {2},
	file = {Alexandre - ASSURANCE MALADIE DE PARIS 75948 PARIS CEDEX 19.pdf:/home/simeon/Zotero/storage/97JY77UI/Alexandre - ASSURANCE MALADIE DE PARIS 75948 PARIS CEDEX 19.pdf:application/pdf},
}

@inproceedings{liu_research_2020,
	address = {Chongqing, China},
	title = {Research on {Fatigue} {Parameter} {Detection} of {Free} {Spanning} {Based} on {Multi}-{Measure} {Fusion}},
	isbn = {978-1-72814-390-3},
	url = {https://ieeexplore.ieee.org/document/9085152/},
	doi = {10.1109/ITNEC48623.2020.9085152},
	abstract = {Submarine pipeline is the lifeline of offshore oil transportation. Affected by seabed earthquake, seabed depression, obstacle and other factors, submarine pipeline is easy to produce free spanning. Under the action of complex environmental load, the free spanning is prone to produce vortex induced vibration (VIV) characterized by fluid structure coupling. The alternating stress produced by vortex induced vibration, as a low cycle fatigue load, leads to pipeline fatigue, failure and even fracture. Fatigue parameter is an important index to judge whether the free spanning is threatened, and it is the data support of pipeline safety assessment. Frequency and displacement are the most important parameters to reveal the state of the pipeline, which it is very difficult to detect the fatigue parameters under the strong ocean background noise. Based on the study of the dynamic response characteristics and stochastic resonance (SR), this paper proposes a multi-measure fusion method for the detection of the free spanning fatigue parameters. To verify the effectiveness of the above methods, computer simulation experiment is carried out. The test results have verified the effectiveness of the proposed approach, especially in the region of low SNR circumstance.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2020 {IEEE} 4th {Information} {Technology}, {Networking}, {Electronic} and {Automation} {Control} {Conference} ({ITNEC})},
	publisher = {IEEE},
	author = {Liu, Xiaodong and Ding, Jun and Peng, Hualiang and Wu, Kui},
	month = jun,
	year = {2020},
	pages = {2151--2156},
	file = {Liu et al. - 2020 - Research on Fatigue Parameter Detection of Free Sp.pdf:/home/simeon/Zotero/storage/Z3T8R926/Liu et al. - 2020 - Research on Fatigue Parameter Detection of Free Sp.pdf:application/pdf},
}

@article{lee_meta-rppg_2020,
	title = {Meta-{rPPG}: {Remote} {Heart} {Rate} {Estimation} {Using} a {Transductive} {Meta}-{Learner}},
	shorttitle = {Meta-{rPPG}},
	url = {http://arxiv.org/abs/2007.06786},
	abstract = {Remote heart rate estimation is the measurement of heart rate without any physical contact with the subject and is accomplished using remote photoplethysmography (rPPG) in this work. rPPG signals are usually collected using a video camera with a limitation of being sensitive to multiple contributing factors, e.g. variation in skin tone, lighting condition and facial structure. End-to-end supervised learning approach performs well when training data is abundant, covering a distribution that doesn’t deviate too much from the distribution of testing data or during deployment. To cope with the unforeseeable distributional changes during deployment, we propose a transductive meta-learner that takes unlabeled samples during testing (deployment) for a self-supervised weight adjustment (also known as transductive inference), providing fast adaptation to the distributional changes. Using this approach, we achieve state-of-the-art performance on MAHNOB-HCI and UBFC-rPPG.},
	language = {en},
	urldate = {2022-01-27},
	journal = {arXiv:2007.06786 [cs, eess]},
	author = {Lee, Eugene and Chen, Evan and Lee, Chen-Yi},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.06786},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: 26 pages, 10 figures, accepted by European Conference on Computer Vision (ECCV) 2020},
	annote = {Comment: 26 pages, 10 figures, accepted by European Conference on Computer Vision (ECCV) 2020},
	file = {Lee et al. - 2020 - Meta-rPPG Remote Heart Rate Estimation Using a Tr.pdf:/home/simeon/Zotero/storage/ZEXEM8FP/Lee et al. - 2020 - Meta-rPPG Remote Heart Rate Estimation Using a Tr.pdf:application/pdf;Lee et al. - 2020 - Meta-rPPG Remote Heart Rate Estimation Using a Tr.pdf:/home/simeon/Zotero/storage/PF2B7TQQ/Lee et al. - 2020 - Meta-rPPG Remote Heart Rate Estimation Using a Tr.pdf:application/pdf},
}

@inproceedings{juhong_smart_2018,
	address = {Chiang Mai},
	title = {Smart eye-tracking system},
	isbn = {978-1-5386-2615-3},
	url = {https://ieeexplore.ieee.org/document/8369701/},
	doi = {10.1109/IWAIT.2018.8369701},
	abstract = {This project is a smart eye tracking system which is designed for people with disabilities and elderly people. The concept of this research is to apply eye movement to control appliances, wheelchair and communicate with caretaker. This system comprises four components, imaging processing module, wheelchair-controlled module, appliances-controlled module and SMS manager module. The image processing module consists of webcam and C++ customized image processing, the eye movement image is captured and transmitted to Raspberry Pi microcontroller for processing with OpenCV to derive the coordinate of eye ball. The coordinate of eye ball is utilized for cursor control on the Raspberry Pi screen to control the system. Besides the eye movement, the eye blink is applied in this system for entering a command as when you press Enter button on keyboard. The wheelchair-controlled module is a cradle with two servos that can be moved to two dimensions and also adaptable to other wheelchair joysticks. This system also remotely controls some appliances and communicate with caretaker via send message to smartphone.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2018 {International} {Workshop} on {Advanced} {Image} {Technology} ({IWAIT})},
	publisher = {IEEE},
	author = {Juhong, Aniwat and Treebupachatsakul, T. and Pintavirooj, C.},
	month = jan,
	year = {2018},
	pages = {1--4},
	file = {Juhong et al. - 2018 - Smart eye-tracking system.pdf:/home/simeon/Zotero/storage/799CZXUJ/Juhong et al. - 2018 - Smart eye-tracking system.pdf:application/pdf},
}

@inproceedings{manu_facial_2016,
	address = {Al-Ain, United Arab Emirates},
	title = {Facial features monitoring for real time drowsiness detection},
	isbn = {978-1-5090-5341-4 978-1-5090-5343-8},
	url = {http://ieeexplore.ieee.org/document/7880030/},
	doi = {10.1109/INNOVATIONS.2016.7880030},
	abstract = {This paper describes an efficient method for drowsiness detection by three well defined phases. These three phases are facial features detection using Viola Jones, the eye tracking and yawning detection. Once the face is detected, the system is made illumination invariant by segmenting the skin part alone and considering only the chromatic components to reject most of the non face image backgrounds based on skin color. The tracking of eyes and yawning detection are done by correlation coefficient template matching. The feature vectors from each of the above phases are concatenated and a binary linear support vector machine classifier is used to classify the consecutive frames into fatigue and nonfatigue states and sound an alarm for the former, if it is above the threshold time. Extensive real time experiments prove that the proposed method is highly efficient in finding the drowsiness and alerting the driver.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2016 12th {International} {Conference} on {Innovations} in {Information} {Technology} ({IIT})},
	publisher = {IEEE},
	author = {Manu, B. N.},
	month = nov,
	year = {2016},
	pages = {1--4},
	file = {Manu - 2016 - Facial features monitoring for real time drowsines.pdf:/home/simeon/Zotero/storage/3K7GRCAG/Manu - 2016 - Facial features monitoring for real time drowsines.pdf:application/pdf},
}

@article{krich_low-sidelobe_2014,
	title = {Low-{Sidelobe} {Antenna} {Beamforming} {Via} {Stochastic} {Optimization}},
	volume = {62},
	issn = {0018-926X, 1558-2221},
	url = {http://ieeexplore.ieee.org/document/6905775/},
	doi = {10.1109/TAP.2014.2359202},
	abstract = {We describe a novel iterative methodology for computing a set of low-sidelobe beamforming weights for an airborne, electronically-steered phased-array radar using an in-ﬂight stochastic optimization routine performed over a number of coherent processing intervals (CPIs). The proposed approach is notable in that it does not rely upon a good antenna calibration and only requires digitization of the radar’s sum beam. By observing the radar ground clutter, the algorithm iteratively adjusts the beamformer. Furthermore, it is computationally inexpensive and scales favorably to radars comprising very large numbers of antenna elements and requiring extremely low sidelobes.},
	language = {en},
	number = {12},
	urldate = {2022-01-27},
	journal = {IEEE Transactions on Antennas and Propagation},
	author = {Krich, Steven I. and Weiner, Ian},
	month = dec,
	year = {2014},
	pages = {6482--6486},
	file = {Krich and Weiner - 2014 - Low-Sidelobe Antenna Beamforming Via Stochastic Op.pdf:/home/simeon/Zotero/storage/C3JQ6CFI/Krich and Weiner - 2014 - Low-Sidelobe Antenna Beamforming Via Stochastic Op.pdf:application/pdf},
}

@inproceedings{beukman_multi-sensor_2016,
	address = {Poitiers, France},
	title = {A multi-sensor system for detection of driver fatigue},
	isbn = {978-1-5090-2870-2},
	url = {http://ieeexplore.ieee.org/document/7819282/},
	doi = {10.1109/INDIN.2016.7819282},
	abstract = {Many vehicle accidents are caused by driver fatigue. Systems to monitor driver fatigue can contribute to a decrease in fatalities. This paper describes the development of a multi-sensor system for driver fatigue detection. The system achieves this by monitoring eye closure and wheel steering movements, and is able to alert the driver of any detected anomalies. Various techniques are suggested for registering the location coordinates. If it is detected that the driver is falling asleep, the system alerts the driver through audible and visual cues and sends an SMS to a third party reporting the occurrence.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2016 {IEEE} 14th {International} {Conference} on {Industrial} {Informatics} ({INDIN})},
	publisher = {IEEE},
	author = {Beukman, A. R. and Hancke, G. P. and Silva, B. J.},
	month = jul,
	year = {2016},
	pages = {870--873},
	file = {Beukman et al. - 2016 - A multi-sensor system for detection of driver fati.pdf:/home/simeon/Zotero/storage/IIQRZJSK/Beukman et al. - 2016 - A multi-sensor system for detection of driver fati.pdf:application/pdf;Beukman et al. - 2016 - A multi-sensor system for detection of driver fati.pdf:/home/simeon/Zotero/storage/L26XP7CG/Beukman et al. - 2016 - A multi-sensor system for detection of driver fati.pdf:application/pdf},
}

@inproceedings{razzaq_hybrid_2017,
	address = {Lahore},
	title = {A hybrid approach for fatigue detection and quantification},
	isbn = {978-1-5386-2303-9},
	url = {http://ieeexplore.ieee.org/document/8289472/},
	doi = {10.1109/INMIC.2017.8289472},
	abstract = {Lane departure warning system, Adaptive cruise control, and Pedestrian detection are widely used in automobile systems. The developing technologies to understand and solve the problem of fatigue are quite challenging in real time automated systems. Building dependable system is difﬁcult as we have to build road-sense into such systems, which is quite trivial for human cognitive system but difﬁcult for an automated system. In this paper, we have proposed an unsupervised hybrid approach to quantify driver’s fatigue level. We have implemented the fatigue monitoring system using modiﬁed Viola Jones algorithm, Adaboost training method and template matching using correlation coefﬁcient. Unintentional lane departures are also due to driver’s fatigue. So we propose a non-invasive hybrid method referred to as FQS (Fatigue Quantifying System) that integrates fatigue detection system along with lane departure feature.This hybrid system aims to detect the correlation between lane departures and driver fatigue levels.Our solution combines both visual and road features to detect the drowsiness of driver to achieve more precision and reduce the false alarm rate. Preliminary results show that the proposed system has high accuracy of 80\% and can quantify the fatigue levels very effectively.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2017 {International} {Multi}-topic {Conference} ({INMIC})},
	publisher = {IEEE},
	author = {Razzaq, Sughra and Ahmad, Muhammad Nouman and Hamayun, Mian M. and ur Rahman, Anis and Fraz, Muhammad Moazam},
	month = nov,
	year = {2017},
	pages = {1--7},
	file = {Razzaq et al. - 2017 - A hybrid approach for fatigue detection and quanti.pdf:/home/simeon/Zotero/storage/HCZ77XWZ/Razzaq et al. - 2017 - A hybrid approach for fatigue detection and quanti.pdf:application/pdf},
}

@incollection{shi_driver_2017,
	address = {Cham},
	title = {Driver {Fatigue} {Detection} {Using} {Multitask} {Cascaded} {Convolutional} {Networks}},
	volume = {510},
	isbn = {978-3-319-68120-7 978-3-319-68121-4},
	url = {https://link.springer.com/10.1007/978-3-319-68121-4_15},
	abstract = {Driving fatigue is one of the main reasons of traffic accidents. In this paper, we apply the multitask cascaded convolutional networks to face detection and alignment in order to ensure the accuracy and real-time of the algorithm. Afterwards another convolution neural network (CNN) is used for eye state recognition. Finally, we calculate the percentage of eyelid closure (PERCLOS) to detect the fatigue. The experimental results show that the proposed method has high recognition accuracy of eye state and can detect the fatigue effectively in real- time.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {Intelligence {Science} {I}},
	publisher = {Springer International Publishing},
	author = {Liu, Xiaoshuang and Fang, Zhijun and Liu, Xiang and Zhang, Xiangxiang and Gu, Jianrong and Xu, Qi},
	editor = {Shi, Zhongzhi and Goertzel, Ben and Feng, Jiali},
	year = {2017},
	doi = {10.1007/978-3-319-68121-4_15},
	note = {Series Title: IFIP Advances in Information and Communication Technology},
	pages = {143--152},
	file = {Liu et al. - 2017 - Driver Fatigue Detection Using Multitask Cascaded .pdf:/home/simeon/Zotero/storage/DJ3L8C9H/Liu et al. - 2017 - Driver Fatigue Detection Using Multitask Cascaded .pdf:application/pdf},
}

@article{sun_driver_2020,
	title = {Driver {Fatigue} {Detection} {System} {Based} on {Colored} and {Infrared} {Eye} {Features} {Fusion}},
	volume = {63},
	issn = {1546-2226},
	url = {https://www.techscience.com/cmc/v63n3/38893},
	doi = {10.32604/cmc.2020.09763},
	abstract = {Real-time detection of driver fatigue status is of great significance for road traffic safety. In this paper, a proposed novel driver fatigue detection method is able to detect the driver’s fatigue status around the clock. The driver’s face images were captured by a camera with a colored lens and an infrared lens mounted above the dashboard. The landmarks of the driver’s face were labeled and the eye-area was segmented. By calculating the aspect ratios of the eyes, the duration of eye closure, frequency of blinks and PERCLOS of both colored and infrared, fatigue can be detected. Based on the change of light intensity detected by a photosensitive device, the weight matrix of the colored features and the infrared features was adjusted adaptively to reduce the impact of lighting on fatigue detection. Video samples of the driver’s face were recorded in the test vehicle. After training the classification model, the results showed that our method has high accuracy on driver fatigue detection in both daytime and nighttime.},
	language = {en},
	number = {3},
	urldate = {2022-01-27},
	journal = {Computers, Materials \& Continua},
	author = {Sun, Yuyang and Yan, Peizhou and Li, Zhengzheng and Zou, Jiancheng and Hong, Don},
	year = {2020},
	pages = {1563--1574},
	file = {Sun et al. - 2020 - Driver Fatigue Detection System Based on Colored a.pdf:/home/simeon/Zotero/storage/FA9ZTLZ4/Sun et al. - 2020 - Driver Fatigue Detection System Based on Colored a.pdf:application/pdf;Sun et al. - 2020 - Driver Fatigue Detection System Based on Colored a.pdf:/home/simeon/Zotero/storage/7QA6TKGW/Sun et al. - 2020 - Driver Fatigue Detection System Based on Colored a.pdf:application/pdf},
}

@inproceedings{yuan_fatigue_2018,
	address = {Xi'an, China},
	title = {Fatigue {State} {Detection} {From} {Multi}-features},
	isbn = {978-94-6252-498-9},
	url = {http://www.atlantis-press.com/php/paper-details.php?id=25894554},
	doi = {10.2991/icsnce-18.2018.47},
	abstract = {With the quickening pace of modern life and the increasing of work pressure, accidents caused by fatigue problems occur more and more frequently. Developing a highperformance fatigue monitoring technology can not only improve the driver's work efficiency, but also solve the security risks caused by fatigue driving. This paper presents an algorithm of fatigue state detection from multi-features, which can determine whether a driver is in a state of fatigue. The thesis focuses on a non-contact, real-time fatigue detection method based on video, and proposes an algorithm with multiple fatigue characteristics. Firstly, it collects the video through the camera and carries out simple preprocessing. Then, the face area is quickly located by AdaBoost and the face shape model is constructed by ASM, which is used for locating the eye and mouth precisely, and extracting the relevant parameters. Based on the above indicators, it establishes the mapping relation between the characteristic space and fatigue space to judge the status with the SVM. Experiment results show the efficiency of the proposed method.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {Proceedings of the 2018 {Second} {International} {Conference} of {Sensor} {Network} and {Computer} {Engineering} ({ICSNCE} 2018)},
	publisher = {Atlantis Press},
	author = {Yuan, Gao and Changyuan, Wang},
	year = {2018},
	file = {Yuan and Changyuan - 2018 - Fatigue State Detection From Multi-features.pdf:/home/simeon/Zotero/storage/UJEUEWG5/Yuan and Changyuan - 2018 - Fatigue State Detection From Multi-features.pdf:application/pdf},
}

@article{liu_driver_2020,
	title = {Driver fatigue detection based on deeply-learned facial expression representation},
	volume = {71},
	issn = {10473203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S104732031930344X},
	doi = {10.1016/j.jvcir.2019.102723},
	abstract = {Driver fatigue detection is a significant application in smart cars. In order to improve the accuracy and timeliness of driver fatigue detection, a fatigue detection algorithm based on deeply-learned facial expression analysis is proposed. Specifically, the face key point detection model is first trained by multi block local binary patterns (MB-LBP) and Adaboost classifier. Subsequently, the eyes and mouth state are detected by using the trained model to detect the 24 facial features. Afterwards, we calculate the number of two parameters that can describe the driver's fatigue state and the proportion of the closed eye time within the unit time (PERCLOS) and yawning frequency. Finally, the fuzzy inference system is utilized to deduce the driver's fatigue state (normal, slight fatigue, severe fatigue). Experimental results show that the proposed algorithm can detect driver fatigue degree quickly and accurately.},
	language = {en},
	urldate = {2022-01-27},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Liu, Zhongmin and Peng, Yuxi and Hu, Wenjin},
	month = aug,
	year = {2020},
	pages = {102723},
	file = {Liu et al. - 2020 - Driver fatigue detection based on deeply-learned f.pdf:/home/simeon/Zotero/storage/EEP77UAJ/Liu et al. - 2020 - Driver fatigue detection based on deeply-learned f.pdf:application/pdf},
}

@article{anber_hybrid_2022,
	title = {A {Hybrid} {Driver} {Fatigue} and {Distraction} {Detection} {Model} {Using} {AlexNet} {Based} on {Facial} {Features}},
	volume = {11},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/11/2/285},
	doi = {10.3390/electronics11020285},
	abstract = {Modern cities have imposed a fast-paced lifestyle where more drivers on the road suffer from fatigue and sleep deprivation. Consequently, road accidents have increased, becoming one of the leading causes of injuries and death among young adults and children. These accidents can be prevented if fatigue symptoms are diagnosed and detected sufﬁciently early. For this reason, we propose and compare two AlexNet CNN-based models to detect drivers’ fatigue behaviors, relying on head position and mouth movements as behavioral measures. We used two different approaches. The ﬁrst approach is transfer learning, speciﬁcally, ﬁne-tuning AlexNet, which allowed us to take advantage of what the model had already learned without developing it from scratch. The newly trained model was able to predict drivers’ drowsiness behaviors. The second approach is the use of AlexNet to extract features by training the top layers of the network. These features were reduced using non-negative matrix factorization (NMF) and classiﬁed with a support vector machine (SVM) classiﬁer. The experiments showed that our proposed transfer learning model achieved an accuracy of 95.7\%, while the feature extraction SVM-based model performed better, with an accuracy of 99.65\%. Both models were trained on a simulated NTHU Driver Drowsiness Detection dataset.},
	language = {en},
	number = {2},
	urldate = {2022-01-27},
	journal = {Electronics},
	author = {Anber, Salma and Alsaggaf, Wafaa and Shalash, Wafaa},
	month = jan,
	year = {2022},
	pages = {285},
	file = {Anber et al. - 2022 - A Hybrid Driver Fatigue and Distraction Detection .pdf:/home/simeon/Zotero/storage/LEH587AB/Anber et al. - 2022 - A Hybrid Driver Fatigue and Distraction Detection .pdf:application/pdf},
}

@inproceedings{streiffer_darnet_2017,
	address = {Las Vegas, Nevada},
	title = {Darnet: a deep learning solution for distracted driving detection},
	isbn = {978-1-4503-5200-0},
	shorttitle = {Darnet},
	url = {http://dl.acm.org/citation.cfm?doid=3154448.3154452},
	doi = {10.1145/3154448.3154452},
	abstract = {Distracted driving is known to be the leading cause of motor vehicle accidents. With the increase in the number of IoT devices available within vehicles, there exists an abundance of data for monitoring driver behavior. However, designing a system around this goal presents two key challenges - how to concurrently collect data spanning multiple IoT devices, and how to jointly analyze this multimodal input. To that end, we present a unified data collection and analysis framework, DarNet, capable of detecting and classifying distracted driving behavior. DarNet consists of two primary components: a data collection system and an analytics engine. Our system takes advantage of advances in machine learning (ML) to classify driving behavior based on input sensor data. In our system implementation, we collect image data from an inward facing camera, and Inertial Measurement Unit (IMU) data from a mobile device, both located within the vehicle. Using deep learning techniques, we show that DarNet achieves a Top-1 classification percentage of 87.02\% on our collected dataset, significantly outperforming our baseline model of 73.88\%. Additionally, we address the privacy concerns associated with collecting image data by presenting an alternative framework designed to operate on down-sampled data which produces a Top-1 classification percentage of 80.00\%.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {Proceedings of the 18th {ACM}/{IFIP}/{USENIX} {Middleware} {Conference} on {Industrial} {Track} - {Middleware} '17},
	publisher = {ACM Press},
	author = {Streiffer, Christopher and Raghavendra, Ramya and Benson, Theophilus and Srivatsa, Mudhakar},
	year = {2017},
	pages = {22--28},
	file = {Streiffer et al. - 2017 - Darnet a deep learning solution for distracted dr.pdf:/home/simeon/Zotero/storage/FVAP5L5C/Streiffer et al. - 2017 - Darnet a deep learning solution for distracted dr.pdf:application/pdf},
}

@article{omerustaoglu_distracted_2020,
	title = {Distracted driver detection by combining in-vehicle and image data using deep learning},
	volume = {96},
	issn = {15684946},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494620305950},
	doi = {10.1016/j.asoc.2020.106657},
	abstract = {Distracted driving is among the most important reasons for traffic accidents today. Recently, there is an increasing interest in building driver assistance systems that detect the actions of the drivers and help them drive safer. In these studies, although some distinct data types such as the physical conditions of the driver, audio and visual features, car information are used; the main data source is the images of the driver that include the face, arms, and hands taken with a camera placed inside the car. In this work, we propose to integrate sensor data into the vision-based distracted driver detection model to improve the generalization ability of the system. With this purpose, we created a new data set that includes driver images and sensor data collected from real-world drives. Then, we constructed a two-stage distracted driving detection system to detect nine distracted behaviors. In the first stage, vision-based Convolutional Neural Network (CNN) models were created by transfer learning and finetuning methods. In the second stage, Long-Short Term Memory-Recurrent Neural Network (LSTM-RNN) models were created using sensor and image data together. We evaluate our system by two different fusion techniques and show that integrating sensor data to image-based driver detection significantly increases the overall performance with both of the fusion techniques. We also show that the accuracy of the vision-based model increases by fine-tuning the pre-trained CNN model using a related public dataset.},
	language = {en},
	urldate = {2022-01-27},
	journal = {Applied Soft Computing},
	author = {Omerustaoglu, Furkan and Sakar, C. Okan and Kar, Gorkem},
	month = nov,
	year = {2020},
	pages = {106657},
	file = {Omerustaoglu et al. - 2020 - Distracted driver detection by combining in-vehicl.pdf:/home/simeon/Zotero/storage/DQ478BAA/Omerustaoglu et al. - 2020 - Distracted driver detection by combining in-vehicl.pdf:application/pdf},
}

@article{ahmad_human_2019,
	title = {Human {Action} {Recognition} {Using} {Deep} {Multilevel} {Multimodal} ({M2}) {Fusion} of {Depth} and {Inertial} {Sensors}},
	url = {http://arxiv.org/abs/1910.11482},
	abstract = {Multimodal fusion frameworks for Human Action Recognition (HAR) using depth and inertial sensor data have been proposed over the years. In most of the existing works, fusion is performed at a single level (feature level or decision level), missing the opportunity to fuse rich mid-level features necessary for better classiﬁcation. To address this shortcoming, in this paper, we propose three novel deep multilevel multimodal (M 2) fusion frameworks to capitalize on different fusion strategies at various stages and to leverage the superiority of multilevel fusion. At input, we transform the depth data into depth images called sequential front view images (SFIs) and inertial sensor data into signal images. Each input modality, depth and inertial, is further made multimodal by taking convolution with the Prewitt ﬁlter. Creating “modality within modality” enables further complementary and discriminative feature extraction through Convolutional Neural Networks (CNNs). CNNs are trained on input images of each modality to learn low-level, high-level and complex features. Learned features are extracted and fused at different stages of the proposed frameworks to combine discriminative and complementary information. These highly informative features are served as input to a multi-class Support Vector Machine (SVM). We evaluate the proposed frameworks on three publicly available multimodal HAR datasets, namely, UTD Multimodal Human Action Dataset (MHAD), Berkeley MHAD, and UTDMHAD Kinect V2. Experimental results show the supremacy of the proposed fusion frameworks over existing methods.},
	language = {en},
	urldate = {2022-01-27},
	journal = {arXiv:1910.11482 [cs, stat]},
	author = {Ahmad, Zeeshan and Khan, Naimul},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.11482},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages, 13 figures},
	file = {Ahmad and Khan - 2019 - Human Action Recognition Using Deep Multilevel Mul.pdf:/home/simeon/Zotero/storage/B3PW466E/Ahmad and Khan - 2019 - Human Action Recognition Using Deep Multilevel Mul.pdf:application/pdf},
}

@inproceedings{ma_depth_2017,
	address = {Singapore, Singapore},
	title = {Depth video-based two-stream convolutional neural networks for driver fatigue detection},
	isbn = {978-1-5386-3276-5},
	url = {http://ieeexplore.ieee.org/document/8336111/},
	doi = {10.1109/ICOT.2017.8336111},
	abstract = {Recently, much research efforts have been dedicated to the development of computer-vision-based driver fatigue detection systems. Most of them utilize the RGB data, and focus on driver status detection during the day. However, drivers are more likely to be tired and drowsy during night time. In this paper, we present a driver fatigue detection system based on CNN using depth video sequences, which helps to provide alerts properly to fatigue drivers during the night time. Specifically, the two-stream CNN architecture incorporates spatial information of current depth frame and temporal information of neighboring depth frames which is represented by motion vectors. Besides, we propose a background removal system for depth video sequence of driving. Our method is trained and evaluated on our driver behavior dataset. Experiments show that the accuracy of the proposed method achieves 91.57\%, which outperforms the baseline system within the recent state-of-theart.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2017 {International} {Conference} on {Orange} {Technologies} ({ICOT})},
	publisher = {IEEE},
	author = {Ma, Xiaoxi and Chau, Lap-Pui and Yap, Kim-Hui},
	month = dec,
	year = {2017},
	pages = {155--158},
	file = {Ma et al. - 2017 - Depth video-based two-stream convolutional neural .pdf:/home/simeon/Zotero/storage/J2HMN4UW/Ma et al. - 2017 - Depth video-based two-stream convolutional neural .pdf:application/pdf},
}

@inproceedings{weiwei_zhang_driver_2015,
	address = {Killarney, Ireland},
	title = {Driver yawning detection based on deep convolutional neural learning and robust nose tracking},
	isbn = {978-1-4799-1960-4},
	url = {http://ieeexplore.ieee.org/document/7280566/},
	doi = {10.1109/IJCNN.2015.7280566},
	abstract = {Driver yawning detection is one of the key technologies used in driver fatigue monitoring systems. Real-time driver yawning detection is a very challenging problem due to the dynamics in driver's movements and lighting conditions. In this paper, we present a yawning detection system that consists of a face detector, a nose detector, a nose tracker and a yawning detector. Deep learning algorithms are developed for detecting driver face area and nose location. A nose tracking algorithm that combines Kalman filter with a dedicated open-source T LD (Track-Learning-Detection) tracker is developed to generate robust tracking results under dynamic driving conditions. Finally a neural network is developed for yawning detection based on the features including nose tracking confidence value, gradient features around corners of mouth and face motion features. Experiments are conducted on real-world driving data, and results show that the deep convolutional networks can generate a satisfactory classification result for detecting driver's face and nose when compared with other pattern classification methods, and the proposed yawning detection system is effective in real-time detection of driver's yawning states.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2015 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {{Weiwei Zhang} and Murphey, Yi L. and {Tianyu Wang} and {Qijie Xu}},
	month = jul,
	year = {2015},
	pages = {1--8},
	file = {Weiwei Zhang et al. - 2015 - Driver yawning detection based on deep convolution.pdf:/home/simeon/Zotero/storage/B3Y57ZJV/Weiwei Zhang et al. - 2015 - Driver yawning detection based on deep convolution.pdf:application/pdf},
}

@article{donahue_long-term_2017,
	title = {Long-{Term} {Recurrent} {Convolutional} {Networks} for {Visual} {Recognition} and {Description}},
	volume = {39},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/7558228/},
	doi = {10.1109/TPAMI.2016.2599174},
	abstract = {Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent are effective for tasks involving sequences, visual and otherwise. We describe a class of recurrent convolutional architectures which is end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of these models for activity recognition, image captioning, and video description. In contrast to previous models which assume a ﬁxed visual representation or perform simple temporal averaging for sequential processing, recurrent convolutional models are “doubly deep” in that they learn compositional representations in space and time. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Differentiable recurrent models are appealing in that they can directly map variable-length inputs (e.g., videos) to variable-length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent sequence models are directly connected to modern visual convolutional network models and can be jointly trained to learn temporal dynamics and convolutional perceptual representations. Our results show that such models have distinct advantages over state-of-the-art models for recognition or generation which are separately deﬁned or optimized.},
	language = {en},
	number = {4},
	urldate = {2022-01-27},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Donahue, Jeff and Hendricks, Lisa Anne and Rohrbach, Marcus and Venugopalan, Subhashini and Guadarrama, Sergio and Saenko, Kate and Darrell, Trevor},
	month = apr,
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {677--691},
	annote = {Comment: Originally presented at CVPR 2015 (oral). Updated version (accepted as a TPAMI journal article) includes additional results},
	file = {Donahue et al. - 2017 - Long-Term Recurrent Convolutional Networks for Vis.pdf:/home/simeon/Zotero/storage/PJIJ4X5C/Donahue et al. - 2017 - Long-Term Recurrent Convolutional Networks for Vis.pdf:application/pdf;Donahue et al. - 2016 - Long-term Recurrent Convolutional Networks for Vis.pdf:/home/simeon/Zotero/storage/V6BC46EL/Donahue et al. - 2016 - Long-term Recurrent Convolutional Networks for Vis.pdf:application/pdf},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient GPU implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	language = {en},
	number = {6},
	urldate = {2022-01-27},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = may,
	year = {2017},
	pages = {84--90},
	file = {Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:/home/simeon/Zotero/storage/54HCUIBH/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:application/pdf;Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:/home/simeon/Zotero/storage/GC7F8A9T/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:application/pdf;Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:/home/simeon/Zotero/storage/GZC4XY4Y/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:application/pdf},
}

@article{wu_eye_nodate,
	title = {An {Eye} {State} {Recognition} {Method} for {Drowsiness} {Detection}},
	abstract = {The issue of public driving safety has become more and more important. During long-distance driving, the driver’s consciousness will decline and the probability of traffic accident will increase. In order to avoid this situation, finding some approaches to realize whether the driver is drowsy or not is very critical. Because the eye state is the key point in driver drowsiness detection, we propose a method to recognize the eye state. At first we use the Haar-like features and Adaboost classifiers to find the face location. Then we use the SVM classifier to find the eyes locations. In third step we calculate the LBP features for the image of the left eye. Finally we put the features into SVM classifier to recognize the eye state. The experimental results show that the proposed method is effective for eye state recognition and is therefore helpful for driver drowsiness detection.},
	language = {en},
	author = {Wu, Yu-Shan and Lee, Ting-Wei and Wu, Quen-Zong and Liu, Heng-Sung},
	pages = {5},
	file = {Wu et al. - An Eye State Recognition Method for Drowsiness Det.pdf:/home/simeon/Zotero/storage/ZP94IPA9/Wu et al. - An Eye State Recognition Method for Drowsiness Det.pdf:application/pdf},
}

@article{alotaibi_deep_2017,
	title = {Deep face liveness detection based on nonlinear diffusion using convolution neural network},
	volume = {11},
	issn = {1863-1703, 1863-1711},
	url = {http://link.springer.com/10.1007/s11760-016-1014-2},
	doi = {10.1007/s11760-016-1014-2},
	abstract = {A face-spooﬁng attack occurs when an imposter manipulates a face recognition and veriﬁcation system to gain access as a legitimate user by presenting a 2D printed image or recorded video to the face sensor. This paper presents an efﬁcient and non-intrusive method to counter face-spooﬁng attacks that uses a single image to detect spooﬁng attacks. We apply a nonlinear diffusion based on an additive operator splitting scheme. Additionally, we propose a specialized deep convolution neural network that can extract the discriminative and high-level features of the input diffused image to differentiate between a fake face and a real face. Our proposed method is both efﬁcient and convenient compared with the previously implemented state-of-the-art methods described in the literature review. We achieved the highest reported accuracy of 99\% on the widely used NUAA dataset. In addition, we tested our method on the Replay Attack dataset which consists of 1200 short videos of both real access and spooﬁng attacks. An extensive experimental analysis was conducted that demonstrated better results when compared to previous static algorithms results. However, this result can be improved by applying a sparse autoencoder learning algorithm to obtain a more distinguishable diffused image.},
	language = {en},
	number = {4},
	urldate = {2022-01-27},
	journal = {Signal, Image and Video Processing},
	author = {Alotaibi, Aziz and Mahmood, Ausif},
	month = may,
	year = {2017},
	pages = {713--720},
	file = {Alotaibi and Mahmood - 2017 - Deep face liveness detection based on nonlinear di.pdf:/home/simeon/Zotero/storage/WGYAVYKA/Alotaibi and Mahmood - 2017 - Deep face liveness detection based on nonlinear di.pdf:application/pdf;Alotaibi and Mahmood - 2017 - Deep face liveness detection based on nonlinear di.pdf:/home/simeon/Zotero/storage/755BAH8E/Alotaibi and Mahmood - 2017 - Deep face liveness detection based on nonlinear di.pdf:application/pdf},
}

@article{yan_review_nodate,
	title = {A {Review} on {Fatigue} {Driving} {Detection}},
	abstract = {Fatigue driving is one of the main causes of traffic accidents. If the driver’s fatigue driving state can be detected in time and reminded in time, it is of great significance for driving safety and reducing traffic accidents. This article mainly reviews the research status of driver fatigue detection technology in recent years, and studies and compares the fatigue detection methods based on driver physiological signals, driver behavior features, vehicle features and information fusion respectively. In addition, we also studied and analyzed the detection methods and the dataset of fatigue driving to provide reference for researchers.},
	language = {en},
	author = {Yan, Xiao},
	pages = {14},
	file = {Yan - A Review on Fatigue Driving Detection.pdf:/home/simeon/Zotero/storage/57U3LGG3/Yan - A Review on Fatigue Driving Detection.pdf:application/pdf},
}

@article{huang_multi-feature_2020,
	title = {Multi-feature fatigue driving detection based on computer vision},
	volume = {1651},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1651/1/012188},
	doi = {10.1088/1742-6596/1651/1/012188},
	abstract = {Fatigue driving is one of the main causes of traffic accidents. This paper proposes a fatigue detection method based on computer vision. The first is the introduction of an optimized algorithm, based on AdaBoost, to detect the face area, and then the ERT algorithm is used to achieve precise localization of the facial landmarks. Finally, a variety of fatigue features of eyes and mouth state associated with driving fatigue are extracted, and after the fusion of all these features, the fatigue driving detection is performed. The experimental results show that multi-feature detection is more accurate than single feature detection.},
	language = {en},
	number = {1},
	urldate = {2022-01-27},
	journal = {Journal of Physics: Conference Series},
	author = {Huang, Juan and Lin, Zihui},
	month = nov,
	year = {2020},
	pages = {012188},
	file = {Huang and Lin - 2020 - Multi-feature fatigue driving detection based on c.pdf:/home/simeon/Zotero/storage/IG37AUJQ/Huang and Lin - 2020 - Multi-feature fatigue driving detection based on c.pdf:application/pdf},
}

@article{lin_research_2013,
	title = {The {Research} on {Fatigue} {Driving} {Detection} {Algorithm}},
	volume = {8},
	issn = {1796-217X},
	url = {http://ojs.academypublisher.com/index.php/jsw/article/view/9658},
	doi = {10.4304/jsw.8.9.2272-2279},
	abstract = {Researches on Driver Fatigue Detection System, which aims to ensure the safety of operations and to reduce traffic accidents caused by artificial factors, has been the major research subject in transportation safety. There is an enormous advantage in the method obtaining the driver's image by camera, We propose efficient tracking and detecting algorithm and with an appearance model based on haar-like features, finding out the accuracy and robustness of tracking of eyes movements and the conflict between realtime tracing and accuracy of fatigue detection algorithms systems. First, PERCLOS algorithm is adopted to analyze and determine whether a person is fatigue. Second, AdaBoost algorithm is applied to fast detect and the algorithm is implemented in FPGA. Third, We propose a compressed sample tracking algorithm, which compress samples of image using the sparse measurement matrix and train the classification online. The algorithms runs in realtime and is implemented based on ARM add FPGA platform. Experimental results show that the algorithm has high recognition accuracy and robust performance under real train driving environment, in the case of nonlinear tracking of the human eye, illumination change, multi-scale variations, the driver head movement and pose variation.},
	language = {en},
	number = {9},
	urldate = {2022-01-27},
	journal = {Journal of Software},
	author = {Lin, Zhui and Wang, Lide and Zhou, Jieqiong and Wang, Tao},
	month = sep,
	year = {2013},
	pages = {2272--2279},
	file = {Lin et al. - 2013 - The Research on Fatigue Driving Detection Algorith.pdf:/home/simeon/Zotero/storage/55WS7SBC/Lin et al. - 2013 - The Research on Fatigue Driving Detection Algorith.pdf:application/pdf},
}

@article{li_fatigue_2019,
	title = {Fatigue driving detection model based on multi‐feature fusion and semi‐supervised active learning},
	volume = {13},
	issn = {1751-9578, 1751-9578},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-its.2018.5590},
	doi = {10.1049/iet-its.2018.5590},
	abstract = {Fatigue driving is one of the main factors of traffic accidents and there are many research efforts focusing on fatigue driving detection. With the extensive use of on-board sensors, a huge number of unlabelled driving data can be easily collected, however, it is a costly and laborious work to annotate semantic labels for these data manually, posing some difficulties to detect fatigue driving with these data. In this work, the authors propose a novel fatigue driving detection model based on multi-feature fusion and semi-supervised active learning. In the authors’ model, the steering features of the vehicle and the facial features of the driver are fused to improve the accuracy and stability of the model. Semi-supervised active learning algorithm allows us to make semantic labels for only a small number of data that can be propagated to the rest data, and help us establish an efficient fatigue driving detection model with automatic label propagation. Some experiments are conducted to validate their model, the results show that the accuracy is 86.25\%, which proves the effectiveness of the fatigue driving detection model.},
	language = {en},
	number = {9},
	urldate = {2022-01-27},
	journal = {IET Intelligent Transport Systems},
	author = {Li, Xu and Hong, Lin and Wang, Jian‐chun and Liu, Xiang},
	month = sep,
	year = {2019},
	pages = {1401--1409},
	file = {Li et al. - 2019 - Fatigue driving detection model based on multi‐fea.pdf:/home/simeon/Zotero/storage/FZKVS9LK/Li et al. - 2019 - Fatigue driving detection model based on multi‐fea.pdf:application/pdf},
}

@inproceedings{dong_eye_2015,
	address = {Dalian, China},
	title = {Eye {Detection} {Based} on {Integral} {Projection} and {Hough} {Round} {Transform}},
	isbn = {978-1-4673-7183-4},
	url = {http://ieeexplore.ieee.org/document/7310752/},
	doi = {10.1109/BDCloud.2015.34},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2015 {IEEE} {Fifth} {International} {Conference} on {Big} {Data} and {Cloud} {Computing}},
	publisher = {IEEE},
	author = {Dong, Chen and Wang, Xiaoli and Pei-hua, Chen and Pu-Liang, Yang},
	month = aug,
	year = {2015},
	pages = {252--255},
	file = {Dong et al. - 2015 - Eye Detection Based on Integral Projection and Hou.pdf:/home/simeon/Zotero/storage/SHMM7EGS/Dong et al. - 2015 - Eye Detection Based on Integral Projection and Hou.pdf:application/pdf},
}

@inproceedings{yao_gabor_2016,
	address = {Beijing, China},
	title = {Gabor {Feature} {Based} {Convolutional} {Neural} {Network} for {Object} {Recognition} in {Natural} {Scene}},
	isbn = {978-1-5090-2535-0},
	url = {http://ieeexplore.ieee.org/document/7726188/},
	doi = {10.1109/ICISCE.2016.91},
	abstract = {Feature extraction and classification are two important components in object recognition. While the traditional methods design these components individually, the deep neural networks jointly learn these two parts. In this paper, we propose a method of the convolutional neural network combined with Gabor filters for strengthening the learning of texture information. We called this model as Gabor-CNN below. Through experiments, the approach achieves the recognition rate of 81.53\%, yielding a 1.26\% promotion in the average accuracy rate compared with the results obtained using the convolutional neural network model alone on the ImageNet10 dataset, as well as significantly outperforming the traditional method based on Bag-of-Words model with SIFT.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2016 3rd {International} {Conference} on {Information} {Science} and {Control} {Engineering} ({ICISCE})},
	publisher = {IEEE},
	author = {Yao, Hu and Chuyi, Li and Dan, Hu and Weiyu, Yu},
	month = jul,
	year = {2016},
	pages = {386--390},
	file = {Yao et al. - 2016 - Gabor Feature Based Convolutional Neural Network f.pdf:/home/simeon/Zotero/storage/NWPC36Q8/Yao et al. - 2016 - Gabor Feature Based Convolutional Neural Network f.pdf:application/pdf;Yao et al. - 2016 - Gabor Feature Based Convolutional Neural Network f.pdf:/home/simeon/Zotero/storage/UCBRVMCW/Yao et al. - 2016 - Gabor Feature Based Convolutional Neural Network f.pdf:application/pdf},
}

@article{barea_driver_nodate,
	title = {Driver {Fatigue} {Detection} {System}},
	abstract = {Abstract – This paper presents a method for detecting the early signs of fatigue/drowsiness during driving. Analysing some biological and environmental variables, it is possible to detect the loss of alertness prior to the driver falling asleep. As a result of this analysis, the system will determine if the subject is able to drive. Heart rate variability (HRV), steering-wheel grip pressure, as well as temperature difference between the inside and outside of the vehicle, make possible to estimate in an indirect way the driver’s fatigue level. A hardware system has been developed to acquire and process these variables, as well as an algorithm to detect beats and calculate the HRV taking into account the others aspects mentioned before.},
	language = {en},
	author = {Barea, Rafael and Bergasa, Luis Miguel and Lopez, Elena},
	pages = {6},
	file = {Barea et al. - Driver Fatigue Detection System.PDF:/home/simeon/Zotero/storage/CA873YDH/Barea et al. - Driver Fatigue Detection System.PDF:application/pdf;Barea et al. - Driver Fatigue Detection System.PDF:/home/simeon/Zotero/storage/FVUXUVVL/Barea et al. - Driver Fatigue Detection System.PDF:application/pdf},
}

@article{zong_design_2021,
	title = {Design and research on the fatigue detection system of ship bridge duty based on image processing},
	volume = {2131},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2131/3/032119},
	doi = {10.1088/1742-6596/2131/3/032119},
	abstract = {With the development of the marine economy, the number of ships is increasing day by day, and is developing towards large-scale, diversified and professional development, and marine accidents caused by driver fatigue have attracted more and more attention. In order to reduce marine traffic accidents caused by fatigue driving of ship drivers and ensure the safety of life and property at sea, it is very necessary and important to study effective methods to detect the fatigue state of ship drivers in real time. This article mainly studies the early warning of ship fatigue driving. In view of the difficulties of the ship fatigue driving detection technology, reasonable performance indicators of the ship anti-fatigue driving image processing and early warning system are proposed; according to the system performance indicators, the HOG+SVM method is determined to automatically track the human face, and the human eye detection and tracking method is designed. Improved the method of eyelid closure to determine fatigue. In order to determine the eye opening and closing state or blinking frequency. The PERCLOS method is used to determine whether the driver is tired, and a warning is given when the ship's watch driver is tired. The system has the characteristics of non-contact, real-time, etc. and complies with the relevant technical standards of the International Maritime Organization (IMO) on the ship bridge fatigue warning system (BNWAS).},
	language = {en},
	number = {3},
	urldate = {2022-01-27},
	journal = {Journal of Physics: Conference Series},
	author = {Zong, Yonggang and Zhao, Xiandong and Ba, Zhongfeng},
	month = dec,
	year = {2021},
	pages = {032119},
	file = {Zong et al. - 2021 - Design and research on the fatigue detection syste.pdf:/home/simeon/Zotero/storage/6Z6TQDH4/Zong et al. - 2021 - Design and research on the fatigue detection syste.pdf:application/pdf},
}

@article{lambert_modelling_nodate,
	title = {Modelling and {Detection} of {Driver}’s {Fatigue} using {Ontology}},
	language = {en},
	author = {Lambert, Alexandre and Hina, Manolo Dulva and Barth, Celine and Soukane, Assia and Ramdane-Cherif, Amar},
	pages = {12},
	file = {Lambert et al. - Modelling and Detection of Driver’s Fatigue using .pdf:/home/simeon/Zotero/storage/35SUNHAL/Lambert et al. - Modelling and Detection of Driver’s Fatigue using .pdf:application/pdf},
}

@article{wang_deep_2021,
	title = {Deep {Face} {Recognition}: {A} {Survey}},
	volume = {429},
	issn = {09252312},
	shorttitle = {Deep {Face} {Recognition}},
	url = {http://arxiv.org/abs/1804.06655},
	doi = {10.1016/j.neucom.2020.10.081},
	abstract = {Deep learning applies multiple processing layers to learn representations of data with multiple levels of feature extraction. This emerging technique has reshaped the research landscape of face recognition (FR) since 2014, launched by the breakthroughs of DeepFace and DeepID. Since then, deep learning technique, characterized by the hierarchical architecture to stitch together pixels into invariant face representation, has dramatically improved the state-of-the-art performance and fostered successful real-world applications. In this survey, we provide a comprehensive review of the recent developments on deep FR, covering broad topics on algorithm designs, databases, protocols, and application scenes. First, we summarize different network architectures and loss functions proposed in the rapid evolution of the deep FR methods. Second, the related face processing methods are categorized into two classes: “one-to-many augmentation” and “many-to-one normalization”. Then, we summarize and compare the commonly used databases for both model training and evaluation. Third, we review miscellaneous scenes in deep FR, such as cross-factor, heterogenous, multiple-media and industrial scenes. Finally, the technical challenges and several promising directions are highlighted.},
	language = {en},
	urldate = {2022-01-29},
	journal = {Neurocomputing},
	author = {Wang, Mei and Deng, Weihong},
	month = mar,
	year = {2021},
	note = {arXiv: 1804.06655},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {215--244},
	annote = {Comment: Neurocomputing},
	file = {Wang and Deng - 2021 - Deep Face Recognition A Survey.pdf:/home/simeon/Zotero/storage/VYV9UE94/Wang and Deng - 2021 - Deep Face Recognition A Survey.pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780459/},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2022-01-29},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
	file = {He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:/home/simeon/Zotero/storage/X96PIZ5C/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@article{malhotra_long_2015,
	title = {Long {Short} {Term} {Memory} {Networks} for {Anomaly} {Detection} in {Time} {Series}},
	abstract = {Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The eﬃcacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Malhotra, Pankaj and Vig, Lovekesh and Shroﬀ, Gautam and Agarwal, Puneet},
	year = {2015},
	pages = {6},
	file = {Malhotra et al. - 2015 - Long Short Term Memory Networks for Anomaly Detect.pdf:/home/simeon/Zotero/storage/FBIZRQQJ/Malhotra et al. - 2015 - Long Short Term Memory Networks for Anomaly Detect.pdf:application/pdf},
}

@article{szegedy_rethinking_2015,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	url = {http://arxiv.org/abs/1512.00567},
	abstract = {Convolutional networks are at the core of most stateof-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efﬁciency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efﬁciently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classiﬁcation challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error and 17.3\% top-1 error.},
	language = {en},
	urldate = {2022-01-29},
	journal = {arXiv:1512.00567 [cs]},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.00567},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer.pdf:/home/simeon/Zotero/storage/VQF3ILH9/Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer.pdf:application/pdf},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insu cient, decaying error back ow. We brie y review Hochreiter's 1991 analysis of this problem, then address it by introducing a novel, e cient, gradient-based method called {\textbackslash}Long Short-Term Memory" (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error ow through {\textbackslash}constant error carrousels" within special units. Multiplicative gate units learn to open and close access to the constant error ow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with arti cial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, arti cial long time lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2022-01-29},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
	file = {Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:/home/simeon/Zotero/storage/YWNC5AYP/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf;Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:/home/simeon/Zotero/storage/5TYTFHIX/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf},
}

@article{arfizurrahmanl_real-time_2021,
	title = {Real-{Time} {Non}-{Intrusive} {Driver} {Fatigue} {Detection} {System} using {Belief} {Rule}-{Based} {Expert} {System}},
	volume = {11},
	url = {https://doi.org/10.22667/JISIS.2021.11.30.044},
	doi = {10.22667/JISIS.2021.11.30.044},
	abstract = {This paper presents a non-intrusive system for detecting driver fatigue in real-time. To determine the level of fatigue the system uses various visual features, namely head nodding, eye closure duration and yawning. A state-of-the-art facial landmark detector ’IntraFace’ has been adopted to determine the eye state, mouth state and head pose estimation. However, different forms of uncertainties such as vagueness, imprecision, ambiguity and incompleteness are involved in calculating these visual parameters. Therefore, a Belief Rule-Based Expert System (BRBES) is employed, which has the ability to handle the uncertainties. The information of the visual parameters is sent to BRBES as input to determine the level of fatigue. An optimal learning model has been developed to improve the performance and accuracy of the BRBES. A comparison between the system and the fuzzy rulebased expert system has been carried out. The system generates more effective and reliable results than the fuzzy rule-based expert system.},
	language = {en},
	number = {4},
	urldate = {2022-01-29},
	journal = {Journal of Internet Services and Information Security},
	author = {Arfizurrahmanl, Mohammad and Ahmad and Hossain, Mohammad Shahadat and Haque, Mohammad Ahsanul and Andersson, Karl},
	month = nov,
	year = {2021},
	pages = {44--60},
	file = {Arfizurrahmanl et al. - 2021 - Real-Time Non-Intrusive Driver Fatigue Detection S.pdf:/home/simeon/Zotero/storage/84WN3E78/Arfizurrahmanl et al. - 2021 - Real-Time Non-Intrusive Driver Fatigue Detection S.pdf:application/pdf},
}

@article{wang_exploiting_2015,
	title = {Exploiting {Spatial} {Redundancy} of {Image} {Sensor} for {Motion} {Robust} {rPPG}},
	volume = {62},
	issn = {0018-9294, 1558-2531},
	url = {http://ieeexplore.ieee.org/document/6894148/},
	doi = {10.1109/TBME.2014.2356291},
	abstract = {Remote photoplethysmography (rPPG) techniques can measure cardiac activity by detecting pulse-induced colour variations on human skin using an RGB camera. State-of-theart rPPG methods are sensitive to subject body motions (e.g., motion-induced colour distortions). This study proposes a novel framework to improve the motion robustness of rPPG. The basic idea of this work originates from the observation that a camera can simultaneously sample multiple skin regions in parallel, and each of them can be treated as an independent sensor for pulse measurement. The spatial-redundancy of an image sensor can thus be exploited to distinguish the pulsesignal from motion-induced noise. To this end, the pixel-based rPPG sensors are constructed to estimate a robust pulse-signal using motion-compensated pixel-to-pixel pulse extraction, spatial pruning, and temporal ﬁltering. The evaluation of this strategy is not based on a full clinical trial, but on 36 challenging benchmark videos consisting of subjects that differ in gender, skin-types and performed motion-categories. Experimental results show that the proposed method improves the SNR of the state-of-the-art rPPG technique from 3.34dB to 6.76dB, and the agreement (±1.96σ) with instantaneous reference pulse-rate from 55\% to 80\% correct. ANOVA with post-hoc comparison shows that the improvement on motion robustness is signiﬁcant. The rPPG method developed in this study has a performance that is very close to that of the contact-based sensor under realistic situations, while its computational efﬁciency allows real-time processing on an off-the-shelf computer.},
	language = {en},
	number = {2},
	urldate = {2022-01-29},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wang, Wenjin and Stuijk, Sander and de Haan, Gerard},
	month = feb,
	year = {2015},
	pages = {415--425},
	file = {Wang et al. - 2015 - Exploiting Spatial Redundancy of Image Sensor for .pdf:/home/simeon/Zotero/storage/2ZFY7MM9/Wang et al. - 2015 - Exploiting Spatial Redundancy of Image Sensor for .pdf:application/pdf},
}

@article{chen_face_2019,
	title = {Face liveness detection: fusing colour texture feature and deep feature},
	volume = {8},
	issn = {2047-4938, 2047-4946},
	shorttitle = {Face liveness detection},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-bmt.2018.5235},
	doi = {10.1049/iet-bmt.2018.5235},
	abstract = {The identification which uses biological characteristics has been a current top in the recent past. However, numerous spoofing skills occur with the rising prosperity of advance recognition technology, especially in the detection and recognition of a face. In allusion to the problem above, more robust and accurate face spoofing detection schemes have been put forward. Convolutional neural networks (CNNs) have demonstrated extraordinary success in face liveness detection recently. In this study, an effective face anti-spoofing detection method based on CNN and rotation invariant local binary patterns (RI-LBP) has been proposed. First, the authors use CNN to extract deep features and use RI-LBP to extract colour texture features. In addition, the principal component analysis approach is employed to decrease the dimensions of deep characteristic. Moreover, two different features are fused before applying to support vector machine (SVM). Finally, the SVM classifier is adopted to identify genuine faces from fake faces. They have conducted extensive experiments to obtain a scheme of better generalisation capability for face anti-spoofing detection. The analysis results indicate that the proposed approach implements great generalisation capability over other state-of-the-art approaches within the intra-databases and cross-databases.},
	language = {en},
	number = {6},
	urldate = {2022-01-29},
	journal = {IET Biometrics},
	author = {Chen, Fu‐Mei and Wen, Chang and Xie, Kai and Wen, Fang‐Qing and Sheng, Guan‐Qun and Tang, Xin‐Gong},
	month = nov,
	year = {2019},
	pages = {369--377},
	file = {Chen et al. - 2019 - Face liveness detection fusing colour texture fea.pdf:/home/simeon/Zotero/storage/CKQGWJ6P/Chen et al. - 2019 - Face liveness detection fusing colour texture fea.pdf:application/pdf},
}

@article{de_haan_robust_2013,
	title = {Robust {Pulse} {Rate} {From} {Chrominance}-{Based} {rPPG}},
	volume = {60},
	issn = {0018-9294, 1558-2531},
	url = {https://ieeexplore.ieee.org/document/6523142/},
	doi = {10.1109/TBME.2013.2266196},
	abstract = {Remote photoplethysmography (rPPG) enables contactless monitoring of the blood volume pulse using a regular camera. Recent research focused on improved motion robustness, but the proposed blind source separation techniques (BSS) in RGB color space show limited success. We present an analysis of the motion problem, from which far superior chrominance-based methods emerge. For a population of 117 stationary subjects, we show our methods to perform in 92\% good agreement (±1.96σ) with contact PPG, with RMSE and standard deviation both a factor of 2 better than BSS-based methods. In a ﬁtness setting using a simple spectral peak detector, the obtained pulse-rate for modest motion (bike) improves from 79\% to 98\% correct, and for vigorous motion (stepping) from less than 11\% to more than 48\% correct. We expect the greatly improved robustness to considerably widen the application scope of the technology.},
	language = {en},
	number = {10},
	urldate = {2022-01-29},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {de Haan, Gerard and Jeanne, Vincent},
	month = oct,
	year = {2013},
	pages = {2878--2886},
	file = {de Haan and Jeanne - 2013 - Robust Pulse Rate From Chrominance-Based rPPG.pdf:/home/simeon/Zotero/storage/FG2YB2DD/de Haan and Jeanne - 2013 - Robust Pulse Rate From Chrominance-Based rPPG.pdf:application/pdf},
}

@article{de_haan_improved_2014,
	title = {Improved motion robustness of remote-{PPG} by using the blood volume pulse signature},
	volume = {35},
	issn = {0967-3334, 1361-6579},
	url = {https://iopscience.iop.org/article/10.1088/0967-3334/35/9/1913},
	doi = {10.1088/0967-3334/35/9/1913},
	abstract = {Remote photoplethysmography (rPPG) enables contact-free monitoring of the blood volume pulse using a color camera. Essentially, it detects the minute optical absorption changes caused by blood volume variations in the skin. In this paper, we show that the different absorption spectra of arterial blood and bloodless skin cause the variations to occur along a very specific vector in a normalized RGB-space. The exact vector can be determined for a given light spectrum and for given transfer characteristics of the optical filters in the camera. We show that this ‘signature’ can be used to design an rPPG algorithm with a much better motion robustness than the recent methods based on blind source separation, and even better than the chrominance-based methods we published earlier. Using six videos recorded in a gym, with four subjects exercising on a range of fitness devices, we confirm the superior motion robustness of our newly proposed rPPG methods. A simple peak detector in the frequency domain returns the correct pulse-rate for 68\% of total measurements compared to 60\% for the best previous method, while the SNR of the pulse-signal improves from  − 5 dB to  − 4 dB. For a large population of 117 stationary subjects we prove that the accuracy is comparable to the best previous method, although the SNR of the pulse-signal drops from  + 8.4 dB to  + 7.6 dB. We expect the improved motion robustness to significantly widen the application scope of the rPPG-technique.},
	language = {en},
	number = {9},
	urldate = {2022-01-29},
	journal = {Physiological Measurement},
	author = {de Haan, G and van Leest, A},
	month = sep,
	year = {2014},
	pages = {1913--1926},
	file = {de Haan and van Leest - 2014 - Improved motion robustness of remote-PPG by using .pdf:/home/simeon/Zotero/storage/NS5YNRWI/de Haan and van Leest - 2014 - Improved motion robustness of remote-PPG by using .pdf:application/pdf},
}

@article{mitas_journal_nodate,
	title = {{JOURNAL} {OF} {MEDICAL} {INFORMATICS} \& {TECHNOLOGIES} {Vol}. 13/2009, {ISSN} 1642-6037},
	language = {en},
	author = {Mitas, Andrzej and Bugdol, Marcin and Ryguła, Artur},
	pages = {8},
	file = {Mitas et al. - JOURNAL OF MEDICAL INFORMATICS & TECHNOLOGIES Vol..pdf:/home/simeon/Zotero/storage/THZE76N2/Mitas et al. - JOURNAL OF MEDICAL INFORMATICS & TECHNOLOGIES Vol..pdf:application/pdf},
}

@article{jackson_deconstructing_2013,
	title = {Deconstructing and reconstructing cognitive performance in sleep deprivation},
	volume = {17},
	issn = {10870792},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1087079212000779},
	doi = {10.1016/j.smrv.2012.06.007},
	abstract = {Mitigation of cognitive impairment due to sleep deprivation in operational settings is critical for safety and productivity. Achievements in this area are hampered by limited knowledge about the effects of sleep loss on actual job tasks. Sleep deprivation has different effects on different cognitive performance tasks, but the mechanisms behind this task-speciﬁcity are poorly understood. In this context it is important to recognize that cognitive performance is not a unitary process, but involves a number of component processes. There is emerging evidence that these component processes are differentially affected by sleep loss.},
	language = {en},
	number = {3},
	urldate = {2022-01-29},
	journal = {Sleep Medicine Reviews},
	author = {Jackson, Melinda L. and Gunzelmann, Glenn and Whitney, Paul and Hinson, John M. and Belenky, Gregory and Rabat, Arnaud and Van Dongen, Hans P.A.},
	month = jun,
	year = {2013},
	pages = {215--225},
	file = {Jackson et al. - 2013 - Deconstructing and reconstructing cognitive perfor.pdf:/home/simeon/Zotero/storage/WUT79IDL/Jackson et al. - 2013 - Deconstructing and reconstructing cognitive perfor.pdf:application/pdf},
}

@article{rabat_extra-auditory_2007,
	title = {Extra-auditory {Effects} of {Noise} in {Laboratory} {Animals}: {The} {Relationship} {Between} {Noise} and {Sleep}},
	volume = {46},
	language = {en},
	number = {1},
	journal = {Journal of the American Association for Laboratory Animal Science},
	author = {Rabat, Arnaud},
	year = {2007},
	pages = {7},
	file = {Rabat - 2007 - Extra-auditory Effects of Noise in Laboratory Anim.pdf:/home/simeon/Zotero/storage/3HMTI9N9/Rabat - 2007 - Extra-auditory Effects of Noise in Laboratory Anim.pdf:application/pdf},
}

@article{arnal_benefits_2015,
	title = {Benefits of {Sleep} {Extension} on {Sustained} {Attention} and {Sleep} {Pressure} {Before} and {During} {Total} {Sleep} {Deprivation} and {Recovery}},
	volume = {38},
	issn = {1550-9109, 0161-8105},
	url = {https://academic.oup.com/sleep/article/38/12/1935/2417960},
	doi = {10.5665/sleep.5244},
	abstract = {Objectives: To investigate the effects of 6 nights of sleep extension on sustained attention and sleep pressure before and during total sleep deprivation and after a subsequent recovery sleep. Design: Subjects participated in two experimental conditions (randomized cross-over design): extended sleep (EXT, 9.8 ± 0.1 h (mean ± SE) time in bed) and habitual sleep (HAB, 8.2 ± 0.1 h time in bed). In each condition, subjects performed two consecutive phases: (1) 6 nights of either EXT or HAB (2) three days in-laboratory: baseline, total sleep deprivation and after 10 h of recovery sleep. Setting: Residential sleep extension and sleep performance laboratory (continuous polysomnographic recording). Participants: 14 healthy men (age range: 26–37 years). Interventions: EXT vs. HAB sleep durations prior to total sleep deprivation.
Measurements and Results: Total sleep time and duration of all sleep stages during the 6 nights were significantly higher in EXT than HAB. EXT improved psychomotor vigilance task performance (PVT, both fewer lapses and faster speed) and reduced sleep pressure as evidenced by longer multiple sleep latencies (MSLT) at baseline compared to HAB. EXT limited PVT lapses and the number of involuntary microsleeps during total sleep deprivation. Differences in PVT lapses and speed and MSLT at baseline were maintained after one night of recovery sleep.
Conclusion: Six nights of extended sleep improve sustained attention and reduce sleep pressure. Sleep extension also protects against psychomotor vigilance task lapses and microsleep degradation during total sleep deprivation. These beneficial effects persist after one night of recovery sleep.},
	language = {en},
	number = {12},
	urldate = {2022-01-29},
	journal = {Sleep},
	author = {Arnal, Pierrick J. and Sauvet, Fabien and Leger, Damien and van Beers, Pascal and Bayon, Virginie and Bougard, Clément and Rabat, Arnaud and Millet, Guillaume Y. and Chennaoui, Mounir},
	month = dec,
	year = {2015},
	pages = {1935--1943},
	file = {Arnal et al. - 2015 - Benefits of Sleep Extension on Sustained Attention.pdf:/home/simeon/Zotero/storage/YV5CGMJB/Arnal et al. - 2015 - Benefits of Sleep Extension on Sustained Attention.pdf:application/pdf},
}

@article{dang_rhythm-dependent_2021,
	title = {Rhythm-{Dependent} {Multilayer} {Brain} {Network} for the {Detection} of {Driving} {Fatigue}},
	volume = {25},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/9137635/},
	doi = {10.1109/JBHI.2020.3008229},
	abstract = {Fatigue driving has attracted a great deal of attention for its huge inﬂuence on automobile accidents. Recognizing driving fatigue provides a primary but signiﬁcant way for addressing this problem. In this paper, we ﬁrst conduct the simulated driving experiments to acquire the EEG signals in alert and fatigue states. Then, for multi-channel EEG signals without pre-processing, a novel rhythm-dependent multilayer brain network (RDMB network) is developed and analyzed for driving fatigue detection. We ﬁnd that there exists a signiﬁcant difference between alert and fatigue states from the view of network science. Further, key sub-RDMB network based on closeness centrality are extracted. We calculate six network measures from the key sub-RDMB network and construct feature vectors to classify the alert and fatigue states. The results show that our method can respectively achieve the average accuracy of 95.28\% (with sample length of 5s), 90.25\% (2s), and 87.69\% (1s), signiﬁcantly higher than compared methods. All these validate the effectiveness of RDMB network for reliable driving fatigue detection via EEG.},
	language = {en},
	number = {3},
	urldate = {2022-01-29},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Dang, Weidong and Gao, Zhongke and Lv, Dongmei and Sun, Xinlin and Cheng, Chichao},
	month = mar,
	year = {2021},
	pages = {693--700},
	file = {Dang et al. - 2021 - Rhythm-Dependent Multilayer Brain Network for the .pdf:/home/simeon/Zotero/storage/B86FK2IB/Dang et al. - 2021 - Rhythm-Dependent Multilayer Brain Network for the .pdf:application/pdf},
}

@article{hasan_human_2021,
	title = {Human {Face} {Detection} {Techniques}: {A} {Comprehensive} {Review} and {Future} {Research} {Directions}},
	volume = {10},
	issn = {2079-9292},
	shorttitle = {Human {Face} {Detection} {Techniques}},
	url = {https://www.mdpi.com/2079-9292/10/19/2354},
	doi = {10.3390/electronics10192354},
	abstract = {Face detection, which is an effortless task for humans, is complex to perform on machines. The recent veer proliferation of computational resources is paving the way for frantic advancement of face detection technology. Many astutely developed algorithms have been proposed to detect faces. However, there is little attention paid in making a comprehensive survey of the available algorithms. This paper aims at providing fourfold discussions on face detection algorithms. First, we explore a wide variety of the available face detection algorithms in ﬁve steps, including history, working procedure, advantages, limitations, and use in other ﬁelds alongside face detection. Secondly, we include a comparative evaluation among different algorithms in each single method. Thirdly, we provide detailed comparisons among the algorithms epitomized to have an all-inclusive outlook. Lastly, we conclude this study with several promising research directions to pursue. Earlier survey papers on face detection algorithms are limited to just technical details and popularly used algorithms. In our study, however, we cover detailed technical explanations of face detection algorithms and various recent sub-branches of the neural network. We present detailed comparisons among the algorithms in all-inclusive and under sub-branches. We provide the strengths and limitations of these algorithms and a novel literature survey that includes their use besides face detection.},
	language = {en},
	number = {19},
	urldate = {2022-01-29},
	journal = {Electronics},
	author = {Hasan, Md Khaled and Ahsan, Md. Shamim and {Abdullah-Al-Mamun} and Newaz, S. H. Shah and Lee, Gyu Myoung},
	month = sep,
	year = {2021},
	pages = {2354},
	file = {Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:/home/simeon/Zotero/storage/CSIQZIER/Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:application/pdf;Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:/home/simeon/Zotero/storage/7BA7RPLM/Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:application/pdf;Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:/home/simeon/Zotero/storage/WJD79Q6W/Hasan et al. - 2021 - Human Face Detection Techniques A Comprehensive R.pdf:application/pdf},
}

@article{celiktutan_comparative_2013,
	title = {A comparative study of face landmarking techniques},
	volume = {2013},
	issn = {1687-5281},
	url = {https://jivp-eurasipjournals.springeropen.com/articles/10.1186/1687-5281-2013-13},
	doi = {10.1186/1687-5281-2013-13},
	abstract = {Face landmarking, defined as the detection and localization of certain characteristic points on the face, is an important intermediary step for many subsequent face processing operations that range from biometric recognition to the understanding of mental states. Despite its conceptual simplicity, this computer vision problem has proven extremely challenging due to inherent face variability as well as the multitude of confounding factors such as pose, expression, illumination and occlusions. The purpose of this survey is to give an overview of landmarking algorithms and their progress over the last decade, categorize them and show comparative performance statistics of the state of the art. We discuss the main trends and indicate current shortcomings with the expectation that this survey will provide further impetus for the much needed high-performance, real-life face landmarking operating at video rates.},
	language = {en},
	number = {1},
	urldate = {2022-01-29},
	journal = {EURASIP Journal on Image and Video Processing},
	author = {Çeliktutan, Oya and Ulukaya, Sezer and Sankur, Bülent},
	month = dec,
	year = {2013},
	pages = {13},
	file = {Çeliktutan et al. - 2013 - A comparative study of face landmarking techniques.pdf:/home/simeon/Zotero/storage/DAUYTNIK/Çeliktutan et al. - 2013 - A comparative study of face landmarking techniques.pdf:application/pdf;Çeliktutan et al. - 2013 - A comparative study of face landmarking techniques.pdf:/home/simeon/Zotero/storage/IP7RML75/Çeliktutan et al. - 2013 - A comparative study of face landmarking techniques.pdf:application/pdf},
}

@inproceedings{huang_facial_2015,
	address = {Santiago, Chile},
	title = {Facial {Micro}-{Expression} {Recognition} {Using} {Spatiotemporal} {Local} {Binary} {Pattern} with {Integral} {Projection}},
	isbn = {978-1-4673-9711-7},
	url = {http://ieeexplore.ieee.org/document/7406359/},
	doi = {10.1109/ICCVW.2015.10},
	abstract = {Recently, there are increasing interests in inferring mirco-expression from facial image sequences. For microexpression recognition, feature extraction is an important critical issue. In this paper, we proposes a novel framework based on a new spatiotemporal facial representation to analyze micro-expressions with subtle facial movement. Firstly, an integral projection method based on difference images is utilized for obtaining horizontal and vertical projection, which can preserve the shape attributes of facial images and increase the discrimination for micro-expressions. Furthermore, we employ the local binary pattern operators to extract the appearance and motion features on horizontal and vertical projections. Intensive experiments are conducted on three available published micro-expression databases for evaluating the performance of the method. Experimental results demonstrate that the new spatiotemporal descriptor can achieve promising performance in micro-expression recognition.},
	language = {en},
	urldate = {2022-01-29},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	publisher = {IEEE},
	author = {Huang, Xiaohua and Wang, Su-Jing and Zhao, Guoying and Piteikainen, Matti},
	month = dec,
	year = {2015},
	pages = {1--9},
	file = {Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:/home/simeon/Zotero/storage/7FBRDY3F/Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:application/pdf;Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:/home/simeon/Zotero/storage/LUVKS9A8/Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:application/pdf;Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:/home/simeon/Zotero/storage/AGM8MUEU/Huang et al. - 2015 - Facial Micro-Expression Recognition Using Spatiote.pdf:application/pdf},
}

@article{bai_pupil_2021,
	title = {A {Pupil} {Segmentation} {Algorithm} {Based} on {Fuzzy} {Clustering} of {Distributed} {Information}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/12/4209},
	doi = {10.3390/s21124209},
	abstract = {Pupil segmentation is critical for line-of-sight estimation based on the pupil center method. Due to noise and individual differences in human eyes, the quality of eye images often varies, making pupil segmentation difﬁcult. In this paper, we propose a pupil segmentation method based on fuzzy clustering of distributed information, which ﬁrst preprocesses the original eye image to remove features such as eyebrows and shadows and highlight the pupil area; then the Gaussian model is introduced into global distribution information to enhance the classiﬁcation fuzzy afﬁliation for the local neighborhood, and an adaptive local window ﬁlter that fuses local spatial and intensity information is proposed to suppress the noise in the image and preserve the edge information of the pupil details. Finally, the intensity histogram of the ﬁltered image is used for fast clustering to obtain the clustering center of the pupil, and this binarization process is used to segment the pupil for the next pupil localization. Experimental results show that the method has high segmentation accuracy, sensitivity, and speciﬁcity. It can accurately segment the pupil when there are interference factors such as light spots, light reﬂection, and contrast difference at the edge of the pupil, which is an important contribution to improving the stability and accuracy of the line-of-sight tracking.},
	language = {en},
	number = {12},
	urldate = {2022-01-29},
	journal = {Sensors},
	author = {Bai, Kemeng and Wang, Jianzhong and Wang, Hongfeng},
	month = jun,
	year = {2021},
	pages = {4209},
	file = {Bai et al. - 2021 - A Pupil Segmentation Algorithm Based on Fuzzy Clus.pdf:/home/simeon/Zotero/storage/7E2VICFF/Bai et al. - 2021 - A Pupil Segmentation Algorithm Based on Fuzzy Clus.pdf:application/pdf;Bai et al. - 2021 - A Pupil Segmentation Algorithm Based on Fuzzy Clus.pdf:/home/simeon/Zotero/storage/CFYYWHYX/Bai et al. - 2021 - A Pupil Segmentation Algorithm Based on Fuzzy Clus.pdf:application/pdf},
}

@article{yiu_deepvog_2019,
	title = {{DeepVOG}: {Open}-source pupil segmentation and gaze estimation in neuroscience using deep learning},
	volume = {324},
	issn = {01650270},
	shorttitle = {{DeepVOG}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027019301578},
	doi = {10.1016/j.jneumeth.2019.05.016},
	abstract = {Background: A prerequisite for many eye tracking and video-oculography (VOG) methods is an accurate localization of the pupil. Several existing techniques face challenges in images with artifacts and under naturalistic low-light conditions, e.g. with highly dilated pupils. New method: For the first time, we propose to use a fully convolutional neural network (FCNN) for segmentation of the whole pupil area, trained on 3946 VOG images hand-annotated at our institute. We integrate the FCNN into DeepVOG, along with an established method for gaze estimation from elliptical pupil contours, which we improve upon by considering our FCNN's segmentation confidence measure.
Results: The FCNN output simultaneously enables us to perform pupil center localization, elliptical contour estimation and blink detection, all with a single network and with an assigned confidence value, at framerates above 130 Hz on commercial workstations with GPU acceleration. Pupil centre coordinates can be estimated with a median accuracy of around 1.0 pixel, and gaze estimation is accurate to within 0.5 degrees. The FCNN is able to robustly segment the pupil in a wide array of datasets that were not used for training.
Comparison with existing methods: We validate our method against gold standard eye images that were artificially rendered, as well as hand-annotated VOG data from a gold-standard clinical system (EyeSeeCam) at our institute.
Conclusions: Our proposed FCNN-based pupil segmentation framework is accurate, robust and generalizes well to new VOG datasets. We provide our code and pre-trained FCNN model open-source and for free under www. github.com/pydsgz/DeepVOG.},
	language = {en},
	urldate = {2022-01-29},
	journal = {Journal of Neuroscience Methods},
	author = {Yiu, Yuk-Hoi and Aboulatta, Moustafa and Raiser, Theresa and Ophey, Leoni and Flanagin, Virginia L. and zu Eulenburg, Peter and Ahmadi, Seyed-Ahmad},
	month = aug,
	year = {2019},
	pages = {108307},
	file = {Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/2NWW8UCP/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/4L2FEKW5/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/2B5LVFD7/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/93SPPFI7/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/7ZAJ7HTV/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/7G95XHZM/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf;Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:/home/simeon/Zotero/storage/R4SYT3U5/Yiu et al. - 2019 - DeepVOG Open-source pupil segmentation and gaze e.pdf:application/pdf},
}

@article{rajamohana_driver_2021,
	title = {Driver drowsiness detection system using hybrid approach of convolutional neural network and bidirectional long short term memory ({CNN}\_BILSTM)},
	volume = {45},
	issn = {22147853},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214785320395742},
	doi = {10.1016/j.matpr.2020.11.898},
	abstract = {In today’s world driver drowsiness is a major reason for fatal accidents of on road vehicles. Developing an automated, real-time drowsiness detection system is essential to provide accurate and timely alerts to the driver. In the proposed system, hybrid approach of CNN (Convolutional Neural Network) and BiLSTM (Bidirectional Long Term Dependencies) is used to detect the driver’s drowsiness. Video camera is used to track the facial image and eye blinks of the driver. The proposed system works in three main phases: In the First phase, driver’s face image is Identiﬁed and observed using a web camera. In the Second phase, the eye image features are extracted using the Euclidean algorithm. During the third phase, the eye blinks are continually monitored. The ﬁnal stage decides whether the measure in eye square is closed state or open state. When a driver falls asleep, there will be a warning message to alert the driver to prevent road accidents.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Materials Today: Proceedings},
	author = {Rajamohana, S.P. and Radhika, E.G. and Priya, S. and Sangeetha, S.},
	year = {2021},
	pages = {2897--2901},
	file = {Rajamohana et al. - 2021 - Driver drowsiness detection system using hybrid ap.pdf:/home/simeon/Zotero/storage/ADMKIPBH/Rajamohana et al. - 2021 - Driver drowsiness detection system using hybrid ap.pdf:application/pdf;Rajamohana et al. - 2021 - Driver drowsiness detection system using hybrid ap.pdf:/home/simeon/Zotero/storage/RHKI9VT2/Rajamohana et al. - 2021 - Driver drowsiness detection system using hybrid ap.pdf:application/pdf},
}

@inproceedings{choi_accurate_2019,
	address = {Taipei, Taiwan},
	title = {Accurate {Eye} {Pupil} {Localization} {Using} {Heterogeneous} {CNN} {Models}},
	isbn = {978-1-5386-6249-6},
	url = {https://ieeexplore.ieee.org/document/8803121/},
	doi = {10.1109/ICIP.2019.8803121},
	abstract = {Eye pupil localization is one of the indispensable technologies in various computer vision applications such as virtual reality and augmented reality. In general, the algorithm consists of finding the approximate eye region and finding the pupil position by extracting the semantic feature from each eye region. However, the performance is affected not only by illumination and image resolution but also by glasses wear. Therefore, this paper proposes an eye pupil localization algorithm which is robust against the above disturbance conditions and also has high accuracy using heterogeneous CNN models. First, faces in the image and landmarks in the face(s) are detected sequentially, and the eye region is determined based on the landmarks. Especially, if glasses are present, the glasses are removed by GAN to find the correct eye region. Next, the pupil region is segmented using fully convolutional networks. Finally, the position of the segmented pupil is calculated. Experimental results show that the proposed algorithm outperforms the state-of-the-art algorithms for public databases such as BioID and GI4E.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2019 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Choi, Jun Ho and Il Lee, Kang and Kim, Young Chan and Cheol Song, Byung},
	month = sep,
	year = {2019},
	pages = {2179--2183},
	file = {Choi et al. - 2019 - Accurate Eye Pupil Localization Using Heterogeneou.pdf:/home/simeon/Zotero/storage/KQLUCKHC/Choi et al. - 2019 - Accurate Eye Pupil Localization Using Heterogeneou.pdf:application/pdf;Choi et al. - 2019 - Accurate Eye Pupil Localization Using Heterogeneou.pdf:/home/simeon/Zotero/storage/BSWTCW4Y/Choi et al. - 2019 - Accurate Eye Pupil Localization Using Heterogeneou.pdf:application/pdf},
}

@article{utaminingrum_image_2017,
	title = {Image {Processing} for {Rapidly} {Eye} {Detection} based on {Robust} {Haar} {Sliding} {Window}},
	volume = {7},
	issn = {2088-8708, 2088-8708},
	url = {http://ijece.iaescore.com/index.php/IJECE/article/view/6430},
	doi = {10.11591/ijece.v7i2.pp823-830},
	abstract = {Object Detection using Haar Cascade Clasifier widely applied in several devices and applications as a medium of interaction between human and computer such as a tool control that utilizes the detection of eye movements. Obviously speed and precision in the detection process such as eyes, has an effect if implemented on a device. If the eye could not detect accurately, controlling device systems could reach bad detection as well. The proposed method can be used as an approach to detect the eye region of eye based on haar classifier method by means of modifying the direction of sliding window. In which, it was initially placed in the middle position of image on facial area by assuming the location of eyes area in the central region of the image. While the window region of conventional haar cascade scan the whole of image start from the left top corner. From the experiment by using our proposed method, it can speed up the the computation time and improve accuracy significantly reach to 92,4\%.},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {International Journal of Electrical and Computer Engineering (IJECE)},
	author = {Utaminingrum, Fitri and Praetya, Renaldi Primaswara and Sari, Yuita Arum},
	month = apr,
	year = {2017},
	pages = {823},
	file = {Utaminingrum et al. - 2017 - Image Processing for Rapidly Eye Detection based o.pdf:/home/simeon/Zotero/storage/RD2GHB2Q/Utaminingrum et al. - 2017 - Image Processing for Rapidly Eye Detection based o.pdf:application/pdf;Utaminingrum et al. - 2017 - Image Processing for Rapidly Eye Detection based o.pdf:/home/simeon/Zotero/storage/22UK7J6N/Utaminingrum et al. - 2017 - Image Processing for Rapidly Eye Detection based o.pdf:application/pdf},
}

@article{huang_local_2011,
	title = {Local {Binary} {Patterns} and {Its} {Application} to {Facial} {Image} {Analysis}: {A} {Survey}},
	volume = {41},
	issn = {1094-6977, 1558-2442},
	shorttitle = {Local {Binary} {Patterns} and {Its} {Application} to {Facial} {Image} {Analysis}},
	url = {http://ieeexplore.ieee.org/document/5739539/},
	doi = {10.1109/TSMCC.2011.2118750},
	abstract = {Local Binary Patterns (LBP) is a non-parametric descriptor whose aim is to efficiently summarize the local structures of images. In recent years, it has aroused increasing interest in many areas of image processing and computer vision, and has shown its effectiveness in a number of applications, in particular for facial image analysis, including tasks as diverse as face detection, face recognition, facial expression analysis, demographic classification, etc. This paper presents a comprehensive survey of LBP methodology including several more recent variations. As a typical application of the LBP approach, LBP-based facial image analysis is extensively reviewed, while its successful extensions in dealing with various tasks of facial image analysis are also highlighted.},
	language = {en},
	number = {6},
	urldate = {2022-01-31},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Huang, Di and Shan, Caifeng and Ardabilian, Mohsen and Wang, Yunhong and Chen, Liming},
	month = nov,
	year = {2011},
	pages = {765--781},
	file = {Huang et al. - 2011 - Local Binary Patterns and Its Application to Facia.pdf:/home/simeon/Zotero/storage/5MAFCH3C/Huang et al. - 2011 - Local Binary Patterns and Its Application to Facia.pdf:application/pdf},
}

@article{ahonen_face_2006,
	title = {Face {Description} with {Local} {Binary} {Patterns}: {Application} to {Face} {Recognition}},
	volume = {28},
	issn = {0162-8828, 2160-9292},
	shorttitle = {Face {Description} with {Local} {Binary} {Patterns}},
	url = {http://ieeexplore.ieee.org/document/1717463/},
	doi = {10.1109/TPAMI.2006.244},
	abstract = {This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed.},
	language = {en},
	number = {12},
	urldate = {2022-01-31},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ahonen, T. and Hadid, A. and Pietikainen, M.},
	month = dec,
	year = {2006},
	pages = {2037--2041},
	file = {Ahonen et al. - 2006 - Face Description with Local Binary Patterns Appli.pdf:/home/simeon/Zotero/storage/ZVFFP9EL/Ahonen et al. - 2006 - Face Description with Local Binary Patterns Appli.pdf:application/pdf},
}

@article{liu_deep_nodate,
	title = {Deep {Learning} {Face} {Attributes} in the {Wild}},
	abstract = {Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are ﬁnetuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the ﬁlters of LNet are ﬁne-tuned only with imagelevel attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pretraining with massive face identities, and such concepts are signiﬁcantly enriched after ﬁne-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.},
	language = {en},
	author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	pages = {9},
	file = {Liu et al. - Deep Learning Face Attributes in the Wild.pdf:/home/simeon/Zotero/storage/JBH97BTC/Liu et al. - Deep Learning Face Attributes in the Wild.pdf:application/pdf},
}

@article{tang_facial_2018,
	title = {Facial landmark detection by semi-supervised deep learning},
	volume = {297},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231218301139},
	doi = {10.1016/j.neucom.2018.01.080},
	language = {en},
	urldate = {2022-01-31},
	journal = {Neurocomputing},
	author = {Tang, Xin and Guo, Fang and Shen, Jianbing and Du, Tianyuan},
	month = jul,
	year = {2018},
	pages = {22--32},
	file = {Tang et al. - 2018 - Facial landmark detection by semi-supervised deep .pdf:/home/simeon/Zotero/storage/WLPSQSML/Tang et al. - 2018 - Facial landmark detection by semi-supervised deep .pdf:application/pdf;Tang et al. - 2018 - Facial landmark detection by semi-supervised deep .pdf:/home/simeon/Zotero/storage/MRPDK6RK/Tang et al. - 2018 - Facial landmark detection by semi-supervised deep .pdf:application/pdf},
}

@article{wang_deep_2020,
	title = {Deep {High}-{Resolution} {Representation} {Learning} for {Visual} {Recognition}},
	url = {http://arxiv.org/abs/1908.07919},
	abstract = {High-resolution representations are essential for position-sensitive vision problems, such as human pose estimation, semantic segmentation, and object detection. Existing state-of-the-art frameworks ﬁrst encode the input image as a low-resolution representation through a subnetwork that is formed by connecting high-to-low resolution convolutions in series (e.g., ResNet, VGGNet), and then recover the high-resolution representation from the encoded low-resolution representation. Instead, our proposed network, named as High-Resolution Network (HRNet), maintains high-resolution representations through the whole process. There are two key characteristics: (i) Connect the high-to-low resolution convolution streams in parallel; (ii) Repeatedly exchange the information across resolutions. The beneﬁt is that the resulting representation is semantically richer and spatially more precise. We show the superiority of the proposed HRNet in a wide range of applications, including human pose estimation, semantic segmentation, and object detection, suggesting that the HRNet is a stronger backbone for computer vision problems. All the codes are available at https://github.com/HRNet.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:1908.07919 [cs]},
	author = {Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and Liu, Wenyu and Xiao, Bin},
	month = mar,
	year = {2020},
	note = {arXiv: 1908.07919},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: To appear in TPAMI. State-of-the-art performance on human pose estimation, semantic segmentation, object detection, instance segmentation, and face alignment. Full version of arXiv:1904.04514. (arXiv admin note: text overlap with arXiv:1904.04514)},
	file = {Wang et al. - 2020 - Deep High-Resolution Representation Learning for V.pdf:/home/simeon/Zotero/storage/7Q4II6YS/Wang et al. - 2020 - Deep High-Resolution Representation Learning for V.pdf:application/pdf},
}

@article{sun_deep_2019,
	title = {Deep {High}-{Resolution} {Representation} {Learning} for {Human} {Pose} {Estimation}},
	url = {http://arxiv.org/abs/1902.09212},
	abstract = {In this paper, we are interested in the human pose estimation problem with a focus on learning reliable highresolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:1902.09212 [cs]},
	author = {Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.09212},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: accepted by CVPR2019},
	file = {Sun et al. - 2019 - Deep High-Resolution Representation Learning for H.pdf:/home/simeon/Zotero/storage/AYJ8DL4W/Sun et al. - 2019 - Deep High-Resolution Representation Learning for H.pdf:application/pdf},
}

@article{huang_multi-stage_2019,
	title = {Multi-{Stage} {HRNet}: {Multiple} {Stage} {High}-{Resolution} {Network} for {Human} {Pose} {Estimation}},
	shorttitle = {Multi-{Stage} {HRNet}},
	url = {http://arxiv.org/abs/1910.05901},
	abstract = {Human pose estimation are of importance for visual understanding tasks such as action recognition and human-computer interaction. In this work, we present a Multiple Stage High-Resolution Network (Multi-Stage HRNet) to tackling the problem of multi-person pose estimation in images. Specifically, we follow the top-down pipelines and high-resolution representations are maintained during single-person pose estimation. In addition, multiple stage network and cross stage feature aggregation are adopted to further refine the keypoint position. The resulting approach achieves promising results in COCO datasets. Our single-model-single-scale test configuration obtains 77.1 AP score in test-dev using publicly available training data.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:1910.05901 [cs]},
	author = {Huang, Junjie and Zhu, Zheng and Huang, Guan},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.05901},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: technical report},
	file = {Huang et al. - 2019 - Multi-Stage HRNet Multiple Stage High-Resolution .pdf:/home/simeon/Zotero/storage/SNIAFUXM/Huang et al. - 2019 - Multi-Stage HRNet Multiple Stage High-Resolution .pdf:application/pdf},
}

@article{hsu_detailed_2020,
	title = {A {Detailed} {Look} {At} {CNN}-based {Approaches} {In} {Facial} {Landmark} {Detection}},
	url = {http://arxiv.org/abs/2005.08649},
	abstract = {Facial landmark detection has been studied over decades. Numerous neural network (NN)-based approaches have been proposed for detecting landmarks, especially the convolutional neural network (CNN)-based approaches. In general, CNN-based approaches can be divided into regression and heatmap approaches. However, no research systematically studies the characteristics of different approaches. In this paper, we investigate both CNN-based approaches, generalize their advantages and disadvantages, and introduce a variation of the heatmap approach, a pixel-wise classiﬁcation (PWC) model. To the best of our knowledge, using the PWC model to detect facial landmarks have not been comprehensively studied. We further design a hybrid loss function and a discrimination network for strengthening the landmarks’ interrelationship implied in the PWC model to improve the detection accuracy without modifying the original model architecture. Six common facial landmark datasets, AFW, Helen, LFPW, 300-W, IBUG, and COFW are adopted to train or evaluate our model. A comprehensive evaluation is conducted and the result shows that the proposed model outperforms other models in all tested datasets.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2005.08649 [cs, stat]},
	author = {Hsu, Chih-Fan and Lin, Chia-Ching and Hung, Ting-Yang and Lei, Chin-Laung and Chen, Kuan-Ta},
	month = may,
	year = {2020},
	note = {arXiv: 2005.08649},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Hsu et al. - 2020 - A Detailed Look At CNN-based Approaches In Facial .pdf:/home/simeon/Zotero/storage/WLS8ZBYJ/Hsu et al. - 2020 - A Detailed Look At CNN-based Approaches In Facial .pdf:application/pdf},
}

@inproceedings{xiangxin_zhu_face_2012,
	address = {Providence, RI},
	title = {Face detection, pose estimation, and landmark localization in the wild},
	isbn = {978-1-4673-1228-8 978-1-4673-1226-4 978-1-4673-1227-1},
	url = {http://ieeexplore.ieee.org/document/6248014/},
	doi = {10.1109/CVPR.2012.6248014},
	abstract = {We present a uniﬁed model for face detection, pose estimation, and landmark estimation in real-world, cluttered images. Our model is based on a mixtures of trees with a shared pool of parts; we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint. We show that tree-structured models are surprisingly effective at capturing global elastic deformation, while being easy to optimize unlike dense graph structures. We present extensive results on standard face benchmarks, as well as a new “in the wild” annotated dataset, that suggests our system advances the state-of-theart, sometimes considerably, for all three tasks. Though our model is modestly trained with hundreds of faces, it compares favorably to commercial systems trained with billions of examples (such as Google Picasa and face.com).},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {{Xiangxin Zhu} and Ramanan, D.},
	month = jun,
	year = {2012},
	pages = {2879--2886},
	file = {Xiangxin Zhu and Ramanan - 2012 - Face detection, pose estimation, and landmark loca.pdf:/home/simeon/Zotero/storage/U9HR2C4N/Xiangxin Zhu and Ramanan - 2012 - Face detection, pose estimation, and landmark loca.pdf:application/pdf},
}

@inproceedings{vukadinovic_fully_2005,
	address = {Waikoloa, HI, USA},
	title = {Fully {Automatic} {Facial} {Feature} {Point} {Detection} {Using} {Gabor} {Feature} {Based} {Boosted} {Classifiers}},
	volume = {2},
	isbn = {978-0-7803-9298-4},
	url = {http://ieeexplore.ieee.org/document/1571392/},
	doi = {10.1109/ICSMC.2005.1571392},
	abstract = {Locating facial feature points in images of faces is an important stage for numerous facial image interpretation tasks. In this paper we present a method for fully automatic detection of 20 facial feature points in images of expressionless faces using Gabor feature based boosted classifiers. The method adopts fast and robust face detection algorithm, which represents an adapted version of the original Viola-Jones face detector. The detected face region is then divided into 20 relevant regions of interest, each of which is examined further to predict the location of the facial feature points. The proposed facial feature point detection method uses individual feature patch templates to detect points in the relevant region of interest. These feature models are GentleBoost templates built from both gray level intensities and Gabor wavelet features. When tested on the Cohn-Kanade database, the method has achieved average recognition rates of 93\%.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2005 {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	publisher = {IEEE},
	author = {Vukadinovic, D. and Pantic, M.},
	year = {2005},
	pages = {1692--1698},
	file = {Vukadinovic and Pantic - 2005 - Fully Automatic Facial Feature Point Detection Usi.pdf:/home/simeon/Zotero/storage/KCZNWBRR/Vukadinovic and Pantic - 2005 - Fully Automatic Facial Feature Point Detection Usi.pdf:application/pdf},
}

@article{yuille_deformable_1991,
	title = {Deformable {Templates} for {Face} {Recognition}},
	volume = {3},
	issn = {0898-929X, 1530-8898},
	url = {https://direct.mit.edu/jocn/article/3/1/59/3023/Deformable-Templates-for-Face-Recognition},
	doi = {10.1162/jocn.1991.3.1.59},
	abstract = {Abstract
            We describe an approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template. This is a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data. Variations in the parameters correspond to allowable deformations of the object and can be specified by a probabilistic model. After the extraction stage the parameters of the deformable template can be used for object description and recognition.},
	language = {en},
	number = {1},
	urldate = {2022-01-31},
	journal = {Journal of Cognitive Neuroscience},
	author = {Yuille, Alan L.},
	month = jan,
	year = {1991},
	pages = {59--70},
	file = {Yuille - 1991 - Deformable Templates for Face Recognition.pdf:/home/simeon/Zotero/storage/H423NJM3/Yuille - 1991 - Deformable Templates for Face Recognition.pdf:application/pdf},
}

@article{iqtait_feature_2018,
	title = {Feature extraction for face recognition via {Active} {Shape} {Model} ({ASM}) and {Active} {Appearance} {Model} ({AAM})},
	volume = {332},
	issn = {1757-8981, 1757-899X},
	url = {https://iopscience.iop.org/article/10.1088/1757-899X/332/1/012032},
	doi = {10.1088/1757-899X/332/1/012032},
	abstract = {Biometric is a pattern recognition system which is used for automatic recognition of persons based on characteristics and features of an individual. Face recognition with high recognition rate is still a challenging task and usually accomplished in three phases consisting of face detection, feature extraction, and expression classification. Precise and strong location of trait point is a complicated and difficult issue in face recognition. Cootes proposed a Multi Resolution Active Shape Models (ASM) algorithm, which could extract specified shape accurately and efficiently. Furthermore, as the improvement of ASM, Active Appearance Models algorithm (AAM) is proposed to extracts both shape and texture of specified object simultaneously. In this paper we give more details about the two algorithms and give the results of experiments, testing their performance on one dataset of faces. We found that the ASM is faster and gains more accurate trait point location than the AAM, but the AAM gains a better match to the texture.},
	language = {en},
	urldate = {2022-01-31},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Iqtait, M and Mohamad, F S and Mamat, M},
	month = mar,
	year = {2018},
	pages = {012032},
	file = {Iqtait et al. - 2018 - Feature extraction for face recognition via Active.pdf:/home/simeon/Zotero/storage/V653RFAH/Iqtait et al. - 2018 - Feature extraction for face recognition via Active.pdf:application/pdf},
}

@inproceedings{dang_review_2017,
	address = {Noida, India},
	title = {Review and comparison of face detection algorithms},
	isbn = {978-1-5090-3519-9},
	url = {http://ieeexplore.ieee.org/document/7943228/},
	doi = {10.1109/CONFLUENCE.2017.7943228},
	abstract = {With the tremendous increase in video and image database there is a great need of automatic understanding and examination of data by the intelligent systems as manually it is becoming out of reach. Narrowing it down to one specific domain, one of the most specific objects that can be traced in the images are people i.e. faces. Face detection is becoming a challenge by its increasing use in number of applications. It is the first step for face recognition, face analysis and detection of other features of face. In this paper, various face detection algorithms are discussed and analyzed like Viola-Jones, SMQT features \& SNOW Classifier, Neural Network-Based Face Detection and Support Vector Machine-Based face detection. All these face detection methods are compared based on the precision and recall value calculated using a DetEval Software which deals with précised values of the bounding boxes around the faces to give accurate results.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2017 7th {International} {Conference} on {Cloud} {Computing}, {Data} {Science} \& {Engineering} - {Confluence}},
	publisher = {IEEE},
	author = {Dang, Kirti and Sharma, Shanu},
	month = jan,
	year = {2017},
	pages = {629--633},
	file = {Dang and Sharma - 2017 - Review and comparison of face detection algorithms.pdf:/home/simeon/Zotero/storage/KGDHVU8Q/Dang and Sharma - 2017 - Review and comparison of face detection algorithms.pdf:application/pdf},
}

@article{kumar_face_2019,
	title = {Face detection techniques: a review},
	volume = {52},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Face detection techniques},
	url = {http://link.springer.com/10.1007/s10462-018-9650-2},
	doi = {10.1007/s10462-018-9650-2},
	abstract = {With the marvelous increase in video and image database there is an incredible need of automatic understanding and examination of information by the intelligent systems as manually it is getting to be plainly distant. Face plays a major role in social intercourse for conveying identity and feelings of a person. Human beings have not tremendous ability to identify different faces than machines. So, automatic face detection system plays an important role in face recognition, facial expression recognition, head-pose estimation, human–computer interaction etc. Face detection is a computer technology that determines the location and size of a human face in a digital image. Face detection has been a standout amongst topics in the computer vision literature. This paper presents a comprehensive survey of various techniques explored for face detection in digital images. Different challenges and applications of face detection are also presented in this paper. At the end, different standard databases for face detection are also given with their features. Furthermore, we organize special discussions on the practical aspects towards the development of a robust face detection system and conclude this paper with several promising directions for future research.},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {Artificial Intelligence Review},
	author = {Kumar, Ashu and Kaur, Amandeep and Kumar, Munish},
	month = aug,
	year = {2019},
	pages = {927--948},
	file = {Kumar et al. - 2019 - Face detection techniques a review.pdf:/home/simeon/Zotero/storage/U6VI3HN2/Kumar et al. - 2019 - Face detection techniques a review.pdf:application/pdf},
}

@inproceedings{xianghua_fan_system_2012,
	address = {Taiyuan, China},
	title = {The system of face detection based on {OpenCV}},
	isbn = {978-1-4577-2074-1 978-1-4577-2073-4 978-1-4577-2072-7},
	url = {http://ieeexplore.ieee.org/document/6242980/},
	doi = {10.1109/CCDC.2012.6242980},
	abstract = {Face detection technology has widely attracted attention due to its enormous application value and market potential, such as face recognition and video surveillance system. Real-time face detection not only is one part of the automatic face recognition system but also is developing an independent research subject. So, there are many approaches to solve face detection. Here the modified AdaBoost algorithm based on OpenCV is presented, and experiments of real-time face detecting are also given through two methods of timer and dual-thread. The result shows that the method of face detection with dual-thread is simpler, smoother and more precise.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2012 24th {Chinese} {Control} and {Decision} {Conference} ({CCDC})},
	publisher = {IEEE},
	author = {{Xianghua Fan} and {Fuyou Zhang} and {Haixia Wang} and {Xiao Lu}},
	month = may,
	year = {2012},
	pages = {648--651},
	file = {Xianghua Fan et al. - 2012 - The system of face detection based on OpenCV.pdf:/home/simeon/Zotero/storage/UPB2TKYC/Xianghua Fan et al. - 2012 - The system of face detection based on OpenCV.pdf:application/pdf},
}

@article{magan_driver_2022,
	title = {Driver {Drowsiness} {Detection} by {Applying} {Deep} {Learning} {Techniques} to {Sequences} of {Images}},
	volume = {12},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/3/1145},
	doi = {10.3390/app12031145},
	abstract = {This work presents the development of an ADAS (advanced driving assistance system) focused on driver drowsiness detection, whose objective is to alert drivers of their drowsy state to avoid road trafﬁc accidents. In a driving environment, it is necessary that fatigue detection is performed in a non-intrusive way, and that the driver is not bothered with alarms when he or she is not drowsy. Our approach to this open problem uses sequences of images that are 60 s long and are recorded in such a way that the subject’s face is visible. To detect whether the driver shows symptoms of drowsiness or not, two alternative solutions are developed, focusing on the minimization of false positives. The ﬁrst alternative uses a recurrent and convolutional neural network, while the second one uses deep learning techniques to extract numeric features from images, which are introduced into a fuzzy logic-based system afterwards. The accuracy obtained by both systems is similar: around 65\% accuracy over training data, and 60\% accuracy on test data. However, the fuzzy logic-based system stands out because it avoids raising false alarms and reaches a speciﬁcity (proportion of videos in which the driver is not drowsy that are correctly classiﬁed) of 93\%. Although the obtained results do not achieve very satisfactory rates, the proposals presented in this work are promising and can be considered a solid baseline for future works.},
	language = {en},
	number = {3},
	urldate = {2022-01-31},
	journal = {Applied Sciences},
	author = {Magán, Elena and Sesmero, M. Paz and Alonso-Weber, Juan Manuel and Sanchis, Araceli},
	month = jan,
	year = {2022},
	pages = {1145},
	file = {Magán et al. - 2022 - Driver Drowsiness Detection by Applying Deep Learn.pdf:/home/simeon/Zotero/storage/DQ8WXLY3/Magán et al. - 2022 - Driver Drowsiness Detection by Applying Deep Learn.pdf:application/pdf},
}

@article{balasundaram_computer_2020,
	title = {Computer vision based fatigue detection using facial parameters},
	volume = {981},
	issn = {1757-8981, 1757-899X},
	url = {https://iopscience.iop.org/article/10.1088/1757-899X/981/2/022005},
	doi = {10.1088/1757-899X/981/2/022005},
	abstract = {Human face is a clear indicator of the fatigue and tiredness experienced by an individual. There may be many cues that can be derived through the analysis of facial parameters which clearly indicate the tiredness. Most of us feel the fatigue and tiredness but at the same time ignore it due to want of time to complete a task or necessity to complete an important work. However there can be instances when this fatigue may turn fatal. Hence an automated system that can easily predict the fatigue becomes the need of the hour. This work is focussed towards developing an automated application that can detect fatigue by analysing various facial parameters. This work uses Computer Vision and has been implemented using Python programming. The result shows good prediction accuracy when it comes to fatigue prediction using facial parameters.},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Balasundaram, A and Ashokkumar, S and Kothandaraman, D and kora, SeenaNaik and Sudarshan, E and Harshaverdhan, A},
	month = dec,
	year = {2020},
	pages = {022005},
	file = {Balasundaram et al. - 2020 - Computer vision based fatigue detection using faci.pdf:/home/simeon/Zotero/storage/TIB7KTFN/Balasundaram et al. - 2020 - Computer vision based fatigue detection using faci.pdf:application/pdf;Balasundaram et al. - 2020 - Computer vision based fatigue detection using faci.pdf:/home/simeon/Zotero/storage/L47LM3NV/Balasundaram et al. - 2020 - Computer vision based fatigue detection using faci.pdf:application/pdf},
}

@article{zhou_predicting_2021,
	title = {Predicting {Driver} {Fatigue} in {Automated} {Driving} with {Explainability}},
	url = {http://arxiv.org/abs/2103.02162},
	abstract = {Research indicates that monotonous automated driving increases the incidence of fatigued driving. Although many prediction models based on advanced machine learning techniques were proposed to monitor driver fatigue, especially in manual driving, little is known about how these black-box machine learning models work. In this paper, we proposed a combination of eXtreme Gradient Boosting (XGBoost) and SHAP (SHapley Additive exPlanations) to predict driver fatigue with explanations due to their eﬃciency and accuracy. First, in order to obtain the ground truth of driver fatigue, PERCLOS (percentage of eyelid closure over the pupil over time) between 0 and 100 was used as the response variable. Second, we built a driver fatigue regression model using both physiological and behavioral measures with XGBoost and it outperformed other selected machine learning models with 3.847 root-mean-squared error (RMSE), 1.768 mean absolute error (MAE) and 0.996 adjusted R2. Third, we employed SHAP to identify the most important predictor variables and uncovered the black-box XGBoost model by showing the main eﬀects of most important predictor variables globally and explaining individual predictions locally. Such an explainable driver fatigue prediction model oﬀered insights into how to intervene in automated driving when necessary, such as during the takeover transition period from automated driving to manual driving.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2103.02162 [cs, eess]},
	author = {Zhou, Feng and Alsaid, Areen and Blommer, Mike and Curry, Reates and Swaminathan, Radhakrishnan and Kochhar, Dev and Talamonti, Walter and Tijerina, Louis},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.02162},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {Zhou et al. - 2021 - Predicting Driver Fatigue in Automated Driving wit.pdf:/home/simeon/Zotero/storage/J9K7ALAG/Zhou et al. - 2021 - Predicting Driver Fatigue in Automated Driving wit.pdf:application/pdf},
}

@article{yang_unsupervised_2020,
	title = {Unsupervised {Drowsy} {Driving} {Detection} {With} {RFID}},
	volume = {69},
	issn = {0018-9545, 1939-9359},
	url = {https://ieeexplore.ieee.org/document/9096612/},
	doi = {10.1109/TVT.2020.2995835},
	abstract = {With the increasing number of vehicles and trafﬁc accidents, driving safety has become an important factor that affects human daily life. As the primary cause of driving accidents, driving fatigue could be prevented by a sensing and alarm system built in the vehicle. In this paper, we propose an effective, low-cost driving fatigue detection system to sense driver’s nodding movements using commodity RFID. The system measures the phase difference between two RFID tags attached to the back of a hat worn by the driver. To accurately extract nodding features, we propose an effective approach to mitigate the environment noise, the interference caused by surrounding movements, and the cumulative error caused by the frequency hopping offset in FCC-compliant RFID systems. A long shortterm memory (LSTM) autoencoder is utilized to detect nodding movements using calibrated data. The highly accurate detection performance of the proposed system is validated by extensive experiments in various real driving scenarios.},
	language = {en},
	number = {8},
	urldate = {2022-01-31},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Yang, Chao and Wang, Xuyu and Mao, Shiwen},
	month = aug,
	year = {2020},
	pages = {8151--8163},
	file = {Yang et al. - 2020 - Unsupervised Drowsy Driving Detection With RFID.pdf:/home/simeon/Zotero/storage/R3S85IL9/Yang et al. - 2020 - Unsupervised Drowsy Driving Detection With RFID.pdf:application/pdf;Yang et al. - 2020 - Unsupervised Drowsy Driving Detection With RFID.pdf:/home/simeon/Zotero/storage/EQF3AX8H/Yang et al. - 2020 - Unsupervised Drowsy Driving Detection With RFID.pdf:application/pdf},
}

@incollection{kanade_high_2004,
	address = {Berlin, Heidelberg},
	title = {High {Accuracy} {Optical} {Flow} {Estimation} {Based} on a {Theory} for {Warping}},
	volume = {3024},
	isbn = {978-3-540-21981-1 978-3-540-24673-2},
	url = {http://link.springer.com/10.1007/978-3-540-24673-2_3},
	abstract = {We study an energy functional for computing optical ﬂow that combines three assumptions: a brightness constancy assumption, a gradient constancy assumption, and a discontinuity-preserving spatio-temporal smoothness constraint. In order to allow for large displacements, linearisations in the two data terms are strictly avoided. We present a consistent numerical scheme based on two nested ﬁxed point iterations. By proving that this scheme implements a coarse-to-ﬁne warping strategy, we give a theoretical foundation for warping which has been used on a mainly experimental basis so far. Our evaluation demonstrates that the novel method gives signiﬁcantly smaller angular errors than previous techniques for optical ﬂow estimation. We show that it is fairly insensitive to parameter variations, and we demonstrate its excellent robustness under noise.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Computer {Vision} - {ECCV} 2004},
	publisher = {Springer Berlin Heidelberg},
	author = {Brox, Thomas and Bruhn, Andrés and Papenberg, Nils and Weickert, Joachim},
	editor = {Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Pajdla, Tomás and Matas, Jiří},
	year = {2004},
	doi = {10.1007/978-3-540-24673-2_3},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {25--36},
	file = {Brox et al. - 2004 - High Accuracy Optical Flow Estimation Based on a T.pdf:/home/simeon/Zotero/storage/N2CJJSHN/Brox et al. - 2004 - High Accuracy Optical Flow Estimation Based on a T.pdf:application/pdf},
}

@article{abdulnabi_multi-task_2015,
	title = {Multi-task {CNN} {Model} for {Attribute} {Prediction}},
	volume = {17},
	issn = {1520-9210, 1941-0077},
	url = {http://arxiv.org/abs/1601.00400},
	doi = {10.1109/TMM.2015.2477680},
	abstract = {This paper proposes a joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN). We consider learning binary semantic attributes through a multi-task CNN model, where each CNN will predict one binary attribute. The multitask learning allows CNN models to simultaneously share visual knowledge among different attribute categories. Each CNN will generate attribute-speciﬁc feature representations, and then we apply multi-task learning on the features to predict their attributes. In our multi-task framework, we propose a method to decompose the overall model’s parameters into a latent task matrix and combination matrix. Furthermore, under-sampled classiﬁers can leverage shared statistics from other classiﬁers to improve their performance. Natural grouping of attributes is applied such that attributes in the same group are encouraged to share more knowledge. Meanwhile, attributes in different groups will generally compete with each other, and consequently share less knowledge. We show the effectiveness of our method on two popular attribute datasets.},
	language = {en},
	number = {11},
	urldate = {2022-01-31},
	journal = {IEEE Transactions on Multimedia},
	author = {Abdulnabi, Abrar H. and Wang, Gang and Lu, Jiwen and Jia, Kui},
	month = nov,
	year = {2015},
	note = {arXiv: 1601.00400},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {1949--1959},
	annote = {Comment: 11 pages, 3 figures, ieee transaction paper},
	file = {Abdulnabi et al. - 2015 - Multi-task CNN Model for Attribute Prediction.pdf:/home/simeon/Zotero/storage/QHU9ZSNY/Abdulnabi et al. - 2015 - Multi-task CNN Model for Attribute Prediction.pdf:application/pdf},
}

@inproceedings{fikirli_dedection_2015,
	address = {Bodrum, Mugla, Turkey},
	title = {Dedection of eye-blink movements with sensors},
	isbn = {978-1-4673-7765-2},
	url = {http://ieeexplore.ieee.org/document/7374610/},
	doi = {10.1109/TIPTEKNO.2015.7374610},
	language = {tr},
	urldate = {2022-01-31},
	booktitle = {2015 {Medical} {Technologies} {National} {Conference} ({TIPTEKNO})},
	publisher = {IEEE},
	author = {Fikirli, Metin Ayberk and Uzunoglu, Cengiz Polat and Solmaz, Iskender Alkin and Ugur, Mukden},
	month = oct,
	year = {2015},
	pages = {1--3},
	file = {Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:/home/simeon/Zotero/storage/4EUDF75W/Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:application/pdf;Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:/home/simeon/Zotero/storage/3MDGKETW/Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:application/pdf;Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:/home/simeon/Zotero/storage/ZDEPQWAE/Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:application/pdf;Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:/home/simeon/Zotero/storage/W6HFRQ7R/Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:application/pdf;Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:/home/simeon/Zotero/storage/J3R5JRLY/Fikirli et al. - 2015 - Dedection of eye-blink movements with sensors.pdf:application/pdf},
}

@article{kumari_bm_driver_2017,
	title = {Driver {Drowsiness} {Detection} {System} {Using} {Sensors}},
	volume = {6},
	issn = {2722-2616, 2252-8776},
	url = {http://ijict.iaescore.com/index.php/IJICT/article/view/10077},
	doi = {10.11591/ijict.v6i3.pp139-145},
	abstract = {A low-cost and simple distributed sensors model that is particularly suitable for measuring eye blink of the driver, accident and hand position on a steering wheel. These sensors can be used in automotive active safety systems that aim at detecting driver’s fatigue, a major issue to prevent road accidents. The key point of this approach is to design a prototype of sensor units, so that it can serve as platform for integrating different kinds of sensors into the steering wheel. Since the sensors are attached to the steering wheel, therefore they can’t be detached by the driver. It will also detect dangerous stylish driving which may lead to fatal accidents. The major drawback is that the eye blink sensors frame worn by the driver can be removed causing the sensor non-operational. The outcome is that the vibrator attached to eye blink sensor’s frame vibrates if the driver shuts his eyes for approximately 3 seconds and also the LCD displays the respective warning message. The wheel is slowed or stopped depending on the condition. This is accompanied by the vehicle’s owner being notified through the GSM module, so the owner can retrieve the driver’s location, photograph and a list of nearby police stations through an android mobile application. Therefore, driver can be alerted during drowsiness and the owner can be notified simultaneously.},
	language = {en},
	number = {3},
	urldate = {2022-01-31},
	journal = {International Journal of Informatics and Communication Technology (IJ-ICT)},
	author = {Kumari B.M, Kusuma and Sethi, Sampada and Kumar P, Ramakanth and Kumar, Nishant and Shankar, Atulit},
	month = dec,
	year = {2017},
	pages = {139},
	file = {Kumari B.M et al. - 2017 - Driver Drowsiness Detection System Using Sensors.pdf:/home/simeon/Zotero/storage/3EJPNEPM/Kumari B.M et al. - 2017 - Driver Drowsiness Detection System Using Sensors.pdf:application/pdf},
}

@article{lobo_exploring_2020,
	title = {Exploring {Monitoring} {Systems} {Data} for {Driver} {Distraction} and {Drowsiness} {Research}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/14/3836},
	doi = {10.3390/s20143836},
	abstract = {Driver inattention is a major contributor to road crashes. The emerging of new driver monitoring systems represents an opportunity for researchers to explore new data sources to understand driver inattention, even if the technology was not developed with this purpose in mind. This study is based on retrospective data obtained from two driver monitoring systems to study distraction and drowsiness risk factors. The data includes information about the trips performed by 330 drivers and corresponding distraction and drowsiness alerts emitted by the systems. The drivers’ historical travel data allowed deﬁning two groups with diﬀerent mobility patterns (short-distance and long-distance drivers) through a cluster analysis. Then, the impacts of the driver’s proﬁle and trip characteristics (e.g., driving time, average speed, and breaking time and frequency) on inattention were analyzed using ordered probit models. The results show that long-distance drivers, typically associated with professionals, are less prone to distraction and drowsiness than short-distance drivers. The driving time increases the probability of inattention, while the breaking frequency is more important to mitigate inattention than the breaking time. Higher average speeds increase the inattention risk, being associated with road facilities featuring a monotonous driving environment.},
	language = {en},
	number = {14},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Lobo, António and Ferreira, Sara and Couto, António},
	month = jul,
	year = {2020},
	pages = {3836},
	file = {Lobo et al. - 2020 - Exploring Monitoring Systems Data for Driver Distr.pdf:/home/simeon/Zotero/storage/DKQZV2LI/Lobo et al. - 2020 - Exploring Monitoring Systems Data for Driver Distr.pdf:application/pdf},
}

@article{sahayadhas_correction_2021,
	title = {Correction: {Sahayadhas}, {A}., et al. {Detecting} {Driver} {Drowsiness} {Based} on {Sensors}: {A} {Review}. {Sensors} 2012, 12, 16937–16953},
	volume = {21},
	issn = {1424-8220},
	shorttitle = {Correction},
	url = {https://www.mdpi.com/1424-8220/21/2/451},
	doi = {10.3390/s21020451},
	abstract = {The authors wish to make the following corrections to this paper [...]},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Sahayadhas, Arun and Sundaraj, Kenneth and Murugappan, Murugappan},
	month = jan,
	year = {2021},
	pages = {451},
	file = {Sahayadhas et al. - 2021 - Correction Sahayadhas, A., et al. Detecting Drive.pdf:/home/simeon/Zotero/storage/B4K6UZ49/Sahayadhas et al. - 2021 - Correction Sahayadhas, A., et al. Detecting Drive.pdf:application/pdf},
}

@inproceedings{lee_boon_leng_wearable_2015,
	address = {Busan},
	title = {Wearable driver drowsiness detection system based on biomedical and motion sensors},
	isbn = {978-1-4799-8203-5},
	url = {http://ieeexplore.ieee.org/document/7370355/},
	doi = {10.1109/ICSENS.2015.7370355},
	abstract = {Driver drowsiness detection system had been developed as mobile device application such as Percentage of Eye Closure (PERCLOS) measured by using mobile device camera. Nevertheless, the mobile device has the potential risk of distracting the driver’s attention, causing accidents. Thus, a wearable-type drowsiness detection system is proposed to overcome such issue. The proposed system used self-designed wristband consisted of photoplethysmogram sensor and galvanic skin response sensor. The sensors data are sent to the mobile device which served as a main analyzing processing unit. Those data are analyzed along with the motion sensors, which are the mobile device built-in accelerometer and gyroscope sensors. Five features are extracted accordingly based on the received raw sensors data, including heart rate, pulse rate variability, respiratory rate, stress level, and adjustment counter. Those features are further served as computation parameters to a support vector machine to derive the driver drowsiness state. The testing results indicated that the accuracy of the system with SVM model reached up to 98.3\%. In addition, driver will be alerted using graphical and vibration alarm generated by the mobile device. In fact, the integration of driver physical behavior and physiological signals is proven to be an outstanding solution to detect driver drowsiness in a safer, more flexible and portable used.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2015 {IEEE} {SENSORS}},
	publisher = {IEEE},
	author = {{Lee Boon Leng} and {Lee Boon Giin} and {Wan-Young Chung}},
	month = nov,
	year = {2015},
	pages = {1--4},
	file = {Lee Boon Leng et al. - 2015 - Wearable driver drowsiness detection system based .pdf:/home/simeon/Zotero/storage/EC6NA8MT/Lee Boon Leng et al. - 2015 - Wearable driver drowsiness detection system based .pdf:application/pdf},
}

@article{celecia_portable_2020,
	title = {A {Portable} {Fuzzy} {Driver} {Drowsiness} {Estimation} {System}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/15/4093},
	doi = {10.3390/s20154093},
	abstract = {The adequate automatic detection of driver fatigue is a very valuable approach for the prevention of traﬃc accidents. Devices that can determine drowsiness conditions accurately must inherently be portable, adaptable to diﬀerent vehicles and drivers, and robust to conditions such as illumination changes or visual occlusion. With the advent of a new generation of computationally powerful embedded systems such as the Raspberry Pi, a new category of real-time and low-cost portable drowsiness detection systems could become standard tools. Usually, the proposed solutions using this platform are limited to the deﬁnition of thresholds for some deﬁned drowsiness indicator or the application of computationally expensive classiﬁcation models that limits their use in real-time. In this research, we propose the development of a new portable, low-cost, accurate, and robust drowsiness recognition device. The proposed device combines complementary drowsiness measures derived from a temporal window of eyes (PERCLOS, ECD) and mouth (AOT) states through a fuzzy inference system deployed in a Raspberry Pi with the capability of real-time response. The system provides three degrees of drowsiness (Low-Normal State, Medium-Drowsy State, and High-Severe Drowsiness State), and was assessed in terms of its computational performance and eﬃciency, resulting in a signiﬁcant accuracy of 95.5\% in state recognition that demonstrates the feasibility of the approach.},
	language = {en},
	number = {15},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Celecia, Alimed and Figueiredo, Karla and Vellasco, Marley and González, René},
	month = jul,
	year = {2020},
	pages = {4093},
	file = {Celecia et al. - 2020 - A Portable Fuzzy Driver Drowsiness Estimation Syst.pdf:/home/simeon/Zotero/storage/7QX6I335/Celecia et al. - 2020 - A Portable Fuzzy Driver Drowsiness Estimation Syst.pdf:application/pdf},
}

@article{ebrahimbabaie_varnosfaderani_prediction_2017,
	title = {Prediction of level of drowsiness using an adaptive geometric brownian motion model, with application to drowsy driving accident prevention},
	volume = {40},
	issn = {13899457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389945717306809},
	doi = {10.1016/j.sleep.2017.11.247},
	abstract = {Introduction: The PERCLOS (PERcentage CLOSure) for one eye and a given time window of duration T seconds (typically 20) is the total time where the eye is closed more than, say, 80\% with respect to some reference maximum opening, divided by the window length. Since PERCLOS is recognized as an important indicator of drowsiness, several drowsiness monitoring systems, e.g. for drivers, use it as their unique or primary parameter. All these systems compute PERCLOS “now” based upon the (“past”) data in the window, so that an alarm may come too late to prevent an accident. It would thus be useful to predict future values of PERCLOS based upon this past data. Prediction implies having a model of the evolution of a “PERCLOS signal”. Given that the motion of the eyelids e governed by complex physiological phenomena e has a signiﬁcant random part, one must treat each PERCLOS signal as a speciﬁc realization of some (underlying) random process (RP). Predicting future values of PERCLOS then requires having a proper RP model for the time evolution of PERCLOS. Here, we present such a model. Materials and methods: Using a glasses-based system imaging one eye and developed in our group, we obtained PERCLOS signals from 17 healthy subjects who performed psychomotor vigilance tasks (PVTs) at 3 different states of sleep deprivation. Each of these 17x3 ¼ 51 signals consists of 110 samples spaced by 5 seconds. We investigated several RP models to model these realizations, and we found that the Geometric Brownian Motion (GBM) RP model constitutes an excellent choice. RP X(t) is said to be GBM if it satisﬁes the stochastic differential equation dX(t)/X(t) ¼ mdt+sdW(t), where m and s are positive constants and W(t) is a Wiener (random) process also called Brownian Motion. For each realization, we determined whether or not GBM was a good model choice by applying the conventionally applied procedure of verifying that the logarithms of the ratios of successive values are normally distributed and uncorrelated in time.
Results: We found out that each of the above 51 PERCLOS signals passed the above pair of statistical model selection tests, so that GBM is a good model choice for each of these 51 signals.
Conclusions: We found that GBM is a good choice of model for all of our 51 PERCLOS signals. In general, for any signal that can be modelled by a GBM, there are methods (mainly found in ﬁnances) for statistically and usefully predicting its future values. Therefore, for all 51 signals considered, one could do such predictions.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Sleep Medicine},
	author = {Ebrahimbabaie Varnosfaderani, P. and Verly, J.G.},
	month = dec,
	year = {2017},
	pages = {e86},
	file = {Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:/home/simeon/Zotero/storage/J7NZ9TRX/Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:application/pdf;Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:/home/simeon/Zotero/storage/IA8H3N8B/Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:application/pdf;Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:/home/simeon/Zotero/storage/H8CYELH3/Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:application/pdf;Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:/home/simeon/Zotero/storage/IPWYYP72/Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:application/pdf;Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:/home/simeon/Zotero/storage/3YC5HSD4/Ebrahimbabaie Varnosfaderani and Verly - 2017 - Prediction of level of drowsiness using an adaptiv.pdf:application/pdf},
}

@article{forsman_efficient_2013,
	title = {Efficient driver drowsiness detection at moderate levels of drowsiness},
	volume = {50},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457512001571},
	doi = {10.1016/j.aap.2012.05.005},
	language = {en},
	urldate = {2022-01-31},
	journal = {Accident Analysis \& Prevention},
	author = {Forsman, Pia M. and Vila, Bryan J. and Short, Robert A. and Mott, Christopher G. and Van Dongen, Hans P.A.},
	month = jan,
	year = {2013},
	pages = {341--350},
	file = {Forsman et al. - 2013 - Efficient driver drowsiness detection at moderate .pdf:/home/simeon/Zotero/storage/D3QQN8K2/Forsman et al. - 2013 - Efficient driver drowsiness detection at moderate .pdf:application/pdf},
}

@article{khan_passive_2015,
	title = {Passive {BCI} based on drowsiness detection: an {fNIRS} study},
	volume = {6},
	issn = {2156-7085, 2156-7085},
	shorttitle = {Passive {BCI} based on drowsiness detection},
	url = {https://opg.optica.org/abstract.cfm?URI=boe-6-10-4063},
	doi = {10.1364/BOE.6.004063},
	abstract = {We use functional near-infrared spectroscopy (fNIRS) to discriminate the alert and drowsy states for a passive brain-computer interface (BCI). The passive brain signals for the drowsy state are acquired from the prefrontal and dorsolateral prefrontal cortex. The experiment is performed on 13 healthy subjects using a driving simulator, and their brain activity is recorded using a continuous-wave fNIRS system. Linear discriminant analysis (LDA) is employed for training and testing, using the data from the prefrontal, left- and right-dorsolateral prefrontal regions. For classification, eight features are tested: mean oxyhemoglobin, mean deoxyhemoglobin, skewness, kurtosis, signal slope, number of peaks, sum of peaks, and signal peak, in 0{\textasciitilde}5, 0{\textasciitilde}10, and 0{\textasciitilde}15 second time windows, respectively. The results show that the best performance for classification is achieved using mean oxyhemoglobin, the signal peak, and the sum of peaks as features. The average accuracies in the right dorsolateral prefrontal cortex (83.1, 83.4 and 84.9\% in the 0{\textasciitilde}5, 0{\textasciitilde}10 and 0{\textasciitilde}15 second time windows, respectively) show that the proposed method has an effective utility for detection of drowsiness for a passive BCI.},
	language = {en},
	number = {10},
	urldate = {2022-01-31},
	journal = {Biomedical Optics Express},
	author = {Khan, M. Jawad and Hong, Keum-Shik},
	month = oct,
	year = {2015},
	pages = {4063},
	file = {Khan and Hong - 2015 - Passive BCI based on drowsiness detection an fNIR.pdf:/home/simeon/Zotero/storage/SIAZ7JYC/Khan and Hong - 2015 - Passive BCI based on drowsiness detection an fNIR.pdf:application/pdf},
}

@inproceedings{gupta_review_2021,
	address = {Tirunelveli, India},
	title = {Review {Paper} on {Yawning} {Detection} {Prediction} {System} for {Driver} {Drowsiness}},
	isbn = {978-1-66541-571-2},
	url = {https://ieeexplore.ieee.org/document/9453008/},
	doi = {10.1109/ICOEI51242.2021.9453008},
	abstract = {Drowsiness can be dangerous when performing tasks that require constant attention, such as driving a vehicle. Sleepiness is correlated with a variety of physiological variables, such as eye closing, head movements, pulse rate, eye twitch rate, etc. Also, the yawn can be considered as an accurate indicator of drowsiness and fatigue. Yawning detection is very important for the safety purpose of drivers as it will let the driver know if he/she is getting drowsy. Driving at that moment may not be safe. Several automatic yawning detection techniques have been developed for driver’s drowsiness monitoring system. Nevertheless, correctly detecting the yawning of the driver and predicting exhaustion in real-time situations is still a crucial challenge. In this paper, we will be reviewing various existing machine learning approaches for driver’s yawning detection. In previous approaches, various classical machine learning algorithms such as viola-Jones, contour activation algorithm and SVM have been used for yawning detection, but these approaches failed to predict yawning in realtime situations. Using Deep learning techniques, we can make a real-time yawn detection system with high accuracy. We find that some precious Deep learning algorithms like CNN, RNN, LSTM, Bi-LSTM can detect the patterns with high accuracy. After the comparison of various algorithms and techniques, we find that with the help of Deep learning algorithms the yawning can be detected in real time with high accuracy.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 5th {International} {Conference} on {Trends} in {Electronics} and {Informatics} ({ICOEI})},
	publisher = {IEEE},
	author = {Gupta, Nitin Kumar and Bari, Anil Kumar and Kumar, Sanjay and Garg, Deepak and Gupta, Kapil},
	month = jun,
	year = {2021},
	pages = {1--6},
	file = {Gupta et al. - 2021 - Review Paper on Yawning Detection Prediction Syste.pdf:/home/simeon/Zotero/storage/PZCF2ZM9/Gupta et al. - 2021 - Review Paper on Yawning Detection Prediction Syste.pdf:application/pdf},
}

@inproceedings{hirata_detection_2009,
	address = {Minneapolis, MN},
	title = {Detection and prediction of drowsiness by reflexive eye movements},
	url = {http://ieeexplore.ieee.org/document/5333504/},
	doi = {10.1109/IEMBS.2009.5333504},
	abstract = {A reliable predictor of drowsiness using objective measures is desirable for machine and vehicle operations in which human errors may cause fatal accidents. We have evaluated the Vestibulo-Ocular Reflex (VOR) as a possible predictor of drowsiness. The VOR is a compensatory eye movement that stabilizes retinal image during head motion, and is inevitably induced by vibration in a car running on the road. We employed an uneventful driving simulation (DS) featuring vibration stimulation to induce both drowsiness and VOR in healthy human subjects. VOR performance was characterized by its gain and variability, and evaluated in relation to the subjects’ drowsiness. A significant decrease in VOR gain and increase in variability accompanied subjective sleepiness, with the changes occurring before subjects became aware of sleepiness. From this finding, we developed a reliable method (88.9\% accuracy) to predict oncoming sleepiness using changes in VOR performance as a cue.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2009 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	publisher = {IEEE},
	author = {Hirata, Y. and Nishiyama, J. and Kinoshita, S.},
	month = sep,
	year = {2009},
	pages = {4015--4018},
	file = {Hirata et al. - 2009 - Detection and prediction of drowsiness by reflexiv.pdf:/home/simeon/Zotero/storage/RFRN635X/Hirata et al. - 2009 - Detection and prediction of drowsiness by reflexiv.pdf:application/pdf},
}

@inproceedings{dehzangi_unobtrusive_2018,
	address = {Beijing},
	title = {Unobtrusive {Driver} {Drowsiness} {Prediction} {Using} {Driving} {Behavior} from {Vehicular} {Sensors}},
	isbn = {978-1-5386-3788-3},
	url = {https://ieeexplore.ieee.org/document/8545427/},
	doi = {10.1109/ICPR.2018.8545427},
	abstract = {Falling asleep is an eventual result of drowsiness, while driving it might also be a cause of major disasters. Driver s oblivious attempt of driving a vehicle when they are drowsy will lead to life-threatening accidents and even fatality. In this paper, we developed a framework to capture the drowsiness state of the driver using vehicle measures in an unobtrusive way. A well experimented VR-based simulated driving environment was employed to monitor the driver s drowsiness based on the acceleration, braking, and steering wheel axis pattern of the vehicle, in tandem with the self-estimated rating from the subject using KSS (Karolinska Sleepiness Scale). We proposed two prediction models to accomplish the drowsiness detection. We used the Classiﬁcation as well the Regression techniques which produced a maximum accuracy rate of 99.10\% and a minimum error rate of 0.34 RMSE. It was evaluated, based on its performance through the Ensemble classiﬁer and Decision-Tree algorithms. As a result, it is identiﬁed that a system built using the Decision-Tree with the proposed segmentation of 4 sec window, could determine the driver s drowsiness at the earliest of 4.4 sec in the Classiﬁcation and 4.5 sec with Regression, respectively.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2018 24th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Dehzangi, Omid and Masilamani, Selvamani},
	month = aug,
	year = {2018},
	pages = {3598--3603},
	file = {Dehzangi and Masilamani - 2018 - Unobtrusive Driver Drowsiness Prediction Using Dri.pdf:/home/simeon/Zotero/storage/2YVQU8T5/Dehzangi and Masilamani - 2018 - Unobtrusive Driver Drowsiness Prediction Using Dri.pdf:application/pdf},
}

@inproceedings{sinha_drowsiness_2021,
	address = {Chennai, India},
	title = {Drowsiness {Detection} {System} {Using} {Deep} {Learning}},
	isbn = {978-1-66544-126-1},
	url = {https://ieeexplore.ieee.org/document/9445132/},
	doi = {10.1109/ICBSII51839.2021.9445132},
	abstract = {Drivers drowsiness is the major problem that causes road accidents. Unlike normal facial expression, drowsiness is defined to be a condition of exhaustion, where the expression of the face is different from usual. The important steps in detecting drowsiness are face detection and expression detection. Many algorithms are being developed to detect face and expressions. But these algorithms give poor performance due to the extrinsic parameters of the environment. Light and position of the camera are the major problems. In this paper, different architectures were used to analyse the performance of face and drowsiness detection. Also we have proposed new detection methods using deep learning techniques. To estimate the drivers’ state we use facial regions corresponding to the entire face. The algorithms employed for face detection are i) Viola Jones ii) DLib iii) Yolo V3. For the Classification , The CNN (Convolutional Neural Network) architecture employed in the drowsiness detection is modified LeNet .},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {Seventh} {International} conference on {Bio} {Signals}, {Images}, and {Instrumentation} ({ICBSII})},
	publisher = {IEEE},
	author = {Sinha, Avigyan and Aneesh, R P and Gopal, Sarada K},
	month = mar,
	year = {2021},
	pages = {1--6},
	file = {Sinha et al. - 2021 - Drowsiness Detection System Using Deep Learning.pdf:/home/simeon/Zotero/storage/CZ8EUQW9/Sinha et al. - 2021 - Drowsiness Detection System Using Deep Learning.pdf:application/pdf},
}

@inproceedings{dewi_purnamasari_heart_2018,
	address = {Semarang},
	title = {Heart {Beat} {Based} {Drowsiness} {Detection} {System} for {Driver}},
	isbn = {978-1-5386-7486-4},
	url = {https://ieeexplore.ieee.org/document/8549786/},
	doi = {10.1109/ISEMANTIC.2018.8549786},
	abstract = {Most traffic accidents are caused by negligence of the driver in managing rest time when driving; driver was sleepy and so could not control the vehicle. Therefore, it is necessary to have a device that can detect sleepiness and warn the driver beforehand so that the driver can avoid the accident. The development of this drowsiness detection system is using the heartbeat as a source of data to be retrieved using Photoplethysmography sensor. The system then classifies and determines the drowsiness level of the driver based on his/her heartbeat. This system uses Arduino Nano and Odroid XU4 as the processing unit and has LCD to display the output. The developed system has the success rate up to 96.52\%. From this work, it has been proven that a person's sleep condition will affect the heart rate.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2018 {International} {Seminar} on {Application} for {Technology} of {Information} and {Communication}},
	publisher = {IEEE},
	author = {Dewi Purnamasari, Prima and Zul Hazmi, Aziz},
	month = sep,
	year = {2018},
	pages = {585--590},
	file = {Dewi Purnamasari and Zul Hazmi - 2018 - Heart Beat Based Drowsiness Detection System for D.pdf:/home/simeon/Zotero/storage/MMPSQ9YA/Dewi Purnamasari and Zul Hazmi - 2018 - Heart Beat Based Drowsiness Detection System for D.pdf:application/pdf},
}

@inproceedings{sone_drowsiness_2013,
	address = {Amphur Muang, Krabi, Thailand},
	title = {Drowsiness detection by skin potential activity},
	isbn = {978-1-4799-1467-8 978-1-4799-1466-1},
	url = {http://ieeexplore.ieee.org/document/6687699/},
	doi = {10.1109/BMEiCon.2013.6687699},
	abstract = {Conventional drowsiness detection devices are usually equipped with infrared LEDs and CCD cameras; however, they are adversely affected by factors such as ambient light and the use of eyewear. Drowsiness detection by other methods would thus improve such devices. This study examines skin potential activity, which is not affected by the aforementioned factors. Response performance during monotonous work using visual stimuli was quantified as drowsiness and compared with skin potential activity.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {The 6th 2013 {Biomedical} {Engineering} {International} {Conference}},
	publisher = {IEEE},
	author = {Sone, Takuma and Yagi, Tohru},
	month = oct,
	year = {2013},
	pages = {1--5},
	file = {Sone and Yagi - 2013 - Drowsiness detection by skin potential activity.pdf:/home/simeon/Zotero/storage/QADDPIMK/Sone and Yagi - 2013 - Drowsiness detection by skin potential activity.pdf:application/pdf},
}

@inproceedings{tateno_development_2018,
	address = {Nara},
	title = {Development of {Drowsiness} {Detection} {System} {Based} on {Respiration} {Changes} {Using} {Heart} {Rate} {Monitoring}},
	isbn = {978-4-907764-60-9},
	url = {https://ieeexplore.ieee.org/document/8492599/},
	doi = {10.23919/SICE.2018.8492599},
	urldate = {2022-01-31},
	booktitle = {2018 57th {Annual} {Conference} of the {Society} of {Instrument} and {Control} {Engineers} of {Japan} ({SICE})},
	publisher = {IEEE},
	author = {Tateno, Shigeyuki and Guan, Xia and Cao, Rui and Qu, Zhaoxian},
	month = sep,
	year = {2018},
	pages = {1664--1669},
	file = {Tateno et al. - 2018 - Development of Drowsiness Detection System Based o.pdf:/home/simeon/Zotero/storage/L9TU2ZC8/Tateno et al. - 2018 - Development of Drowsiness Detection System Based o.pdf:application/pdf},
}

@inproceedings{brulin_multi-sensors_2010,
	address = {Corfu, Greece},
	title = {Multi-sensors data fusion system for fall detection},
	isbn = {978-1-4244-6559-0},
	url = {http://ieeexplore.ieee.org/document/5687712/},
	doi = {10.1109/ITAB.2010.5687712},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Proceedings of the 10th {IEEE} {International} {Conference} on {Information} {Technology} and {Applications} in {Biomedicine}},
	publisher = {IEEE},
	author = {Brulin, Damien and Courtial, Estelle},
	month = nov,
	year = {2010},
	pages = {1--4},
	file = {Brulin and Courtial - 2010 - Multi-sensors data fusion system for fall detectio.pdf:/home/simeon/Zotero/storage/N7LTP7S8/Brulin and Courtial - 2010 - Multi-sensors data fusion system for fall detectio.pdf:application/pdf},
}

@inproceedings{chen_band-pass_2018,
	address = {Las Vegas, NV},
	title = {A band-pass {IR} light photodetector for wearable intelligent glasses in a drowsiness-fatigue-detection system},
	isbn = {978-1-5386-3025-9},
	url = {http://ieeexplore.ieee.org/document/8326352/},
	doi = {10.1109/ICCE.2018.8326352},
	abstract = {This paper proposes a band-pass infrared (IR) light photodetector, which is applied to our developed wearable intelligent glasses in a drowsiness-fatigue-detection (DFD) system. The proposed band-pass IR photodetector is designed to detect IR light in the wavelength range from about 810 to 890nm. The benefits of the proposed band-pass infrared photodetector are to provide higher SNR, decrease the ambient environmental light image to a minimum, and effectively enhance detection accuracy. As a result, the recognition algorithm is easier to be implemented and mounted on the light-weight version wearable intelligent glasses with high detection accurate rate.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2018 {IEEE} {International} {Conference} on {Consumer} {Electronics} ({ICCE})},
	publisher = {IEEE},
	author = {Chen, Liang-Bi and Chang, Wan-Jung and Hu, Wei-Wen and Wang, Chun-Kai and Lee, Da-Huei and Chiou, Yu-Zung},
	month = jan,
	year = {2018},
	pages = {1--2},
	file = {Chen et al. - 2018 - A band-pass IR light photodetector for wearable in.pdf:/home/simeon/Zotero/storage/NQVFSHJS/Chen et al. - 2018 - A band-pass IR light photodetector for wearable in.pdf:application/pdf},
}

@inproceedings{lemkaddem_multi-modal_2018,
	address = {Las Vegas, NV, USA},
	title = {Multi-modal driver drowsiness detection: {A} feasibility study},
	isbn = {978-1-5386-2405-0},
	shorttitle = {Multi-modal driver drowsiness detection},
	url = {http://ieeexplore.ieee.org/document/8333357/},
	doi = {10.1109/BHI.2018.8333357},
	abstract = {Driver drowsiness is a significant contributing factor to road accidents and can lead to severe physical injuries, deaths, and significant economic losses. Earlier research primarily concentrated on estimating the level of drowsiness using a single measure such as lane or steering monitoring, behavioral measures or physiological ones. Hybrid systems employing multiple measures provide more reliable solutions because they minimize the number of false alarms and maintain a high recognition rate, which promote their acceptance. In this paper, we present an unobtrusive system that combines a dashboard-mount camera alongside with a watch-like wearable system recording optical (PPG) signals. Statistical analysis performed on 17 subjects demonstrates that our hybrid drowsiness detection system, which leverages both physiological and behavioral measures can reliably determine the drowsiness level with an accuracy ranging from 86\% to 96\% depending on the number of levels and the classification method used.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2018 {IEEE} {EMBS} {International} {Conference} on {Biomedical} \& {Health} {Informatics} ({BHI})},
	publisher = {IEEE},
	author = {Lemkaddem, A. and Delgado-Gonzalo, R. and Turetken, E. and Dasen, S. and Moser, V. and Gressum, C. and Sola, J. and Ferrario, D. and Verjus, C.},
	month = mar,
	year = {2018},
	pages = {9--12},
	file = {Lemkaddem et al. - 2018 - Multi-modal driver drowsiness detection A feasibi.pdf:/home/simeon/Zotero/storage/LKLJH43E/Lemkaddem et al. - 2018 - Multi-modal driver drowsiness detection A feasibi.pdf:application/pdf},
}

@article{kolpe_drowsiness_2020,
	title = {Drowsiness {Detection} and {Warning} {System} {Using} {Python}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3645864},
	doi = {10.2139/ssrn.3645864},
	abstract = {Now-a-days, road accidents have become one of the major issue. The major road accidents are caused due to drowsiness, drunken and rash driving. This is the reason, every year the number of road accidents is increasing especially by cars. Due to drowsiness, drivers become less active while driving. This paper represents to build a system for Drowsiness detection and Warning for automobile safety and accident prevention. We are using eye detection, drowsiness detection and eye blinking pattern detection with the help of machine vision-based concepts. In order to detect fatigue or drowsiness, webcamera has been used which points directly towards the driver’s face and detects the eye movement of the driver.},
	language = {en},
	urldate = {2022-01-31},
	journal = {SSRN Electronic Journal},
	author = {Kolpe, Pratiksha and Kadam, Pratibha and Mashayak, Usama},
	year = {2020},
	file = {Kolpe et al. - 2020 - Drowsiness Detection and Warning System Using Pyth.pdf:/home/simeon/Zotero/storage/4Q3ER3PM/Kolpe et al. - 2020 - Drowsiness Detection and Warning System Using Pyth.pdf:application/pdf},
}

@article{student_btech_computer_science_engineering_course_in_srm_institue_of_science_and_technology_drowsiness_2020,
	title = {Drowsiness {Detection} {System}},
	volume = {9},
	issn = {22498958},
	url = {https://www.ijeat.org/wp-content/uploads/papers/v9i4/D8489049420.pdf},
	doi = {10.35940/ijeat.D8489.049420},
	abstract = {Melbourne is one of the liveliest cities in the world. It has a well efficient transport system, supported by a vast network of trams. Therefore, the mental health and stress level of the tram drivers plays a crucial role in the safety of the passengers. The issue of fatigue and drowsiness in the tram drivers are mostly due to their work-time and the most common thing is that the drowsiness occurs during the work time itself. This drowsiness is a risk for everyone including those who are not travelling in the tram. The current system that is used to prevent the drivers from falling sleeping is called the deadlock system. In this system the driver keeps his foot on a pedal at all times. Whenever the driver lifts his foot from the pedal the tram stops moving. Considering the technologies that are currently implemented in the vehicles seems to be insufficient. More over the driver gets uncomfortable when he keeps his foot onto the lever for a long time during long working hours. We have used OpenCV in python to create a program which monitors the eyes of a person and ensures that they keep the eyes open. The developed algorithm uses python libraries to detect any abnormality in the time interval between blinks and the extent of openness of the driver’s eyes. When an abnormality is detected the driver receives an alarm on his phone indicating driver drowsiness.},
	language = {en},
	number = {4},
	urldate = {2022-01-31},
	journal = {International Journal of Engineering and Advanced Technology},
	author = {{Student, B.Tech, Computer Science Engineering course in SRM Institue of Science and Technology} and S, Suriya Kumar and R, Kishor and {Student, B.Tech, Computer Science Engineering course in SRM Institue of Science and Technology} and Kalaivani, J. and {Assistant Professor in the Department of Computer Science and Engineering from SRM Institute of Science and Technology}},
	month = apr,
	year = {2020},
	pages = {1341--1343},
	file = {Student, B.Tech, Computer Science Engineering course in SRM Institue of Science and Technology et al. - 2020 - Drowsiness Detection System.pdf:/home/simeon/Zotero/storage/UM7AR2JF/Student, B.Tech, Computer Science Engineering course in SRM Institue of Science and Technology et al. - 2020 - Drowsiness Detection System.pdf:application/pdf},
}

@article{dong_towards_2014,
	title = {Towards {Whole} {Body} {Fatigue} {Assessment} of {Human} {Movement}: {A} {Fatigue}-{Tracking} {System} {Based} on {Combined} {sEMG} and {Accelerometer} {Signals}},
	volume = {14},
	issn = {1424-8220},
	shorttitle = {Towards {Whole} {Body} {Fatigue} {Assessment} of {Human} {Movement}},
	url = {http://www.mdpi.com/1424-8220/14/2/2052},
	doi = {10.3390/s140202052},
	abstract = {This paper proposes a method to assess the overall fatigue of human body movement. First of all, according to previous research regarding localized muscular fatigue, a linear relation is assumed between the mean frequency and the muscular working time when the muscle is experiencing fatigue. This assumption is verified with a rigorous statistical analysis. Based on this proven linearity, localized muscular fatigue is simplified as a linear model. Furthermore, localized muscular fatigue is considered a dynamic process and, hence, the localized fatigue levels are tracked by updating the parameters with the most current surface electromyogram (sEMG) measurements. Finally, an overall fatigue level is computed by fusing localized muscular fatigue levels. The developed fatigue-tracking system is evaluated with two fatigue experiments (in which 10 male subjects and seven female subjects participated), including holding self-weight (dip start position training) and lifting weight with one arm (arm curl training).},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Dong, Haiwei and Ugalde, Izaskun and Figueroa, Nadia and El Saddik, Abdulmotaleb},
	month = jan,
	year = {2014},
	pages = {2052--2070},
	file = {Dong et al. - 2014 - Towards Whole Body Fatigue Assessment of Human Mov.pdf:/home/simeon/Zotero/storage/V4A994NW/Dong et al. - 2014 - Towards Whole Body Fatigue Assessment of Human Mov.pdf:application/pdf},
}

@inproceedings{doudou_performance_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Performance {Specifications} of {Market} {Physiological} {Sensors} for {Efficient} {Driver} {Drowsiness} {Detection} {System}:},
	isbn = {978-989-758-284-4},
	shorttitle = {Performance {Specifications} of {Market} {Physiological} {Sensors} for {Efficient} {Driver} {Drowsiness} {Detection} {System}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006607800990106},
	doi = {10.5220/0006607800990106},
	abstract = {Driver Fatigue, Drowsiness Detection, Measurement, Sensors, Physiological Signals.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Sensor} {Networks}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Doudou, Messaoud and Bouabdallah, Abdelmadjid},
	year = {2018},
	pages = {99--106},
	file = {Doudou and Bouabdallah - 2018 - Performance Specifications of Market Physiological.pdf:/home/simeon/Zotero/storage/5EVSREIV/Doudou and Bouabdallah - 2018 - Performance Specifications of Market Physiological.pdf:application/pdf},
}

@article{massaroni_contactless_2021,
	title = {Contactless {Methods} {For} {Measuring} {Respiratory} {Rate}: {A} {Review}},
	volume = {21},
	issn = {1530-437X, 1558-1748, 2379-9153},
	shorttitle = {Contactless {Methods} {For} {Measuring} {Respiratory} {Rate}},
	url = {https://ieeexplore.ieee.org/document/9194745/},
	doi = {10.1109/JSEN.2020.3023486},
	abstract = {Recent advances in understanding the importance of respiratory frequency (fR) as a sensitive marker of a variety of physiopathological stressors are fostering growing interest in respiratory monitoring. This interest is further stimulated by the everincreasing efforts that companies are devoting to the development of systems measuring fR. There are a variety of techniques based on different sensors and technologies for fR monitoring. These techniques are commonly classiﬁed as contact-based or contactless, depending on whether the system which embeds the sensor is in contact with the body or not. This review is focused on the contactless methods for fR monitoring. We have introduced the main ﬁelds of use where contactless respiratory monitoring is important and provided a taxonomy to classify the most popular contactless techniques for fR monitoring. Finally, we have described the performances of the most popular methods, the main open challenges, and the main perspectives.},
	language = {en},
	number = {11},
	urldate = {2022-01-31},
	journal = {IEEE Sensors Journal},
	author = {Massaroni, Carlo and Nicolo, Andrea and Sacchetti, Massimo and Schena, Emiliano},
	month = jun,
	year = {2021},
	pages = {12821--12839},
	file = {Massaroni et al. - 2021 - Contactless Methods For Measuring Respiratory Rate.pdf:/home/simeon/Zotero/storage/IPXYCRA5/Massaroni et al. - 2021 - Contactless Methods For Measuring Respiratory Rate.pdf:application/pdf},
}

@inproceedings{du_apnearadar_2017,
	address = {Shenzhen},
	title = {{ApneaRadar}: {A} {24GHz} {Radar}-{Based} {Contactless} {Sleep} {Apnea} {Detection} {System}},
	isbn = {978-1-5090-4860-1},
	shorttitle = {{ApneaRadar}},
	url = {http://ieeexplore.ieee.org/document/8210539/},
	doi = {10.1109/ICFST.2017.8210539},
	abstract = {Sleep apnea is a serious sleep disorder which results in a large number of health problems and fatal diseases. Existing sleep apnea detection systems require the users to wear several sensors during sleep which is uncomfortable and interruptive to user's sleep. In this paper, we propose ApneaRadar, a contactless sleep monitoring system to detect sleep apnea in real time using a commercial off-the-shelf 24GHz radar. The proposed ApneaRadar system is able to capture the movement of the user's chest therefore to achieve the breathing pattern during sleep. We also proposed an algorithm to detect the sleep apnea based on the breathing pattern in real time. We implemented the ApneaRadar system and conducted a series of more than 100-hour experiment in volunteers who wear the Polysomnography (PSG) meanwhile as the ground truth. The experimental results show that our proposed system achieves over 90\% accuracy in apnea detection compared with PSG.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2017 2nd {International} {Conference} on {Frontiers} of {Sensors} {Technologies} ({ICFST})},
	publisher = {IEEE},
	author = {Du, Na and Liu, Kewen and Ge, Linfei and Zhang, Jin},
	month = apr,
	year = {2017},
	pages = {372--376},
	file = {Du et al. - 2017 - ApneaRadar A 24GHz Radar-Based Contactless Sleep .pdf:/home/simeon/Zotero/storage/KKQPIW87/Du et al. - 2017 - ApneaRadar A 24GHz Radar-Based Contactless Sleep .pdf:application/pdf},
}

@article{al-mulla_review_2011,
	title = {A {Review} of {Non}-{Invasive} {Techniques} to {Detect} and {Predict} {Localised} {Muscle} {Fatigue}},
	volume = {11},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/11/4/3545},
	doi = {10.3390/s110403545},
	abstract = {Muscle fatigue is an established area of research and various types of muscle fatigue have been investigated in order to fully understand the condition. This paper gives an overview of the various non-invasive techniques available for use in automated fatigue detection, such as mechanomyography, electromyography, near-infrared spectroscopy and ultrasound for both isometric and non-isometric contractions. Various signal analysis methods are compared by illustrating their applicability in real-time settings. This paper will be of interest to researchers who wish to select the most appropriate methodology for research on muscle fatigue detection or prediction, or for the development of devices that can be used in, e.g., sports scenarios to improve performance or prevent injury. To date, research on localised muscle fatigue focuses mainly on the clinical side. There is very little research carried out on the implementation of detecting/predicting fatigue using an autonomous system, although recent research on automating the process of localised muscle fatigue detection/prediction shows promising results.},
	language = {en},
	number = {4},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Al-Mulla, Mohamed R. and Sepulveda, Francisco and Colley, Martin},
	month = mar,
	year = {2011},
	pages = {3545--3594},
	file = {Al-Mulla et al. - 2011 - A Review of Non-Invasive Techniques to Detect and .pdf:/home/simeon/Zotero/storage/BDAKVFY7/Al-Mulla et al. - 2011 - A Review of Non-Invasive Techniques to Detect and .pdf:application/pdf},
}

@article{zito_soc_2011,
	title = {{SoC} {CMOS} {UWB} {Pulse} {Radar} {Sensor} for {Contactless} {Respiratory} {Rate} {Monitoring}},
	volume = {5},
	issn = {1932-4545, 1940-9990},
	url = {http://ieeexplore.ieee.org/document/6104396/},
	doi = {10.1109/TBCAS.2011.2176937},
	abstract = {An ultra wideband (UWB) system-on-chip radar sensor for respiratory rate monitoring has been realized in 90 nm CMOS technology and characterized experimentally. The radar testchip has been applied to the contactless detection of the respiration activity of adult and baby. The ﬁeld operational tests demonstrate that the UWB radar sensor detects the respiratory rate of person under test (adult and baby) associated with sub-centimeter chest movements, allowing the continuous-time non-invasive monitoring of hospital patients and other people at risk of obstructive apneas such as babies in cot beds, or other respiratory diseases.},
	language = {en},
	number = {6},
	urldate = {2022-01-31},
	journal = {IEEE Transactions on Biomedical Circuits and Systems},
	author = {Zito, Domenico and Pepe, Domenico and Mincica, Martina and Zito, Fabio and Tognetti, Alessandro and Lanata, Antonio and De Rossi, Danilo},
	month = dec,
	year = {2011},
	pages = {503--510},
	file = {Zito et al. - 2011 - SoC CMOS UWB Pulse Radar Sensor for Contactless Re.pdf:/home/simeon/Zotero/storage/NB6UJWDQ/Zito et al. - 2011 - SoC CMOS UWB Pulse Radar Sensor for Contactless Re.pdf:application/pdf},
}

@inproceedings{irani_contactless_2014,
	address = {Paris, France},
	title = {Contactless measurement of muscles fatigue by tracking facial feature points in a video},
	isbn = {978-1-4799-5751-4},
	url = {http://ieeexplore.ieee.org/document/7025849/},
	doi = {10.1109/ICIP.2014.7025849},
	abstract = {Physical exercise may result in muscle tiredness which is known as muscle fatigue. This occurs when the muscles cannot exert normal force, or when more than normal effort is required. Fatigue is a vital sign, for example, for therapists to assess their patient’s progress or to change their exercises when the level of the fatigue might be dangerous for the patients. The current technology for measuring tiredness, like Electromyography (EMG), requires installing some sensors on the body. In some applications, like remote patient monitoring, this however might not be possible. To deal with such cases, in this paper we present a contactless method based on computer vision techniques to measure tiredness by detecting, tracking, and analyzing some facial feature points during the exercise. Experimental results on several test subjects and comparing them against ground truth data show that the proposed system can properly find the temporal point of tiredness of the muscles when the test subjects are doing physical exercises.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Irani, Ramin and Nasrollahi, Kamal and Moeslund, Thomas B.},
	month = oct,
	year = {2014},
	pages = {4181--4185},
	file = {Irani et al. - 2014 - Contactless measurement of muscles fatigue by trac.pdf:/home/simeon/Zotero/storage/8RRZME62/Irani et al. - 2014 - Contactless measurement of muscles fatigue by trac.pdf:application/pdf},
}

@inproceedings{murawski_contactless_2013,
	address = {Baltimore, MD, USA},
	title = {The contactless active optical sensor for vehicle driver fatigue detection},
	isbn = {978-1-4673-4642-9},
	url = {http://ieeexplore.ieee.org/document/6688139/},
	doi = {10.1109/ICSENS.2013.6688139},
	abstract = {In this paper we present the contactless active optical sensor for driver fatigue detection in variable weather and lighting conditions. The fatigue was determined by monitoring activity of the eyes. In our case the bright pupil effect was used. The brightness of the pupil was increased by developing a new keying technique of controlling the IR emitter signal. This technique caused the brightness to increase in comparison to the continuous signal by 50\%on average. The new developed sensor, as well as, the image processing algorithm was used during the construction of the driver fatigue monitoring system. The system detects fatigue by analyzing the variability of the following signals: PERCLOSE, PEROPEN, blink frequency, activity of the eyes and pupil diameter.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2013 {IEEE} {SENSORS}},
	publisher = {IEEE},
	author = {Murawski, K. and Sondej, T. and Rozanowski, K. and Truszczynski, O. and Macander, M. and Macander, L.},
	month = nov,
	year = {2013},
	pages = {1--4},
	file = {Murawski et al. - 2013 - The contactless active optical sensor for vehicle .pdf:/home/simeon/Zotero/storage/CYC44Y2B/Murawski et al. - 2013 - The contactless active optical sensor for vehicle .pdf:application/pdf},
}

@inproceedings{ibrahim_vehicle_2021,
	address = {Rome, Italy},
	title = {Vehicle {In}-{Cabin} {Contactless} {WiFi} {Human} {Sensing}},
	isbn = {978-1-66544-108-7},
	url = {https://ieeexplore.ieee.org/document/9491580/},
	doi = {10.1109/SECON52354.2021.9491580},
	abstract = {We demonstrate in-cabin WiFi-based sensing in a real vehicle, tracking a passengers breathing rate in real-time.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 18th {Annual} {IEEE} {International} {Conference} on {Sensing}, {Communication}, and {Networking} ({SECON})},
	publisher = {IEEE},
	author = {Ibrahim, Mohammed and Brown, Kenneth N.},
	month = jul,
	year = {2021},
	pages = {1--2},
	file = {Ibrahim and Brown - 2021 - Vehicle In-Cabin Contactless WiFi Human Sensing.pdf:/home/simeon/Zotero/storage/4RTJVKVW/Ibrahim and Brown - 2021 - Vehicle In-Cabin Contactless WiFi Human Sensing.pdf:application/pdf},
}

@article{abbas_driver_2020,
	title = {Driver {Fatigue} {Detection} {Systems} {Using} {Multi}-{Sensors}, {Smartphone}, and {Cloud}-{Based} {Computing} {Platforms}: {A} {Comparative} {Analysis}},
	volume = {21},
	issn = {1424-8220},
	shorttitle = {Driver {Fatigue} {Detection} {Systems} {Using} {Multi}-{Sensors}, {Smartphone}, and {Cloud}-{Based} {Computing} {Platforms}},
	url = {https://www.mdpi.com/1424-8220/21/1/56},
	doi = {10.3390/s21010056},
	abstract = {Internet of things (IoT) cloud-based applications deliver advanced solutions for smart cities to decrease trafﬁc accidents caused by driver fatigue while driving on the road. Environmental conditions or driver behavior can ultimately lead to serious roadside accidents. In recent years, the authors have developed many low-cost, computerized, driver fatigue detection systems (DFDs) to help drivers, by using multi-sensors, and mobile and cloud-based computing architecture. To promote safe driving, these are the most current emerging platforms that were introduced in the past. In this paper, we reviewed state-of-the-art approaches for predicting unsafe driving styles using three common IoT-based architectures. The novelty of this article is to show major differences among multisensors, smartphone-based, and cloud-based architectures in multimodal feature processing. We discussed all of the problems that machine learning techniques faced in recent years, particularly the deep learning (DL) model, to predict driver hypovigilance, especially in terms of these three IoT-based architectures. Moreover, we performed state-of-the-art comparisons by using driving simulators to incorporate multimodal features of the driver. We also mention online data sources in this article to test and train network architecture in the ﬁeld of DFDs on public available multimodal datasets. These comparisons assist other authors to continue future research in this domain. To evaluate the performance, we mention the major problems in these three architectures to help researchers use the best IoT-based architecture for detecting DFDs in a real-time environment. Moreover, the important factors of Multi-Access Edge Computing (MEC) and 5th generation (5G) networks are analyzed in the context of deep learning architecture to improve the response time of DFD systems. Lastly, it is concluded that there is a research gap when it comes to implementing the DFD systems on MEC and 5G technologies by using multimodal features and DL architecture.},
	language = {en},
	number = {1},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Abbas, Qaisar and Alsheddy, Abdullah},
	month = dec,
	year = {2020},
	pages = {56},
	file = {Abbas and Alsheddy - 2020 - Driver Fatigue Detection Systems Using Multi-Senso.pdf:/home/simeon/Zotero/storage/UDTSKTUY/Abbas and Alsheddy - 2020 - Driver Fatigue Detection Systems Using Multi-Senso.pdf:application/pdf},
}

@incollection{corchado_drowsy_2014,
	address = {Cham},
	title = {A {Drowsy} {Driver} {Detection} {System} {Based} on a {New} {Method} of {Head} {Posture} {Estimation}},
	volume = {8669},
	isbn = {978-3-319-10839-1 978-3-319-10840-7},
	url = {http://link.springer.com/10.1007/978-3-319-10840-7_44},
	abstract = {A drowsy driver detection system based on a new method for head posture estimation is proposed. In the ﬁrst part, we introduced six possible models of head positions that can be detected by our algorithm which is explained in the second part. Indeed, there are three key stages characterizing our method: First of all, we proceed with driver’s face detection by Viola and Jones algorithm. Then, we extract the image reference and the non image reference coordinates from the face bounding’s box. Finally, based on measuring both the head inclination’s angle and distances between the extracted coordinates, we classify the head state (normal or inclined). Test results demonstrate that the proposed system can eﬃciently measure the aforementioned parameters and detect the head state as a sign of driver’s drowsiness.. . .},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Intelligent {Data} {Engineering} and {Automated} {Learning} – {IDEAL} 2014},
	publisher = {Springer International Publishing},
	author = {Teyeb, Ines and Jemai, Olfa and Zaied, Mourad and Ben Amar, Chokri},
	editor = {Corchado, Emilio and Lozano, José A. and Quintián, Héctor and Yin, Hujun},
	year = {2014},
	doi = {10.1007/978-3-319-10840-7_44},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {362--369},
	file = {Teyeb et al. - 2014 - A Drowsy Driver Detection System Based on a New Me.pdf:/home/simeon/Zotero/storage/3UVND9RT/Teyeb et al. - 2014 - A Drowsy Driver Detection System Based on a New Me.pdf:application/pdf;Teyeb et al. - 2014 - A Drowsy Driver Detection System Based on a New Me.pdf:/home/simeon/Zotero/storage/DJPX4IBF/Teyeb et al. - 2014 - A Drowsy Driver Detection System Based on a New Me.pdf:application/pdf},
}

@article{egelund_spectral_1982,
	title = {Spectral analysis of heart rate variability as an indicator of driver fatigue},
	volume = {25},
	issn = {0014-0139, 1366-5847},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00140138208925026},
	doi = {10.1080/00140138208925026},
	language = {en},
	number = {7},
	urldate = {2020-11-02},
	journal = {Ergonomics},
	author = {Egelund, Niels},
	month = jul,
	year = {1982},
	pages = {663--672},
	file = {Egelund - 1982 - Spectral analysis of heart rate variability as an .pdf:/home/simeon/Zotero/storage/QTK9GEE5/Egelund - 1982 - Spectral analysis of heart rate variability as an .pdf:application/pdf;egelund1982.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/egelund1982.pdf:application/pdf},
}

@article{chowdhury_sensor_2018,
	title = {Sensor {Applications} and {Physiological} {Features} in {Drivers}’ {Drowsiness} {Detection}: {A} {Review}},
	volume = {18},
	issn = {1530-437X, 1558-1748, 2379-9153},
	shorttitle = {Sensor {Applications} and {Physiological} {Features} in {Drivers}’ {Drowsiness} {Detection}},
	url = {http://ieeexplore.ieee.org/document/8293771/},
	doi = {10.1109/JSEN.2018.2807245},
	abstract = {Drowsiness in drivers has become a serious cause of concern due to the occurrences of a large number of fatalities on the road each year. Lives of pedestrians and passengers are put to risk as drivers tend to fall asleep at the steering wheel. In the recent past, many researchers have paid attention to the problem of drowsiness detection since safe roads and safe driving are of paramount concern to all societies. This paper has led to the development of several novel and effective methods in detecting drivers’ drowsiness. These include: 1) Vehicle based methods; 2) Behavioral methods; and 3) Physiological methods. Since wake-sleep is an intermediate state between two physiologically dissimilar states, physiological signals can deﬁne this transition more accurately when compared with approaches that fall in other categories. This paper focuses on the role of physiological signals in detecting driver’s drowsiness level. The proposed methods measure the physiological signals by means of various sensors, which monitor the driver’s physiological parameters on a continual basis. Multiple sensors can be embedded on the driver or in the vicinity of the driver to capture vital signs indicating the onset of drowsiness. The aim here is to provide an insightful review of all such key approaches that fall in this category. This paper conducts a detailed study in which key physiological parameters that relate to drowsiness are identiﬁed, described, and analyzed. Furthermore, the overall advantages and limitations of these physiological based schemes are also highlighted.},
	language = {en},
	number = {8},
	urldate = {2020-11-02},
	journal = {IEEE Sensors Journal},
	author = {Chowdhury, Anuva and Shankaran, Rajan and Kavakli, Manolya and Haque, Md. Mokammel},
	month = apr,
	year = {2018},
	pages = {3055--3067},
	file = {Chowdhury et al. - 2018 - Sensor Applications and Physiological Features in .pdf:/home/simeon/Zotero/storage/7B3XQXHQ/Chowdhury et al. - 2018 - Sensor Applications and Physiological Features in .pdf:application/pdf;chowdhury2018.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/chowdhury2018.pdf:application/pdf},
}

@article{brookhuis_monitoring_2010,
	title = {Monitoring drivers’ mental workload in driving simulators using physiological measures},
	volume = {42},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S000145750900116X},
	doi = {10.1016/j.aap.2009.06.001},
	abstract = {Many trafﬁc accidents are caused by, or at least related to, inadequate mental workload, when it is either too low (vigilance) or too high (stress). Creating variations in mental workload and accident-prone driving for research purposes is difﬁcult in the real world. In driving simulators the measurement of driver mental workload is relatively easily conducted by means of physiological measures, although good research skills are required and it is time-consuming. The fact that modern driving simulator environments are laboratory-equivalent nowadays allows full control with respect to environmental conditions, scenarios and stimuli, and enables physiological measurement of parameters of mental workload such as heart rate and brain activity. Several examples are presented to illustrate the potential of modern highstandard driving simulator environments regarding the monitoring of drivers’ mental workload during task performance.},
	language = {en},
	number = {3},
	urldate = {2020-11-02},
	journal = {Accident Analysis \& Prevention},
	author = {Brookhuis, Karel A. and de Waard, Dick},
	month = may,
	year = {2010},
	pages = {898--903},
	file = {Brookhuis and de Waard - 2010 - Monitoring drivers’ mental workload in driving sim.pdf:/home/simeon/Zotero/storage/M6KQUZ2P/Brookhuis and de Waard - 2010 - Monitoring drivers’ mental workload in driving sim.pdf:application/pdf;brookhuis2010.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/brookhuis2010.pdf:application/pdf},
}

@article{mu_driver_2017,
	title = {Driver {Fatigue} {Detection} {System} {Using} {Electroencephalography} {Signals} {Based} on {Combined} {Entropy} {Features}},
	volume = {7},
	issn = {2076-3417},
	url = {http://www.mdpi.com/2076-3417/7/2/150},
	doi = {10.3390/app7020150},
	abstract = {Driver fatigue has become one of the major causes of trafﬁc accidents, and is a complicated physiological process. However, there is no effective method to detect driving fatigue. Electroencephalography (EEG) signals are complex, unstable, and non-linear; non-linear analysis methods, such as entropy, maybe more appropriate. This study evaluates a combined entropy-based processing method of EEG data to detect driver fatigue. In this paper, 12 subjects were selected to take part in an experiment, obeying driving training in a virtual environment under the instruction of the operator. Four types of enthrones (spectrum entropy, approximate entropy, sample entropy and fuzzy entropy) were used to extract features for the purpose of driver fatigue detection. Electrode selection process and a support vector machine (SVM) classiﬁcation algorithm were also proposed. The average recognition accuracy was 98.75\%. Retrospective analysis of the EEG showed that the extracted features from electrodes T5, TP7, TP8 and FP1 may yield better performance. SVM classiﬁcation algorithm using radial basis function as kernel function obtained better results. A combined entropy-based method demonstrates good classiﬁcation performance for studying driver fatigue detection.},
	language = {en},
	number = {2},
	urldate = {2020-11-02},
	journal = {Applied Sciences},
	author = {Mu, Zhendong and Hu, Jianfeng and Min, Jianliang},
	month = feb,
	year = {2017},
	pages = {150},
	file = {Mu et al. - 2017 - Driver Fatigue Detection System Using Electroencep.pdf:/home/simeon/Zotero/storage/HFUZRH2C/Mu et al. - 2017 - Driver Fatigue Detection System Using Electroencep.pdf:application/pdf;applsci-07-00150.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/applsci-07-00150.pdf:application/pdf},
}

@inproceedings{begum_intelligent_2013,
	title = {Intelligent driver monitoring systems based on physiological sensor signals: {A} review},
	shorttitle = {Intelligent driver monitoring systems based on physiological sensor signals},
	doi = {10.1109/ITSC.2013.6728246},
	abstract = {Drowsiness, stress and lack of concentration caused by a variety of different factors is a serious problem in traffic. Many traffic accidents are due to these risky behaviors of the drivers. A system which recognizes the state of the driver and e.g. suggests breaks when stress level is too high or driver is too tired would enable large savings and reduces accident. Today different physiological sensor signals such as Electrocardiogram (ECG), Elektro-okulogram (EOG), Electroencephalogram (EEG) and Pulse Oximeter (Oxygen saturation measurements) enable clinician to determine psychological and behavioral state with high accuracy. There are researchers working on developing intelligent systems help to monitor potential risky behaviors of drivers using sensor signals. Thus, this paper provides an overview and analysis of driver monitoring/alerting systems developments and implementations which are based on physiological sensor signals. Summarizing published research works and systems this review provides a resource for researchers, scholars and developers working in the area.},
	booktitle = {16th {International} {IEEE} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC} 2013)},
	author = {Begum, S.},
	month = oct,
	year = {2013},
	note = {ISSN: 2153-0017},
	keywords = {behavioural sciences computing, Biomedical monitoring, cognition, Correlation, driver behavioral state determination, driver information systems, driver monitoring-alerting system, driver risky behavior monitoring, driver state recognition, Electrocardiography, intelligent driver monitoring system, intelligent system, Monitoring, physiological sensor signals, physiology, psychological state determination, road accidents, road traffic, Skin, Stress, traffic accidents, Vehicles},
	pages = {282--289},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Connectors}},
	url = {https://www.zotero.org/download/connectors},
	urldate = {2020-11-02},
}

@article{zadeh_fuzzy_1988,
	address = {University of California, Berkeley},
	title = {Fuzzy {Logic}},
	journal = {IEEE},
	author = {Zadeh, Lofti A.},
	year = {1988},
	file = {zadeh1988.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/zadeh1988.pdf:application/pdf},
}

@article{gomez-perez_asun_nodate,
	title = {\{asun, mfernandez, ocorcho\}@fi.upm.es},
	language = {en},
	author = {Gómez-Pérez, Asunción and Fernández-López, M and Corcho, O},
	pages = {110},
	file = {Ontological_Engineering_With_Examples_from_the_Are.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/Ontological_Engineering_With_Examples_from_the_Are.pdf:application/pdf;Ontological_Engineering_With_Examples_from_the_Are.pdf:/Users/simeon/Desktop/Recherche/Article/Ontological_Engineering_With_Examples_from_the_Are.pdf:application/pdf},
}

@inproceedings{ortalda_safe_2018,
	address = {Seville, Spain},
	title = {Safe {Driving} {Mechanism}: {Detection}, {Recognition} and {Avoidance} of {Road} {Obstacles}:},
	isbn = {978-989-758-330-8},
	shorttitle = {Safe {Driving} {Mechanism}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006935400960107},
	doi = {10.5220/0006935400960107},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {Proceedings of the 10th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Ortalda, Andrea and Moujahid, Abdallah and Hina, Manolo Dulva and Soukane, Assia and Ramdane-Cherif, Amar},
	year = {2018},
	pages = {96--107},
	file = {KEOD 2018 Article v6.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/KEOD 2018 Article v6.pdf:application/pdf;KEOD 2018 Article v6.pdf:/Users/simeon/Desktop/Recherche/Article/KEOD 2018 Article v6.pdf:application/pdf},
}

@inproceedings{moujahid_machine_2018,
	address = {Paris},
	title = {Machine {Learning} {Techniques} in {ADAS}: {A} {Review}},
	isbn = {978-1-5386-4485-0},
	shorttitle = {Machine {Learning} {Techniques} in {ADAS}},
	url = {https://ieeexplore.ieee.org/document/8441758/},
	doi = {10.1109/ICACCE.2018.8441758},
	abstract = {What machine learning (ML) technique is used for system intelligence implementation in ADAS (advanced driving assistance system)? This paper tries to answer this question. This paper analyzes ADAS and ML independently and then relate which ML technique is applicable to what ADAS component and why. The paper gives a good grasp of the current state-of-the-art. Sample works in supervised, unsupervised, deep and reinforcement learnings are presented; their strengths and rooms for improvements are also discussed. This forms part of the basics in understanding autonomous vehicle. This work is a contribution to the ongoing research in ML aimed at reducing road traffic accidents and fatalities, and the invocation of safe driving.},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {2018 {International} {Conference} on {Advances} in {Computing} and {Communication} {Engineering} ({ICACCE})},
	publisher = {IEEE},
	author = {Moujahid, Abdallah and ElAraki Tantaoui, Mounir and Hina, Manolo Dulva and Soukane, Assia and Ortalda, Andrea and ElKhadimi, Ahmed and Ramdane-Cherif, Amar},
	month = jun,
	year = {2018},
	pages = {235--242},
	file = {ICACCE_2018_paper_108.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/ICACCE_2018_paper_108.pdf:application/pdf;ICACCE_2018_paper_108.pdf:/Users/simeon/Desktop/Recherche/Article/ICACCE_2018_paper_108.pdf:application/pdf},
}

@inproceedings{hina_machine_2019,
	address = {Akko, Israel},
	title = {Machine {Learning} {Techniques} for {Cognition} of {Driving} {Context}},
	isbn = {978-1-72812-803-0},
	url = {https://ieeexplore.ieee.org/document/8798589/},
	doi = {10.1109/MED.2019.8798589},
	abstract = {It is important that a vehicle recognizes the driving context to which it is a part of. The cognition of driving events would enable an intelligent vehicle to make sense of the current driving situation in order to perform corresponding safe-driving actions to overcome obstacle and prevent road accident. By applying machine-learning techniques, driving events can be recognized with sufficient degree of precision and accordingly, safe driving actions appropriate to the given driving event could be implemented. This technique coupled with driving assistance messages directed towards the driver (semi-autonomous vehicle) or actions towards the vehicle (autonomous vehicle) is a contribution to safe driving and in reducing accident fatalities.},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {2019 27th {Mediterranean} {Conference} on {Control} and {Automation} ({MED})},
	publisher = {IEEE},
	author = {Hina, Manolo Dulva and Soukane, Assia and Ramdane-Cherif, Amar},
	month = jul,
	year = {2019},
	pages = {380--385},
	file = {hina2019.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/hina2019.pdf:application/pdf;hina2019.pdf:/Users/simeon/Desktop/Recherche/Article/hina2019.pdf:application/pdf},
}

@inproceedings{hina_secured_2016,
	address = {Rio de Janeiro, Brazil},
	title = {Secured data processing, notification and transmission in a human-vehicle interaction system},
	isbn = {978-1-5090-1889-5},
	url = {http://ieeexplore.ieee.org/document/7795721/},
	doi = {10.1109/ITSC.2016.7795721},
	abstract = {Project CASA (Car Safety Apps) is a joint project of a consortium composed of 5 industrial and one academic partners in France with an aim of building an Android app that promotes safe and green driving, and secured data transmission. In this paper, we focus on the security aspects and features of our project. We present that the multimodal data processing of our work is safe and secured. The driver notification and alert messages are intended to keep the driver safe from road accidents. The data transmission using LiFi, instead of WiFi, makes the communication secured due to the absence of radio wave’ interference with other road users and the absence of electromagnetic interference makes it a green technology. The contributions of our work are as follows: (i) generation of assistive messages that are suitable for safe and green driving, and (ii) secured and green data transmission.},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {2016 {IEEE} 19th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE},
	author = {Hina, Manolo Dulva and {Hongyu Guan} and Ramdane-Cherif, Amar and {Nan Deng}},
	month = nov,
	year = {2016},
	pages = {1277--1284},
	file = {hina2016.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/hina2016.pdf:application/pdf;hina2016.pdf:/Users/simeon/Desktop/Recherche/Article/hina2016.pdf:application/pdf},
}

@article{formenti_thermal_2013,
	title = {Thermal {Imaging} of {Exercise}-{Associated} {Skin} {Temperature} {Changes} in {Trained} and {Untrained} {Female} {Subjects}},
	volume = {41},
	issn = {0090-6964, 1573-9686},
	url = {http://link.springer.com/10.1007/s10439-012-0718-x},
	doi = {10.1007/s10439-012-0718-x},
	abstract = {Heat dissipation during sport exercise is an important physiological mechanism that may inﬂuence athletic performance. Our aim was to test the hypothesis that differences exist in the dynamics of exercise-associated skin temperature changes between trained and untrained subjects. We investigated thermoregulation of a local muscle area (muscle–tendon unit) involved in a localized steady-load exercise (standing heels raise) using infrared thermography. Seven trained female subjects and seven untrained female controls were studied. Each subject performed standing heels raise exercise for 2 min. Thermal images were recorded prior to exercise (1 min), during exercise (2 min), and after exercise (7 min). The analysis of thermal images provided the skin temperature time course, which was characterized by a set of descriptive parameters. Two-way ANOVA for repeated measures detected a signiﬁcant interaction (p = 0.03) between group and time, thus indicating that athletic subjects increased their skin temperature differently with respect to untrained subjects. This was conﬁrmed by comparing the parameters describing the speed of rise of skin temperature. It was found that trained subjects responded to exercise more quickly than untrained controls (p {\textless} 0.05). In conclusion, physical training improves the ability to rapidly elevate skin temperature in response to a localized exercise in female subjects.},
	language = {en},
	number = {4},
	urldate = {2020-07-01},
	journal = {Annals of Biomedical Engineering},
	author = {Formenti, Damiano and Ludwig, Nicola and Gargano, Marco and Gondola, Marco and Dellerma, Nicoletta and Caumo, Andrea and Alberti, Giampietro},
	month = apr,
	year = {2013},
	pages = {863--871},
	file = {formenti2012.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/formenti2012.pdf:application/pdf;formenti2012.pdf:/Users/simeon/Desktop/Recherche/Article/formenti2012.pdf:application/pdf;Formenti et al. - 2013 - Thermal Imaging of Exercise-Associated Skin Temper.pdf:/home/simeon/Zotero/storage/UG4YVDXV/Formenti et al. - 2013 - Thermal Imaging of Exercise-Associated Skin Temper.pdf:application/pdf},
}

@article{lefrancois_choosing_nodate,
	title = {Choosing your ontologies for sensor data applications},
	language = {en},
	author = {Lefrançois, Maxime},
	pages = {106},
	file = {chosing your ontologie for sensor data app.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/chosing your ontologie for sensor data app.pdf:application/pdf;chosing your ontologie for sensor data app.pdf:/Users/simeon/Desktop/Recherche/Article/chosing your ontologie for sensor data app.pdf:application/pdf},
}

@incollection{milisavljevic_sensor_2009,
	title = {Sensor {Data} {Fusion} in {Automotive} {Applications}},
	isbn = {978-3-902613-52-3},
	url = {http://www.intechopen.com/books/sensor_and_data_fusion/sensor_data_fusion_in_automotive_applications},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {Sensor and {Data} {Fusion}},
	publisher = {I-Tech Education and Publishing},
	author = {Lytrivis, Panagiotis and Thomaidis, George and Amditis, Angelos},
	editor = {Milisavljevic, Nada},
	month = feb,
	year = {2009},
	doi = {10.5772/6574},
	file = {6083.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/6083.pdf:application/pdf;6083.pdf:/Users/simeon/Desktop/Recherche/Article/6083.pdf:application/pdf},
}

@article{hina_cognition_nodate,
	title = {Cognition of {Driving} {Context} for {Driving} {Assistance}},
	abstract = {In this paper, we presented our innovative way of determining the driving context for a driving assistance system. We invoke the fusion of all parameters that describe the context of the environment, the vehicle and the driver to obtain the driving context. We created a training set that stores driving situation patterns and from which the system consults to determine the driving situation. A machine-learning algorithm predicts the driving situation. The driving situation is an input to the fission process that yields the action that must be implemented when the driver needs to be informed or assisted from the given the driving situation. The action may be directed towards the driver, the vehicle or both. This is an ongoing work whose goal is to offer an alternative driving assistance system for safe driving, green driving and comfortable driving. Here, ontologies are used for knowledge representation.},
	language = {en},
	author = {Hina, Manolo Dulva and Thierry, Clement and Soukane, Assia and Ramdane-Cherif, Amar},
	pages = {11},
	file = {18my020041-4-1-[1] version finale.pdf:/Users/simeon/Desktop/Recherche/Article/18my020041-4-1-[1] version finale.pdf:application/pdf;18my020041-4-1-[1] version finale.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/18my020041-4-1-[1] version finale.pdf:application/pdf},
}

@article{musen_protege_2015,
	title = {The protégé project: a look back and a look forward},
	volume = {1},
	issn = {2372-3483, 2372-3483},
	shorttitle = {The protégé project},
	url = {https://dl.acm.org/doi/10.1145/2757001.2757003},
	doi = {10.1145/2757001.2757003},
	language = {en},
	number = {4},
	urldate = {2020-06-18},
	journal = {AI Matters},
	author = {Musen, Mark A.},
	month = jun,
	year = {2015},
	pages = {4--12},
	file = {musen2015.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/musen2015.pdf:application/pdf},
}

@inproceedings{xiong_development_2016,
	address = {Rio de Janeiro, Brazil},
	title = {The development of an {Ontology} for driving {Context} {Modelling} and reasoning},
	isbn = {978-1-5090-1889-5},
	url = {http://ieeexplore.ieee.org/document/7795524/},
	doi = {10.1109/ITSC.2016.7795524},
	abstract = {In order to use technology to inﬂuence human behaviour and promote safer and more fuel efﬁcient behaviour through incentive mechanisms, an instrumented vehicle is developed. The ﬁrst step is to make it “perceive” the outside world, so extracting knowledge from some data sources such as sensors is crucial. More critically, there is a fundamental need for a standard that would enable knowledge sharing/exchanging among the different entities, e.g., between on-board sensors, invehicle controls and trafﬁc management agencies. This paper proposes an Ontology for Context Modelling (OCM) to be used as the world model for driving context representation and reasoning, which can enable a better understanding of trafﬁc context and sensor capability, which is the basis for providing data source to Advanced Driver Assistance Systems (ADAS), V2X (Vehicle-to-Everything) communications and even driving decision making within autonomous vehicles. Through the experiments, we evaluate the capability of the OCM to represent the driving context and the reasoning mechanism to compensate for sensor failures and recognize lane changing and overtaking events. This methodology has signiﬁcant value for creating standards in autonomous and semi-autonomous cars.},
	language = {en},
	urldate = {2020-06-18},
	booktitle = {2016 {IEEE} 19th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE},
	author = {Xiong, Zhitao and Dixit, Vinayak V. and Waller, S. Travis},
	month = nov,
	year = {2016},
	pages = {13--18},
	file = {Xiong et al. - 2016 - The development of an Ontology for driving Context.pdf:/home/simeon/Zotero/storage/REX3YZKT/Xiong et al. - 2016 - The development of an Ontology for driving Context.pdf:application/pdf;xiong2016.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/xiong2016.pdf:application/pdf;xiong2016.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/xiong2016.pdf:application/pdf},
}

@article{zhao_ontologies_nodate,
	title = {Ontologies for {Advanced} {Driver} {Assistance} {Systems}},
	abstract = {Many Advanced Driver Assistance Systems (ADAS) have been developed to improve car safety. A Knowledge Base is indispensable for autonomous vehicles to perceive driving environments and understand trafﬁc regulations. In this paper, we introduce an ontology-based Knowledge Base, which contains maps and trafﬁc regulations. By accessing to the Knowledge Base, the intelligent vehicles can aware overspeed situations and make decisions at intersections in comply with trafﬁc regulations. Two simple ADAS systems are developed based on the Knowledge Base. We conducted ﬁeld test with an intelligent vehicle to evaluate the ADAS systems.},
	language = {en},
	author = {Zhao, Lihua and Ichise, Ryutaro and Mita, Seiichi and Sasaki, Yutaka},
	pages = {6},
	file = {SIG-SWO-035-03.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/SIG-SWO-035-03.pdf:application/pdf},
}

@inproceedings{avancha_ontology-driven_2004,
	address = {Boston, MA, USA},
	title = {Ontology-driven adaptive sensor networks},
	isbn = {978-0-7695-2208-1},
	url = {http://ieeexplore.ieee.org/document/1331726/},
	doi = {10.1109/MOBIQ.2004.1331726},
	abstract = {A wireless sensor network deployed in an area of interest is affected by variations in environmental conditions associated with that area. It must adapt to these variations in order to continue functioning as desired by the user. We present a novel, two-phase solution to the wireless sensor network adaptivity problem. In the ﬁrst phase, nodes in the network, organized as clusters, execute an efﬁcient algorithm to dynamically calibrate sensed data. Each node provides its current energy level and the state of each on-board sensor to a cluster-head. In the second phase, each clusterhead executes an efﬁcient, ontology-driven algorithm to determine the future state of the network under existing conditions, based on information received from each sensor node. We describe an example application scenario to show how our two-phase solution can be employed to enable a realworld wireless sensor network to adapt itself to variations in environmental conditions.},
	language = {en},
	urldate = {2020-06-18},
	booktitle = {The {First} {Annual} {International} {Conference} on {Mobile} and {Ubiquitous} {Systems}: {Networking} and {Services}, 2004. {MOBIQUITOUS} 2004.},
	publisher = {IEEE},
	author = {Avancha, S. and Patel, C.},
	year = {2004},
	pages = {194--202},
	file = {Ontology-driven adaptive sensor networks.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/Ontology-driven adaptive sensor networks.pdf:application/pdf},
}

@article{bendadouche_etat_nodate,
	title = {Etat de l'art sur les ontologies de capteurs pour une intégration intelligente des données},
	abstract = {This paper is a state of the art of sensor ontologies developed in different fields and applications. In the context of our work, we are interested in Wireless Sensor Networks (WSN) for monitoring environmental phenomena. We have studied sensor ontologies to develop a WSN data integration method which differentiates the acquisition and transmission data policies. The ontology allows us to define the needed concepts to describe these policies. Furthermore, it should also be a component of a decision support system which pilots the WSN to optimize data transmission. Our state of the art is a critical analysis of existing sensor ontologies. This analysis focuses on the topics and on the various uses of ontologies in WSN. Thus, we will highlight that currently there is no ontology able to differentiate data collected from those transmitted to the information system.},
	language = {fr},
	author = {Bendadouche, Rimel and Roussey, Catherine and de Sousa, Gil and Chanet, Jean-Pierre and Hou, Kun Mean},
	pages = {17},
	file = {Etat_de_lart_sur_les_ontologies_de_capteurs_pour__(2).pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/Etat_de_lart_sur_les_ontologies_de_capteurs_pour__(2).pdf:application/pdf},
}

@inproceedings{hargutt_eyelid_2001,
	title = {{EYELID} {MOVEMENTS} {AND} {THEIR} {PREDICTIVE} {VALUE} {FOR} {FATIGUE} {STAGES}},
	url = {https://trid.trb.org/view/721168},
	urldate = {2020-06-18},
	author = {Hargutt, V. and Kruger, H.-P.},
	year = {2001},
	file = {Snapshot:/home/simeon/Zotero/storage/CFW94YTN/721168.html:text/html},
}

@inproceedings{kasabov_evolving_2006,
	address = {Ambelside, UK},
	title = {Evolving {Intelligent} {Systems}: {Methods}, {Learning}, \& {Applications}},
	isbn = {978-0-7803-9718-7 978-0-7803-9719-4},
	shorttitle = {Evolving {Intelligent} {Systems}},
	url = {http://ieeexplore.ieee.org/document/4016749/},
	doi = {10.1109/ISEFS.2006.251185},
	abstract = {The basic concept, formulation, background, and a panoramic view over the recent research results and open problems in the newly emerging area of Evolving Intelligent Systems are summarized in this short communication. Intelligent systems can be defined as systems that incorporate some form of reasoning that is typical for humans. Fuzzy Systems are well known for being able to formalize human knowledge that still separates humans from machines. Artificial Neural Networks have proven to be a useful form of parallel processing of information that employs principles from the organization of the brain. Finally, the evolution is a phenomenon that was initially used to solve optimization problems inspired by the progress in Genetic Algorithms, Evolutionary Computing, and Genetic Programming. These types of evolutionary algorithms are mimicking the natural selection that takes place in populations of living creatures over generations. More recently, the evolution of individual systems within their life-span (self-organization, learning through experience, and self-developing) has attracted attention. These systems called 'evolving' came as a result of the research on practical intelligent systems and on-line learning algorithms that are capable of extracting knowledge from data and performing a higher level adaptation of model structure as well as model parameters. Evolving systems can also be considered an extension of the multi-model concept known from the control theory, and of the on-line identification of fuzzy rule-based models. They can also be regarded as an extension of the methods for on-line learning neural networks with flexible structure that can grow and shrink. This new concept of evolving intelligent systems can also be treated in the framework of knowledge and data integration. Evolutionary, population / generation based computation, can be applied to optimize parameters and features of an individual system, that learns incrementally from incoming data. The specifics of this paper lays in the generalization of the recent advances in the development of evolving fuzzy and neuro-fuzzy models and the more analytical angle of consideration through the prism of knowledge evolution as opposed to the usually used data-centered approach. This powerful new concept has been recently introduced by the authors in a series of parallel works and is still under intensive development. It forms the conceptual basis for the development of the truly intelligent systems. A number of applications of this technique to a range of industrial and benchmark processes have been recently reported. Due to the lack of space only some of them will be mentioned primarily with illustrative purpose.},
	language = {en},
	urldate = {2020-05-27},
	booktitle = {2006 {International} {Symposium} on {Evolving} {Fuzzy} {Systems}},
	publisher = {IEEE},
	author = {Kasabov, Nikola and Filev, Dimitar},
	month = sep,
	year = {2006},
	pages = {8--18},
	file = {Kasabov and Filev - 2006 - Evolving Intelligent Systems Methods, Learning, &.pdf:/home/simeon/Zotero/storage/IQR286SZ/Kasabov and Filev - 2006 - Evolving Intelligent Systems Methods, Learning, &.pdf:application/pdf;kasabov2006.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/kasabov2006.pdf:application/pdf;kasabov2006.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/kasabov2006.pdf:application/pdf},
}

@article{salmon_bad_2019,
	title = {Bad behaviour or societal failure? {Perceptions} of the factors contributing to drivers' engagement in the fatal five driving behaviours},
	volume = {74},
	issn = {00036870},
	shorttitle = {Bad behaviour or societal failure?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003687018302813},
	doi = {10.1016/j.apergo.2018.08.008},
	abstract = {The so-called ‘fatal ﬁve’ behaviours (drink and drug driving, distraction and inattention, speeding, fatigue, and failure to wear a seat belt) are known to be the major behavioural contributory factors to road trauma. However, little is known about the factors that lead to drivers engaging in each behaviour. This article presents the ﬁndings from a study which collected and analysed data on the factors that lead to drivers engaging in each behaviour. The study involved a survey of drivers' perceptions of the causes of each behaviour and a subject matter expert workshop to gain the views of road safety experts. The results were mapped onto a systems ergonomics model of the road transport system in Queensland, Australia, to show where in the system the factors reside. In addition to well-known factors relating to drivers' knowledge, experience and personality, additional factors at the higher levels of the road transport system related to road safety policy, transport system design, road rules and regulations, and societal issues were identiﬁed. It is concluded that the fatal ﬁve behaviours have a web of interacting contributory factors underpinning them and are systems problems rather than driver-centric problems. The implications for road safety interventions are discussed.},
	language = {en},
	urldate = {2020-05-27},
	journal = {Applied Ergonomics},
	author = {Salmon, Paul M. and Read, Gemma J.M. and Beanland, Vanessa and Thompson, Jason and Filtness, Ashleigh J. and Hulme, Adam and McClure, Rod and Johnston, Ian},
	month = jan,
	year = {2019},
	pages = {162--171},
	file = {Salmon et al. - 2019 - Bad behaviour or societal failure Perceptions of .pdf:/home/simeon/Zotero/storage/22EK6CZI/Salmon et al. - 2019 - Bad behaviour or societal failure Perceptions of .pdf:application/pdf;salmon2019.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/salmon2019.pdf:application/pdf;salmon2019.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/salmon2019.pdf:application/pdf},
}

@article{polat_new_2006,
	title = {A new method to medical diagnosis: {Artificial} immune recognition system ({AIRS}) with fuzzy weighted pre-processing and application to {ECG} arrhythmia},
	volume = {31},
	issn = {09574174},
	shorttitle = {A new method to medical diagnosis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417405002125},
	doi = {10.1016/j.eswa.2005.09.019},
	abstract = {Changes in the normal rhythm of a human heart may result in different cardiac arrhythmias, which may be immediately fatal or cause irreparable damage to the heart sustained over long periods of time. The ability to automatically identify arrhythmias from ECG recordings is important for clinical diagnosis and treatment. Artiﬁcial immune systems (AISs) is a new but effective branch of artiﬁcial intelligence. Among the systems proposed in this ﬁeld so far, artiﬁcial immune recognition system (AIRS), which was proposed by A. Watkins, has showed an effective and intriguing performance on the problems it was applied. Previously, AIRS was applied a range of problems including machinelearning benchmark problems and medical classiﬁcation problems like breast cancer, diabets, liver disorders classiﬁcation problems. The conducted medical classiﬁcation task was performed for ECG arrhythmia data taken from UCI repository of machine-learning. Firsly, ECG dataset is normalized in the range of [0,1] and is weighted with fuzzy weighted pre-processing. Then, weighted input values obtained from fuzzy weighted pre-processing is classiﬁed by using AIRS classiﬁer system. In this study, fuzzy weighted pre-processing, which can be improved by ours, is a new method and ﬁrstly, it is applied to ECG dataset. Classiﬁer system consists of three stages: 50–50\% of traing-test dataset, 70–30\% of traing-test dataset and 80–20\% of traing-test dataset, subsequently, the obtained classiﬁcation accuries: 78.79, 75.00 and 80.77\%.},
	language = {en},
	number = {2},
	urldate = {2020-05-26},
	journal = {Expert Systems with Applications},
	author = {Polat, Kemal and Şahan, Seral and Güneş, Salih},
	month = aug,
	year = {2006},
	pages = {264--269},
	file = {Polat et al. - 2006 - A new method to medical diagnosis Artificial immu.pdf:/home/simeon/Zotero/storage/VVYATKSI/Polat et al. - 2006 - A new method to medical diagnosis Artificial immu.pdf:application/pdf;polat2006.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/polat2006.pdf:application/pdf;polat2006.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/polat2006.pdf:application/pdf},
}

@article{knight_casper_2001,
	title = {Casper: {Space} {Exploration} through {Continuous} {Planning}},
	language = {en},
	journal = {IEEE INTELLIGENT SYSTEMS},
	author = {Knight, Russell and Rabideau, Gregg and Chien, Steve and Engelhardt, Barbara and Sherwood, Rob},
	year = {2001},
	pages = {6},
	file = {Knight et al. - 2001 - Casper Space Exploration through Continuous Plann.pdf:/home/simeon/Zotero/storage/YI8L9UZY/Knight et al. - 2001 - Casper Space Exploration through Continuous Plann.pdf:application/pdf;knight2001.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/knight2001.pdf:application/pdf;knight2001.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/knight2001.pdf:application/pdf},
}

@article{granter_alphago_2017,
	title = {{AlphaGo}, {Deep} {Learning}, and the {Future} of the {Human} {Microscopist}},
	volume = {141},
	issn = {0003-9985, 1543-2165},
	url = {http://www.archivesofpathology.org/doi/10.5858/arpa.2016-0471-ED},
	doi = {10.5858/arpa.2016-0471-ED},
	language = {en},
	number = {5},
	urldate = {2020-05-26},
	journal = {Archives of Pathology \& Laboratory Medicine},
	author = {Granter, Scott R. and Beck, Andrew H. and Papke, David J.},
	month = may,
	year = {2017},
	pages = {619--621},
	file = {Granter et al. - 2017 - AlphaGo, Deep Learning, and the Future of the Huma.pdf:/home/simeon/Zotero/storage/CYF965UE/Granter et al. - 2017 - AlphaGo, Deep Learning, and the Future of the Huma.pdf:application/pdf;granter2017.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/granter2017.pdf:application/pdf;granter2017.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/granter2017.pdf:application/pdf},
}

@phdthesis{dingus_development_1985,
	title = {Development of models for detection of automobile driver impairment},
	school = {Faculty of Virginia Polytechnic Institute},
	author = {Dingus, Thomas A.},
	year = {1985},
	file = {LD5655.V855_1985.D543.pdf:/Users/simeon/Desktop/Recherche/Article/vehicule-measure/LD5655.V855_1985.D543.pdf:application/pdf},
}

@inproceedings{mccall_visual_2004,
	address = {Washington, WA, USA},
	title = {Visual context capture and analysis for driver attention monitoring},
	isbn = {978-0-7803-8500-9},
	url = {http://ieeexplore.ieee.org/document/1398920/},
	doi = {10.1109/ITSC.2004.1398920},
	language = {en},
	urldate = {2020-05-11},
	booktitle = {Proceedings. {The} 7th {International} {IEEE} {Conference} on {Intelligent} {Transportation} {Systems} ({IEEE} {Cat}. {No}.{04TH8749})},
	publisher = {IEEE},
	author = {McCall, J.C. and Trivedi, M.M.},
	year = {2004},
	pages = {332--337},
	file = {McCall and Trivedi - 2004 - Visual context capture and analysis for driver att.pdf:/home/simeon/Zotero/storage/AZGUKGAC/McCall and Trivedi - 2004 - Visual context capture and analysis for driver att.pdf:application/pdf;visual-context-capture-and-analysis-for-driver-attention-monitor.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/visual-context-capture-and-analysis-for-driver-attention-monitor.pdf:application/pdf;visual-context-capture-and-analysis-for-driver-attention-monitor.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/visual-context-capture-and-analysis-for-driver-attention-monitor.pdf:application/pdf},
}

@inproceedings{taylor_warwick-jlr_2015,
	address = {Nottingham, United Kingdom},
	title = {Warwick-{JLR} driver monitoring dataset ({DMD}): statistics and early findings},
	isbn = {978-1-4503-3736-6},
	shorttitle = {Warwick-{JLR} driver monitoring dataset ({DMD})},
	url = {http://dl.acm.org/citation.cfm?doid=2799250.2799286},
	doi = {10.1145/2799250.2799286},
	abstract = {Driving is a safety critical task that requires a high levels of attention and workload from the driver. Despite this, people often also perform secondary tasks such as eating or using a mobile phone, which increase workload levels and divert cognitive and physical attention from the primary task of driving. If a vehicle is aware that the driver is currently under high workload, the vehicle functionality can be changed in order to minimize any further demand. Traditionally, workload measurements have been performed using intrusive means such as physiological sensors. Another approach may be to monitor workload online using readily available and robust sensors accessible via the vehicle’s Controller Area Network (CAN). In this paper, we present details of the Warwick-JLR Driver Monitoring Dataset (DMD) collected for this purpose, and to announce its publication for driver monitoring research. The collection protocol is brieﬂy introduced, followed by statistical analysis of the dataset to describe its structure. Finally, the public release of the dataset, for use in both driver monitoring and data mining research, is announced.},
	language = {en},
	urldate = {2020-05-11},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications} - {AutomotiveUI} '15},
	publisher = {ACM Press},
	author = {Taylor, Phillip and Griffiths, Nathan and Bhalerao, Abhir and Xu, Zhou and Gelencser, Adam and Popham, Thomas},
	year = {2015},
	pages = {89--92},
	file = {Taylor et al. - 2015 - Warwick-JLR driver monitoring dataset (DMD) stati.pdf:/home/simeon/Zotero/storage/JVYJYSPJ/Taylor et al. - 2015 - Warwick-JLR driver monitoring dataset (DMD) stati.pdf:application/pdf;taylor2015.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/taylor2015.pdf:application/pdf;taylor2015.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/taylor2015.pdf:application/pdf},
}

@inproceedings{amditis_system_2003,
	address = {Versailles, France},
	title = {System architecture of a driver's monitoring and hypovigilance warning system},
	volume = {2},
	isbn = {978-0-7803-7346-4},
	url = {http://ieeexplore.ieee.org/document/1188004/},
	doi = {10.1109/IVS.2002.1188004},
	abstract = {Abstracl Driiw hypovigilance (or underawakeness) is stated as a major cause of road accidents, especially in highways. This paper presents the concept of the system architecture of an intelligent in-vehicle system - AWAKE system which monitors driver’s vigilance and warns the driver according to traflc risk estimation. A WAKE intends to develop and validate an on-board system to improve safey, comfort and more eflcient use of cars, in particular in terms of alertness enhancement and hypovigilance watch. A WAKE is a project, co-jiunded by the IST program of the Europeari Commission.},
	language = {en},
	urldate = {2020-05-11},
	booktitle = {Intelligent {Vehicle} {Symposium}, 2002. {IEEE}},
	publisher = {IEEE},
	author = {Amditis, A. and Polychronopoulos, A. and Bekiaris, E. and Antonello, P.C.},
	year = {2003},
	pages = {527--532},
	file = {Amditis et al. - 2003 - System architecture of a driver's monitoring and h.pdf:/home/simeon/Zotero/storage/EMPARS3F/Amditis et al. - 2003 - System architecture of a driver's monitoring and h.pdf:application/pdf;system-architecture-of-a-drivers-monitoring-and-hypovigilance-wa.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/system-architecture-of-a-drivers-monitoring-and-hypovigilance-wa.pdf:application/pdf;system-architecture-of-a-drivers-monitoring-and-hypovigilance-wa.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/system-architecture-of-a-drivers-monitoring-and-hypovigilance-wa.pdf:application/pdf},
}

@article{wang_driver_nodate,
	title = {Driver {Fatigue} {Detection}: {A} {Survey}},
	abstract = {Driver fatigue is an important factor in a large number of accidents. There has been much work done in driver fatigue detection. This paper presents a comprehensive survey of research on driver fatigue detection and provides structural categories for the methods which have been proposed. The methods of fatigue detection mainly focused on measures of the driver’s state, driver performance and the combination of the driver’s state and performance. The measures of driver’s state included PERCLOS, mouth shape and head position; the measures of driver performance included lane tracking and tracking of distance between vehicles. These approaches are presented and discussed in detail. Some typical driver monitoring systems are also introduced in this paper. Finally, summary and conclusions are presented.},
	language = {en},
	author = {Wang, Qiong and Yang, Jingyu and Ren, Mingwu and Zheng, Yujie},
	pages = {5},
	file = {Wang et al. - Driver Fatigue Detection A Survey.pdf:/home/simeon/Zotero/storage/338999ZY/Wang et al. - Driver Fatigue Detection A Survey.pdf:application/pdf;qiongwang2006.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/qiongwang2006.pdf:application/pdf;qiongwang2006.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/qiongwang2006.pdf:application/pdf},
}

@article{golz_evaluation_2010,
	title = {Evaluation of fatigue monitoring technologies},
	volume = {14},
	issn = {1432-9123, 1439-054X},
	url = {http://link.springer.com/10.1007/s11818-010-0482-9},
	doi = {10.1007/s11818-010-0482-9},
	language = {en},
	number = {3},
	urldate = {2020-05-11},
	journal = {Somnologie - Schlafforschung und Schlafmedizin},
	author = {Golz, M. and Sommer, D. and Trutschel, U. and Sirois, B. and Edwards, D.},
	month = sep,
	year = {2010},
	pages = {187--199},
	file = {Golz et al. - 2010 - Evaluation of fatigue monitoring technologies.pdf:/home/simeon/Zotero/storage/JSXUWZZX/Golz et al. - 2010 - Evaluation of fatigue monitoring technologies.pdf:application/pdf;golz2010.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/golz2010.pdf:application/pdf;golz2010.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/golz2010.pdf:application/pdf},
}

@inproceedings{arun_hypovigilance_2011,
	address = {Shah Alam, Malaysia},
	title = {Hypovigilance warning system: {A} review on driver alerting techniques},
	isbn = {978-1-4577-0337-9},
	shorttitle = {Hypovigilance warning system},
	url = {http://ieeexplore.ieee.org/document/5991831/},
	doi = {10.1109/ICSGRC.2011.5991831},
	abstract = {In recent years, driver hypovigilance (drowsiness and inattentiveness) is one of the major causes for road accidents and it leads to severe traumas such as physical injuries, deaths, and economic losses. Several researchers have reported on driver drowsiness detection and only very few works have been reported on detecting the driver hypovigilance. The physiological signals and vision based approaches are mostly used for estimating the driver’s hypovigilance. When the physical state of the driver is drowsy or inattentive, it is important to alert the driver through alerting methods to avoid the accidents. In this paper, we have reviewed various methods used to alert drivers and the issues involved in detecting the hypovigilance. There are many methods adopted for alerting the driver during hypovigilance such as alarms, visual effects, vibrations, etc. This present work discusses in detail about the different methods used for driver alertness system. The level of alertness is based on the hypovigilance level of the driver. The hypovigilance detection system should be designed in such a way to efficiently trigger the alert system only when the driver is in hypovigilance state.},
	language = {en},
	urldate = {2020-05-11},
	booktitle = {2011 {IEEE} {Control} and {System} {Graduate} {Research} {Colloquium}},
	publisher = {IEEE},
	author = {Arun, S and Murugappan, M and Sundaraj, Kenneth},
	month = jun,
	year = {2011},
	pages = {65--69},
	file = {Arun et al. - 2011 - Hypovigilance warning system A review on driver a.pdf:/home/simeon/Zotero/storage/FEG7TDGL/Arun et al. - 2011 - Hypovigilance warning system A review on driver a.pdf:application/pdf;arun2011.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/arun2011.pdf:application/pdf;arun2011.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/arun2011.pdf:application/pdf},
}

@article{arnedt_comparative_2005,
	title = {Comparative sensitivity of a simulated driving task to self-report, physiological, and other performance measures during prolonged wakefulness},
	volume = {58},
	issn = {00223999},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022399904004829},
	doi = {10.1016/j.jpsychores.2004.05.002},
	language = {en},
	number = {1},
	urldate = {2020-05-11},
	journal = {Journal of Psychosomatic Research},
	author = {Arnedt, J. Todd and Geddes, M. Ainsley C. and MacLean, Alistair W.},
	month = jan,
	year = {2005},
	pages = {61--71},
	file = {Arnedt et al. - 2005 - Comparative sensitivity of a simulated driving tas.pdf:/home/simeon/Zotero/storage/GV44WSJL/Arnedt et al. - 2005 - Comparative sensitivity of a simulated driving tas.pdf:application/pdf;arnedt2005.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/arnedt2005.pdf:application/pdf;arnedt2005.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/arnedt2005.pdf:application/pdf},
}

@article{nemcova_multimodal_2020,
	title = {Multimodal {Features} for {Detection} of {Driver} {Stress} and {Fatigue}: {Review}},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Multimodal {Features} for {Detection} of {Driver} {Stress} and {Fatigue}},
	url = {https://ieeexplore.ieee.org/document/9031734/},
	doi = {10.1109/TITS.2020.2977762},
	abstract = {Driver fatigue and stress signiﬁcantly contribute to higher number of car accidents worldwide. Although, different detection approaches have been already commercialized and used by car producers (and third party companies), research activities in this ﬁeld are still needed in order to increase the reliability of these alert systems. Also, in the context of automated driving, the driver mental state assessment will be an important part of cars in future. This paper presents state-of-the-art review of different approaches for driver fatigue and stress detection and evaluation. We describe in details various signals (biological, car and video) and derived features used for these tasks and we discuss their relevance and advantages. In order to make this review complete, we also describe different datasets, acquisition systems and experiment scenarios.},
	language = {en},
	urldate = {2020-05-11},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Nemcova, Andrea and Seitl, Martin and Dominik, Tomas and Semela, Marek and Sucha, Matus and Kolar, Radim and Svozilova, Veronika and Bucsuhazy, Katerina and Smisek, Radovan and Mezl, Martin and Hesko, Branislav and Belak, Michal and Bilik, Martin and Maxera, Pavel},
	year = {2020},
	pages = {1--20},
	file = {Nemcova et al. - 2021 - Multimodal Features for Detection of Driver Stress.pdf:/home/simeon/Zotero/storage/R9Z84U5W/Nemcova et al. - 2021 - Multimodal Features for Detection of Driver Stress.pdf:application/pdf;09031734.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/09031734.pdf:application/pdf;09031734.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/09031734.pdf:application/pdf},
}

@article{hu_detecting_2020,
	title = {Detecting fatigue in car drivers and aircraft pilots by using non-invasive measures: {The} value of differentiation of sleepiness and mental fatigue},
	volume = {72},
	issn = {00224375},
	shorttitle = {Detecting fatigue in car drivers and aircraft pilots by using non-invasive measures},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022437519306735},
	doi = {10.1016/j.jsr.2019.12.015},
	abstract = {Introduction: Fatigue is one of the most crucial factors that contribute to a decrease of the operating per- 27 formance of aircraft pilots and car drivers and, as such, plays a dangerous role in transport safety. To 28 reduce fatigue-related tragedies and to increase the quality of a healthy life, many studies have focused 29 on exploring effective methods and psychophysiological indicators for detecting and monitoring fatigue. 30 However, those fatigue indicators rose many discrepancies among simulator and ﬁeld studies, due to the 31 vague conceptualism of fatigue, per se, which hinders the development of fatigue monitoring devices.},
	language = {en},
	urldate = {2020-05-11},
	journal = {Journal of Safety Research},
	author = {Hu, Xinyun and Lodewijks, Gabriel},
	month = feb,
	year = {2020},
	pages = {173--187},
	file = {Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:/home/simeon/Zotero/storage/YQ73JP77/Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:application/pdf;10.1016@j.jsr.2019.12.015.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/10.1016@j.jsr.2019.12.015.pdf:application/pdf;10.1016@j.jsr.2019.12.015.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/10.1016@j.jsr.2019.12.015.pdf:application/pdf;Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:/home/simeon/Zotero/storage/N6DAQRQZ/Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:application/pdf;Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:/home/simeon/Zotero/storage/788L7XU9/Hu and Lodewijks - 2020 - Detecting fatigue in car drivers and aircraft pilo.pdf:application/pdf},
}

@misc{noauthor_sci-hub_nodate,
	title = {Sci-{Hub} - поиск прокси для скачивания статьи {\textbar} {Multimodal} {Features} for {Detection} of {Driver} {Stress} and {Fatigue}: {Review} {\textbar} 10.1109/{TITS}.2020.2977762},
	url = {https://sci-hub.tw/10.1109/TITS.2020.2977762},
	urldate = {2020-04-29},
	file = {Sci-Hub - поиск прокси для скачивания статьи | Multimodal Features for Detection of Driver Stress and Fatigue\: Review | 10.1109/TITS.2020.2977762:/home/simeon/Zotero/storage/95DBU7FI/TITS.2020.html:text/html},
}

@article{lal_physiological_2000,
	title = {Physiological indicators of driver fatigue},
	volume = {4},
	url = {http://dx.doi.org/},
	abstract = {Fatigue has major implications in transportation system safety. Investigating the psychophysiological links to fatigue can enhance our understanding and management of fatigue in the transport industry. This study examined psychophysiological changes in thirty-five subjects randomly assigned to a driver simulator task. Electroencephalography changes during fatigue were significantly different to the alert baseline (p{\textless}0.01). Delta and theta activity increased the most from fatigue during simulated driving. Heart rate was significantly lower after the driving task (p{\textless}0.01). Blink rate also changed in association with fatigue. We conclude that significant physiological changes occur during driver fatigue. The results are discussed in light of directions for future studies and for the development of a fatigue counter measure device.},
	language = {en},
	journal = {Proceedings of the Australasian road safety research, policing and education conference},
	author = {Lal, S. K. L. and Craig, A.},
	year = {2000},
	pages = {489--494},
}

@book{klir_fuzzy_1995,
	address = {Upper Saddle River, N.J},
	title = {Fuzzy sets and fuzzy logic: theory and applications},
	isbn = {978-0-13-101171-7},
	shorttitle = {Fuzzy sets and fuzzy logic},
	language = {en},
	publisher = {Prentice Hall PTR},
	author = {Klir, George J. and Yuan, Bo},
	year = {1995},
	keywords = {Fuzzy logic, Fuzzy sets},
	file = {Klir and Yuan - 1995 - Fuzzy sets and fuzzy logic theory and application.pdf:/home/simeon/Zotero/storage/ZVWAXFGA/Klir and Yuan - 1995 - Fuzzy sets and fuzzy logic theory and application.pdf:application/pdf},
}

@article{shabnam_abtahi_driver_nodate,
	title = {Driver {Drowsiness} {Monitoring} {Based} on {Yawning} {Detection}},
	author = {Shabnam Abtahi},
	file = {abtahi2011.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/abtahi2011.pdf:application/pdf},
}

@inproceedings{haq_eye-blink_2016,
	address = {Delhi, India},
	title = {Eye-blink rate detection for fatigue determination},
	isbn = {978-1-4673-6984-8},
	url = {http://ieeexplore.ieee.org/document/7975348/},
	doi = {10.1109/IICIP.2016.7975348},
	abstract = {This paper focuses on detection of eye, calculating the eye-blink rate of a person and then determining his level of attentiveness. It is established by researchers that the level of attentiveness of a normal person is greatly expressed by his eye-blinking rate. If a person is feeling fatigued or drowsy, his eye blinking pattern changes. In this paper BioID dataset has been employed for eye detection and result were 97\% positive detection. Using the detected eyes, we determined the eyeblink rate which if varied from the average threshold level determined that the person is fatigued or low on attention. The result for eye-blink detection is 87\%. This methodology when employed in vehicles will help greatly in reducing the amount of fatigue related accidents by alarming the driver so that he can take preventive measures.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2016 1st {India} {International} {Conference} on {Information} {Processing} ({IICIP})},
	publisher = {IEEE},
	author = {Haq, Zeeshan Ali and Hasan, Ziaul},
	month = aug,
	year = {2016},
	pages = {1--5},
	file = {Haq and Hasan - 2016 - Eye-blink rate detection for fatigue determination.pdf:/home/simeon/Zotero/storage/KU9AANC4/Haq and Hasan - 2016 - Eye-blink rate detection for fatigue determination.pdf:application/pdf},
}

@article{du_effects_2015,
	title = {Effects of {Fatigue} on {Driving} {Performance} {Under} {Different} {Roadway} {Geometries}: {A} {Simulator} {Study}},
	volume = {16},
	issn = {1538-9588, 1538-957X},
	shorttitle = {Effects of {Fatigue} on {Driving} {Performance} {Under} {Different} {Roadway} {Geometries}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/15389588.2014.971155},
	doi = {10.1080/15389588.2014.971155},
	abstract = {Methods: Twenty-four participants each completed a driving scenario twice: while alert and while experiencing fatigue. The driving scenario was composed of straight road segments and curves; there were 6 curves with 3 radius values (i.e., 200, 500, and 800 m) and 2 turning directions (i.e., left and right). Analysis was conducted on driving performance measures such as longitudinal speed, steering wheel movements, and lateral position.
Results: Results conﬁrmed that decremental changes in driving performance due to fatigue varied among road conditions. On straight segments, drivers’ abilities to steer and maintain lane position were impaired, whereas on curves we found decremental changes in the quality of longitudinal speed as well as steering control and keeping the vehicle in the lane. Moreover, the effects of fatigue on driving performance were relative to the radius and direction of the curve. Fatigue impaired drivers’ abilities to control the steering wheel, and the impairment proved more obvious on curves. The degree varied signiﬁcantly as the curve radius changed. Drivers tended to drive closer to the right side due to fatigue, and the impairment in maintaining lane position became more obvious as the right-turn curve radius decreased.
Conclusions: Driver fatigue has detrimental effects on driving performance, and the effects differ under different roadway geometries.},
	language = {en},
	number = {5},
	urldate = {2021-02-17},
	journal = {Traffic Injury Prevention},
	author = {Du, Hongji and Zhao, Xiaohua and Zhang, Xingjian and Zhang, Yunlong and Rong, Jian},
	month = jul,
	year = {2015},
	pages = {468--473},
	file = {du2015.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/du2015.pdf:application/pdf},
}

@article{eoh_electroencephalographic_2005,
	title = {Electroencephalographic study of drowsiness in simulated driving with sleep deprivation},
	volume = {35},
	issn = {01698141},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169814104001647},
	doi = {10.1016/j.ergon.2004.09.006},
	abstract = {Drivers’ drowsiness is one of the main causes of car accidents or near-missed accidents. This has been proven by many studies that established links between driver’s drowsiness and road accidents. The objective of this study was to analyze the EEG changes in fatigued subjects while performing a simulated driving task. After a night of sleep deprivation, eight subjects were given a dose of caffeine to reduce drowsiness. During about 50 min of continuous driving, car movements and subject behaviors were recorded on video cameras, and 8 channels of EEG were also recorded. Three basic indices, three ratio indices, and two burst indices were calculated from preprocessed EEG signals. EEG a,b, b/a and (a+y)/b indices showed signiﬁcant differences between driving periods. In the comparison of road type, EEG a,b, b/a and (a+y)/b indices of the straight section of the driving task were signiﬁcantly different from those of the curved section. This study also analyzed EEG changes before and after car accidents, showing that b and (a+y)/b were related to the mental alertness level. In the analysis of burst activity, y burst activity, which was not signiﬁcant in the mean power analysis, was signiﬁcantly different between driving sessions.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {International Journal of Industrial Ergonomics},
	author = {Eoh, Hong J. and Chung, Min K. and Kim, Seong-Han},
	month = apr,
	year = {2005},
	pages = {307--320},
	file = {Eoh et al. - 2005 - Electroencephalographic study of drowsiness in sim.pdf:/home/simeon/Zotero/storage/4K4PGDGA/Eoh et al. - 2005 - Electroencephalographic study of drowsiness in sim.pdf:application/pdf;eoh2005.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/eoh2005.pdf:application/pdf},
}

@inproceedings{erins_feasibility_2019,
	title = {Feasibility study of physiological parameter registration sensors for non-intrusive human fatigue detection system},
	url = {http://www.tf.llu.lv/conference/proceedings2019/Papers/N363.pdf},
	doi = {10.22616/ERDev2019.18.N363},
	abstract = {Human fatigue manifests in slower reactions, reduced ability to process information, memory lapses, absent-mindedness, decreased awareness, lack of attention, underestimation of risk, reduced coordination etc. Chronic, decompensated and acute fatigue in form of drowsiness and falling asleep can lead to errors and accidents, ill-health and injury, and reduced productivity of sectors as in equipment operations, transportation. Their detection is necessary where they provide an option for the quantification and objective evaluation of subjective fatigue levels. Many studies are dealing with this topic for automotive and workability usage to design a fatigue detection and countermeasure device. The paper describes research of recent attitude to the development of the fatigue condition detection methods with the usage of human biological signal combinations, like electroencephalography (EEG), photoplethysmography (PPG), electromyography (EMG), galvanic skin response (GSR), temperature, position, respiration and percentage of eye closure (PERCLOS) to obtain diagnostic parameters reflecting the state of central nervous, cardiovascular, respiratory and muscular system and for monitoring of physiological vital changes. The current research focuses on aspects of non-obtrusive sensor signal quality and placement, and selection factors and evaluation of usability and potential integration into a wearable platform with the use of current sensor technologies that extend the application of sensors from laboratory to everyday environment. The sensor review aims to support development of a platform with multilevel fatigue monitoring and workability evaluation system designed in order to provide an integrated service in the area of operational safety.},
	language = {en},
	urldate = {2021-02-17},
	author = {Erins, Matiss and Minejeva, Olesja and Kivlenieks, Raivis and Lauznis, Juris},
	month = may,
	year = {2019},
	file = {Erins et al. - 2019 - Feasibility study of physiological parameter regis.pdf:/home/simeon/Zotero/storage/U5GDEYVX/Erins et al. - 2019 - Feasibility study of physiological parameter regis.pdf:application/pdf},
}

@article{fan_yawning_2007,
	title = {{YAWNING} {DETECTION} {FOR} {MONITORING} {DRIVER} {FATIGUE}},
	abstract = {Fatigue driving is an important reason of traffic accidents. Yawning is an evidence of driver fatigue. This paper proposes to locate and track a driver’s mouth movement using a CCD camera to study on monitoring and recognizing a driver’s yawning. Firstly detecting drivers’ faces uses Gravity-Center template, then detecting drivers’ left and right mouth corners by grey projection, and extracting texture features of drivers’ mouth corners (left and right) using Gabor wavelets. Finally LDA is applied to classify feature vectors to detect yawning. The method is tested on 400 images from twenty videos. In contrast, yawning is also detected by the ratio of mouth height and width. The experiment results show that Gabor coefficients are more powerful than geometric features to detect yawning and the average recognition rate is 95\% which has more than 20\% improvement.},
	language = {en},
	journal = {Hong Kong},
	author = {Fan, Xiao},
	year = {2007},
	pages = {5},
	file = {Fan - 2007 - YAWNING DETECTION FOR MONITORING DRIVER FATIGUE.pdf:/home/simeon/Zotero/storage/PC28T8GW/Fan - 2007 - YAWNING DETECTION FOR MONITORING DRIVER FATIGUE.pdf:application/pdf;fan2007.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/fan2007.pdf:application/pdf},
}

@article{fleming_overview_2001,
	title = {Overview of automotive sensors},
	volume = {1},
	issn = {1530437X},
	url = {http://ieeexplore.ieee.org/document/983469/},
	doi = {10.1109/7361.983469},
	abstract = {An up-to-date review paper on automotive sensors is presented. Attention is focused on sensors used in production automotive systems. The primary sensor technologies in use today are reviewed and are classified according to their three major areas ofautomotive systems application–powertrain, chassis, and body. This subject is extensive. As described in this paper, for use in automotive systems, there are six types of rotational motion sensors, four types of pressure sensors, five types of position sensors, and three types of temperature sensors. Additionally, two types of mass air flow sensors, five types of exhaust gas oxygen sensors, one type of engine knock sensor, four types of linear acceleration sensors, four types of angular-rate sensors, four types of occupant comfort/convenience sensors, two types of near-distance obstacle detection sensors, four types of far-distance obstacle detection sensors, and and ten types of emerging, state-of the-art, sensors technologies are identified.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {IEEE Sensors Journal},
	author = {Fleming, W.J.},
	month = dec,
	year = {2001},
	pages = {296--308},
	file = {fleming2001.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/fleming2001.pdf:application/pdf},
}

@inproceedings{friedrichs_camera-based_2010,
	address = {La Jolla, CA, USA},
	title = {Camera-based drowsiness reference for driver state classification under real driving conditions},
	isbn = {978-1-4244-7866-8},
	url = {http://ieeexplore.ieee.org/document/5548039/},
	doi = {10.1109/IVS.2010.5548039},
	abstract = {Experts assume that accidents caused by drowsiness are signiﬁcantly under-reported in police crash investigations (1-3\%). They estimate that about 24-33\% of the severe accidents are related to drowsiness. In order to develop warning systems that detect reduced vigilance based on the driving behavior, a reliable and accurate drowsiness reference is needed. Studies have shown that measures of the driver’s eyes are capable to detect drowsiness under simulator or experiment conditions. In this study, the performance of the latest eye tracking based in-vehicle fatigue prediction measures are evaluated. These measures are assessed statistically and by a classiﬁcation method based on a large dataset of 90 hours of real road drives. The results show that eye-tracking drowsiness detection works well for some drivers as long as the blinks detection works properly. Even with some proposed improvements, however, there are still problems with bad light conditions and for persons wearing glasses. As a summary, the camera based sleepiness measures provide a valuable contribution for a drowsiness reference, but are not reliable enough to be the only reference.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2010 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	publisher = {IEEE},
	author = {Friedrichs, Fabian and Yang, Bin},
	month = jun,
	year = {2010},
	pages = {101--106},
	file = {Friedrichs and Yang - 2010 - Camera-based drowsiness reference for driver state.pdf:/home/simeon/Zotero/storage/VUTKTQ2E/Friedrichs and Yang - 2010 - Camera-based drowsiness reference for driver state.pdf:application/pdf;friedrichs2010.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/friedrichs2010.pdf:application/pdf},
}

@book{hartley_review_2000,
	address = {Melbourne},
	title = {Review of fatigue detection and prediction technologies},
	isbn = {978-0-642-54469-8},
	language = {en},
	publisher = {National Road Transport Commission},
	author = {Hartley, Laurence and {Australia} and {National Road Transport Commission} and {Murdoch University} and {Institute for Research into Safety \& Transport}},
	year = {2000},
	note = {OCLC: 155455789},
	file = {Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:/home/simeon/Zotero/storage/PWDCPZ6J/Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:application/pdf;Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:/home/simeon/Zotero/storage/QCR9JL62/Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:application/pdf;fdpt.pdf:/Users/simeon/Desktop/Recherche/Article/comportement-measure/fdpt.pdf:application/pdf;Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:/home/simeon/Zotero/storage/53JVA87R/Hartley et al. - 2000 - Review of fatigue detection and prediction technol.pdf:application/pdf;fdpt.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/fdpt.pdf:application/pdf},
}

@article{he_driver_2015,
	title = {Driver fatigue evaluation model with integration of multi‐indicators based on dynamic {Bayesian} network},
	volume = {9},
	issn = {1751-9578, 1751-9578},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-its.2014.0103},
	doi = {10.1049/iet-its.2014.0103},
	abstract = {Electroencephalogram (EEG) data are an effective indicator to evaluate driver fatigue, but it is usually disturbed by noise. The frequent head nodding, as well as the time of day and total driving time, also have very close relationship with driver fatigue. All these factors should be taken into account for comprehensive driver fatigue evaluation. 50 drivers are recruited to take part in the fatigue-oriented experiment on the driving simulator. Based on the EEG samples, the EEGbased indicator of driver fatigue has been established by artificial neural network. Subsequently, a new algorithm is present to compute the head nodding angle with posture data from the passive tools fixed on the driver’s head and trunk, respectively, and then head-based indicator of driver fatigue is determined. Finally, a new evaluation model of driver fatigue is established with integration of four fatigue-based indicators with DBN (Dynamic Bayesian Network). The results show that it is more accurate to evaluate the driver fatigue compared with the sole EEG-based indicator.},
	language = {en},
	number = {5},
	urldate = {2021-02-17},
	journal = {IET Intelligent Transport Systems},
	author = {He, Qichang and Li, Wei and Fan, Xiumin and Fei, Zhimin},
	month = jun,
	year = {2015},
	pages = {547--554},
	file = {He et al. - 2015 - Driver fatigue evaluation model with integration o.pdf:/home/simeon/Zotero/storage/6AUMW4CP/He et al. - 2015 - Driver fatigue evaluation model with integration o.pdf:application/pdf},
}

@article{jabon_facial_2011,
	title = {Facial expression analysis for predicting unsafe driving behavior},
	volume = {10},
	issn = {1536-1268},
	url = {http://ieeexplore.ieee.org/document/5456355/},
	doi = {10.1109/MPRV.2010.46},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {IEEE Pervasive Computing},
	author = {Jabon, M. E. and Bailenson, J. N. and Pontikakis, E. and Takayama, L. and Nass, C.},
	month = apr,
	year = {2011},
	pages = {84--95},
	file = {Jabon et al. - 2011 - Facial expression analysis for predicting unsafe d.pdf:/home/simeon/Zotero/storage/SGT6ACGF/Jabon et al. - 2011 - Facial expression analysis for predicting unsafe d.pdf:application/pdf;jabon2011.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/jabon2011.pdf:application/pdf;Jabon et al. - 2011 - Facial expression analysis for predicting unsafe d.pdf:/home/simeon/Zotero/storage/W3R9V4EB/Jabon et al. - 2011 - Facial expression analysis for predicting unsafe d.pdf:application/pdf},
}

@article{ji_real-time_2004,
	title = {Real-{Time} {Nonintrusive} {Monitoring} and {Prediction} of {Driver} {Fatigue}},
	volume = {53},
	issn = {0018-9545},
	url = {http://ieeexplore.ieee.org/document/1317209/},
	doi = {10.1109/TVT.2004.830974},
	abstract = {This paper describes a real-time online prototype driver-fatigue monitor. It uses remotely located charge-coupled-device cameras equipped with active infrared illuminators to acquire video images of the driver. Various visual cues that typically characterize the level of alertness of a person are extracted in real time and systematically combined to infer the fatigue level of the driver. The visual cues employed characterize eyelid movement, gaze movement, head movement, and facial expression. A probabilistic model is developed to model human fatigue and to predict fatigue based on the visual cues obtained. The simultaneous use of multiple visual cues and their systematic combination yields a much more robust and accurate fatigue characterization than using a single visual cue. This system was validated under real-life fatigue conditions with human subjects of different ethnic backgrounds, genders, and ages; with/without glasses; and under different illumination conditions. It was found to be reasonably robust, reliable, and accurate in fatigue characterization.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Ji, Q. and Zhu, Z. and Lan, P.},
	month = jul,
	year = {2004},
	pages = {1052--1068},
	file = {Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:/home/simeon/Zotero/storage/NUET92R9/Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:application/pdf;Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:/home/simeon/Zotero/storage/8DPUGG8P/Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:application/pdf;Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:/home/simeon/Zotero/storage/GFL37FT2/Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:application/pdf;ji2004.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/ji2004.pdf:application/pdf;Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:/home/simeon/Zotero/storage/ETRJR43J/Ji et al. - 2004 - Real-Time Nonintrusive Monitoring and Prediction o.pdf:application/pdf},
}

@article{khan_effective_2018,
	title = {An {Effective} {Framework} for {Driver} {Fatigue} {Recognition} {Based} on {Intelligent} {Facial} {Expressions} {Analysis}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8515199/},
	doi = {10.1109/ACCESS.2018.2878601},
	abstract = {Driver fatigue is a major cause of traffic accidents. Automatic vision-based driver fatigue recognition is one of the most prospective commercial applications based on facial expression analysis technology. Generally, factors like noise, illumination effects, image scaling, and redundant data affect the performance of facial expression recognition systems. In this article, we have proposed an efficient algorithm which is not only capable of working with multi-scale images but is also able to overcome the mentioned obstacles. The proposed framework can be divided into three main phases. In the first step, the input image is converted into four sub-band images by applying a Discrete Wavelet Transform (DWT) which preserves the important information of face image. Also, the original image is down-sampled to obtain the image of different sizes. Based on entropy analysis, each image is then further divided into a number of blocks classified as either informative or non-informative blocks. In the second step, the high variance features are selected in a zigzag manner using Discrete Cosine Transform (DCT). In the final step, classifiers are trained and tested to accurately classify the expressions into seven generic expression classes. The empirical results suggest that the proposed framework not only effectively utilizes the multi-scale images but also outperforms other similar techniques in terms of classification accuracy rate.},
	language = {en},
	urldate = {2021-02-17},
	journal = {IEEE Access},
	author = {Khan, Sajid Ali and Hussain, Shariq and Xiaoming, Sun and Yang, Shunkun},
	year = {2018},
	pages = {67459--67468},
	file = {Khan et al. - 2018 - An Effective Framework for Driver Fatigue Recognit.pdf:/home/simeon/Zotero/storage/AFXZTIUW/Khan et al. - 2018 - An Effective Framework for Driver Fatigue Recognit.pdf:application/pdf;khan2018.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/khan2018.pdf:application/pdf},
}

@inproceedings{krajewski_steering_2009,
	address = {Big Sky, Montana, USA{\textgreater}},
	title = {Steering {Wheel} {Behavior} {Based} {Estimation} of {Fatigue}},
	url = {http://ir.uiowa.edu/drivingassessment/2009/papers/18},
	doi = {10.17077/drivingassessment.1311},
	abstract = {This paper examined a steering behavior based fatigue monitoring system. The advantages of using steering behavior for detecting fatigue are that these systems measure continuously, cheaply, non-intrusively, and robustly even under extremely demanding environmental conditions. The expected fatigue induced changes in steering behavior are a pattern of slow drifting and fast corrective counter steering. Using advanced signal processing procedures for feature extraction, we computed 3 feature set in the time, frequency and state space domain (a total number of 1251 features) to capture fatigue impaired steering patterns. Each feature set was separately fed into 5 machine learning methods (e.g. Support Vector Machine, K-Nearest Neighbor). The outputs of each single classifier were combined to an ensemble classification value. Finally we combined the ensemble values of 3 feature subsets to a of meta-ensemble classification value. To validate the steering behavior analysis, driving samples are taken from a driving simulator during a sleep deprivation study (N=12). We yielded a recognition rate of 86.1\% in classifying slight from strong fatigue.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of the 5th {International} {Driving} {Symposium} on {Human} {Factors} in {Driver} {Assessment}, {Training}, and {Vehicle} {Design} : {Driving} {Assessment} 2009},
	publisher = {University of Iowa},
	author = {Krajewski, Jarek and Sommer, David and Trutschel, Udo and Edwards, Dave and Golz, Martin},
	year = {2009},
	pages = {118--124},
	file = {Steering Wheel Behavior Based Estimation of Fatigue.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/Steering Wheel Behavior Based Estimation of Fatigue.pdf:application/pdf},
}

@article{kuutti_survey_2018,
	title = {A {Survey} of the {State}-of-the-{Art} {Localization} {Techniques} and {Their} {Potentials} for {Autonomous} {Vehicle} {Applications}},
	volume = {5},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/8306879/},
	doi = {10.1109/JIOT.2018.2812300},
	abstract = {For an autonomous vehicle to operate safely and effectively, an accurate and robust localisation system is essential. While there are a variety of vehicle localisation techniques in literature, there is a lack of effort in comparing these techniques and identifying their potentials and limitations for autonomous vehicle applications. Hence, this paper evaluates the state-of-the-art vehicle localisation techniques and investigates their applicability on autonomous vehicles. The analysis starts with discussing the techniques which merely use the information obtained from on-board vehicle sensors. It is shown that although some techniques can achieve the accuracy required for autonomous driving but suffer from the high cost of the sensors and also sensor performance limitations in different driving scenarios (e.g. cornering, intersections) and different environmental conditions (e.g. darkness, snow). The paper continues the analysis with considering the techniques which benefit from off-board information obtained from V2X communication channels, in addition to vehicle sensory information. The analysis shows that augmenting off-board information to sensory information has potential to design low-cost localisation systems with high accuracy and robustness however their performance depends on penetration rate of nearby connected vehicles or infrastructure and the quality of network service.},
	language = {en},
	number = {2},
	urldate = {2021-02-17},
	journal = {IEEE Internet of Things Journal},
	author = {Kuutti, Sampo and Fallah, Saber and Katsaros, Konstantinos and Dianati, Mehrdad and Mccullough, Francis and Mouzakitis, Alexandros},
	month = apr,
	year = {2018},
	pages = {829--846},
	file = {kuutti2018.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/kuutti2018.pdf:application/pdf},
}

@article{lal_critical_2001,
	title = {A critical review of the psychophysiology of driver fatigue},
	volume = {55},
	issn = {03010511},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301051100000855},
	doi = {10.1016/S0301-0511(00)00085-5},
	abstract = {Driver fatigue is a major cause of road accidents and has implications for road safety. This review discusses the concepts of fatigue and provides a summary on psychophysiological associations with driver fatigue. A variety of psychophysiological parameters have been used in previous research as indicators of fatigue, with electroencephalography perhaps being the most promising. Most research found changes in theta and delta activity to be strongly linked to transition to fatigue. Therefore, monitoring electroencephalography during driver fatigue may be a promising variable for use in fatigue countermeasure devices. The review also identiﬁed anxiety and mood states as factors that may possibly affect driver fatigue. Furthermore, personality and temperament may also inﬂuence fatigue. Given the above, understanding the psychology of fatigue may lead to better fatigue management. The ﬁndings from this review are discussed in the light of directions for future studies and for the development of fatigue countermeasures. © 2001 Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Biological Psychology},
	author = {Lal, Saroj K.L. and Craig, Ashley},
	month = feb,
	year = {2001},
	pages = {173--194},
	file = {Lal and Craig - 2001 - A critical review of the psychophysiology of drive.pdf:/home/simeon/Zotero/storage/AIRH3EKD/Lal and Craig - 2001 - A critical review of the psychophysiology of drive.pdf:application/pdf;Lal and Craig - 2001 - A critical review of the psychophysiology of drive.pdf:/home/simeon/Zotero/storage/F3I37D4C/Lal and Craig - 2001 - A critical review of the psychophysiology of drive.pdf:application/pdf;lal2001.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/lal2001.pdf:application/pdf;Lal_Craig_2001_A critical review of the psychophysiology of driver fatigue.pdf:/home/simeon/Zotero/storage/L4MA5BBV/Lal_Craig_2001_A critical review of the psychophysiology of driver fatigue.pdf:application/pdf},
}

@article{lee_stress_2016,
	title = {Stress {Events} {Detection} of {Driver} by {Wearable} {Glove} {System}},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {http://ieeexplore.ieee.org/document/7736144/},
	doi = {10.1109/JSEN.2016.2625323},
	abstract = {This paper is focused to develop a wearable glove system to detect driver stress events in real-time. The driver’s stress is estimated by the use of physiological signals and steering wheel motion analysis. The steering wheel motion is analyzed by driver’s hand moving characteristic. Principally, the sensors on the glove gathered the photoplethysmogram signal via fingertip, and hand motion signal via inertial motion unit. The sensor module readings are transmitted to an end terminal application via a Bluetooth low energy transmission module to compute the driver stress index. The studies are carried out in a simulated driving which is composed of three distinct driving scenarios to study the subjects’ behaviors that correlate with stress. Twentyeight subjects are requested to perform three different driving sessions with random scenarios generated while performing various driving maneuvers to assess the dynamic of mental workloads. The stress assessments of driving test subjects are selfreported at pre- and post-stimulus as well as observed through facial expression recorded throughout the whole experiments. Moreover, this study also aimed to investigate the correlation of stress events with different driving tasks. Stress index are computed by a support vector machine pattern classifier with extracted features from sensors reading. Notably, stress index differences were found among three driving scenarios and driving maneuvers. Results revealed the true accuracy of stress detection is greater than 95\% in average.},
	language = {en},
	urldate = {2021-02-17},
	journal = {IEEE Sensors Journal},
	author = {Lee, Dae Seok and Chong, Teak Wei and Lee, Boon Giin},
	year = {2016},
	pages = {1--1},
	file = {Lee et al. - 2016 - Stress Events Detection of Driver by Wearable Glov.pdf:/home/simeon/Zotero/storage/QET9USHA/Lee et al. - 2016 - Stress Events Detection of Driver by Wearable Glov.pdf:application/pdf;lee2016.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/lee2016.pdf:application/pdf},
}

@article{li_online_2017,
	title = {Online {Detection} of {Driver} {Fatigue} {Using} {Steering} {Wheel} {Angles} for {Real} {Driving} {Conditions}},
	volume = {17},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/17/3/495},
	doi = {10.3390/s17030495},
	abstract = {This paper presents a drowsiness on-line detection system for monitoring driver fatigue level under real driving conditions, based on the data of steering wheel angles (SWA) collected from sensors mounted on the steering lever. The proposed system ﬁrstly extracts approximate entropy (ApEn) features from ﬁxed sliding windows on real-time steering wheel angles time series. After that, this system linearizes the ApEn features series through an adaptive piecewise linear ﬁtting using a given deviation. Then, the detection system calculates the warping distance between the linear features series of the sample data. Finally, this system uses the warping distance to determine the drowsiness state of the driver according to a designed binary decision classiﬁer. The experimental data were collected from 14.68 h driving under real road conditions, including two fatigue levels: “wake” and “drowsy”. The results show that the proposed system is capable of working online with an average 78.01\% accuracy, 29.35\% false detections of the “awake” state, and 15.15\% false detections of the “drowsy” state. The results also conﬁrm that the proposed method based on SWA signal is valuable for applications in preventing trafﬁc accidents caused by driver fatigue.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Li, Zuojin and Li, Shengbo and Li, Renjie and Cheng, Bo and Shi, Jinliang},
	month = mar,
	year = {2017},
	pages = {495},
	file = {li2017.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/li2017.pdf:application/pdf},
}

@article{li_support_2020,
	title = {Support vector machine filtering data aid on fatigue driving detection},
	volume = {309},
	issn = {2261-236X},
	url = {https://www.matec-conferences.org/10.1051/matecconf/202030903036},
	doi = {10.1051/matecconf/202030903036},
	abstract = {This paper proposes an assumption that filtering out the confusing “awake” data from fatigue driving detection model promotes the accuracy of detection of “drowsy” status under real driving situation. Instead of focus on both “drowsy” and “awake” driving status, we set our first priority to alarm “drowsy” and temporarily ignore the accuracy of “awake” status recognition. The Support Vector Machine as a good classifier is employed for data filtering, provides more efficient training data and removes the data that may confuse the detection model. The results prove our assumption by 72\% accuracy on “drowsy” recognition, which is higher than 38\% recognition performed by detection without SVM filtering. In addition, the size of training samples after filtering for conducting detection model is extremely smaller than no filtering.},
	language = {en},
	urldate = {2021-02-17},
	journal = {MATEC Web of Conferences},
	author = {Li, Zuojin and Song, Lei and Yang, Qing and Chen, Shengfu and Chen, Liukui},
	editor = {Joo, J.},
	year = {2020},
	pages = {03036},
	file = {li2020.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/li2020.pdf:application/pdf},
}

@article{liu_predicting_2009,
	title = {Predicting driver drowsiness using vehicle measures: {Recent} insights and future challenges},
	volume = {40},
	issn = {00224375},
	shorttitle = {Predicting driver drowsiness using vehicle measures},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022437509000668},
	doi = {10.1016/j.jsr.2009.04.005},
	abstract = {Introduction: Driver drowsiness is a signiﬁcant contributing factor to road crashes. One approach to tackling this issue is to develop technological countermeasures for detecting driver drowsiness, so that a driver can be warned before a crash occurs. Method: The goal of this review is to assess, given the current state of knowledge, whether vehicle measures can be used to reliably predict drowsiness in real time. Results: Several behavioral experiments have shown that drowsiness can have a serious impact on driving performance in controlled, experimental settings. However, most of those studies have investigated simple functions of performance (such as standard deviation of lane position) and results are often reported as averages across drivers, and across time. Conclusions: Further research is necessary to examine more complex functions, as well as individual differences between drivers. Impact on Industry: A successful countermeasure for predicting driver drowsiness will probably require the setting of multiple criteria, and the use of multiple measures.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {Journal of Safety Research},
	author = {Liu, Charles C. and Hosking, Simon G. and Lenné, Michael G.},
	month = aug,
	year = {2009},
	pages = {239--245},
	file = {liu2009.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/liu2009.pdf:application/pdf},
}

@inproceedings{liu_real-time_2011,
	address = {Hefei, Anhui, China},
	title = {Real-{Time} {Long}-{Range} {Lane} {Detection} and {Tracking} for {Intelligent} {Vehicle}},
	isbn = {978-1-4577-1560-0},
	url = {http://ieeexplore.ieee.org/document/6005947/},
	doi = {10.1109/ICIG.2011.116},
	abstract = {This paper presents a real-time long-range lane detection and tracking approach to meet the requirements of the high-speed intelligent vehicles running on highway roads. Based on a linear-parabolic two-lane highway road model and a novel strong lane marking feature named Lane Marking Segmentation, the maximal lane detection distance of this approach is up to 120 meters. Then the lane lines are selected and tracked by estimating the ego vehicle lateral offset with a Kalman filter. Experiment results with test dataset extracted from real traffic scenes on highway roads show that the approaches proposed in this paper can achieve a high detection rate with a low time cost.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2011 {Sixth} {International} {Conference} on {Image} and {Graphics}},
	publisher = {IEEE},
	author = {Liu, Xin and Dai, Bin and Song, Jinze and He, Hangen and Zhang, Bo},
	month = aug,
	year = {2011},
	pages = {654--659},
	file = {liu2011.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/liu2011.pdf:application/pdf},
}

@article{may_driver_2009,
	title = {Driver fatigue: {The} importance of identifying causal factors of fatigue when considering detection and countermeasure technologies},
	volume = {12},
	issn = {13698478},
	shorttitle = {Driver fatigue},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1369847808001009},
	doi = {10.1016/j.trf.2008.11.005},
	abstract = {Driver fatigue is an ill-deﬁned term in the literature. It has been broadly used to refer to a wide range of driver states, each with different causal mechanisms. Technologies currently exist which enable detection of driver fatigue and interventions that have the potential to dramatically reduce crash probability. The successful implementation of these technologies depends on the cause and type of fatigue experienced. Sleep-related (SR) forms of driver fatigue result from accumulated sleep debt, prolonged wakefulness or troughs in the circadian rhythms. SR fatigue is resistant to most intervention strategies. Conversely, technologies for detecting and countering task-related (TR) fatigue (caused by mental overload or underload) are proving to be effective tools for improving transportation safety. Methods of detecting and counteracting the various forms of driver fatigue are discussed. Emphasis is placed on examining the effectiveness of existing and emerging technologies for combating TR forms of driver fatigue.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {May, Jennifer F. and Baldwin, Carryl L.},
	month = may,
	year = {2009},
	pages = {218--224},
	file = {May and Baldwin - 2009 - Driver fatigue The importance of identifying caus.pdf:/home/simeon/Zotero/storage/B6WX5DUB/May and Baldwin - 2009 - Driver fatigue The importance of identifying caus.pdf:application/pdf;May and Baldwin - 2009 - Driver fatigue The importance of identifying caus.pdf:/home/simeon/Zotero/storage/GCBVFGZK/May and Baldwin - 2009 - Driver fatigue The importance of identifying caus.pdf:application/pdf;may2009.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/may2009.pdf:application/pdf;may2009.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/may2009.pdf:application/pdf},
}

@article{oron-gilad_road_2007,
	title = {Road {Characteristics} and {Driver} {Fatigue}: {A} {Simulator} {Study}},
	volume = {8},
	issn = {1538-9588, 1538-957X},
	shorttitle = {Road {Characteristics} and {Driver} {Fatigue}},
	url = {https://www.tandfonline.com/doi/full/10.1080/15389580701354318},
	doi = {10.1080/15389580701354318},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Traffic Injury Prevention},
	author = {Oron-Gilad, Tal and Ronen, Adi},
	month = aug,
	year = {2007},
	pages = {281--289},
	file = {Oron-Gilad and Ronen - 2007 - Road Characteristics and Driver Fatigue A Simulat.pdf:/home/simeon/Zotero/storage/85PC52FA/Oron-Gilad and Ronen - 2007 - Road Characteristics and Driver Fatigue A Simulat.pdf:application/pdf;oron-gilad2007.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/oron-gilad2007.pdf:application/pdf},
}

@article{oyini_mbouna_visual_2013,
	title = {Visual {Analysis} of {Eye} {State} and {Head} {Pose} for {Driver} {Alertness} {Monitoring}},
	volume = {14},
	issn = {1524-9050, 1558-0016},
	url = {https://ieeexplore.ieee.org/document/6518125},
	doi = {10.1109/TITS.2013.2262098},
	abstract = {This paper presents visual analysis of eye state and head pose (HP) for continuous monitoring of alertness of a vehicle driver. Most existing approaches to visual detection of nonalert driving patterns rely either on eye closure or head nodding angles to determine the driver drowsiness or distraction level. The proposed scheme uses visual features such as eye index (EI), pupil activity (PA), and HP to extract critical information on nonalertness of a vehicle driver. EI determines if the eye is open, half closed, or closed from the ratio of pupil height and eye height. PA measures the rate of deviation of the pupil center from the eye center over a time period. HP ﬁnds the amount of the driver’s head movements by counting the number of video segments that involve a large deviation of three Euler angles of HP, i.e., nodding, shaking, and tilting, from its normal driving position. HP provides useful information on the lack of attention, particularly when the driver’s eyes are not visible due to occlusion caused by large head movements. A support vector machine (SVM) classiﬁes a sequence of video segments into alert or nonalert driving events. Experimental results show that the proposed scheme offers high classiﬁcation accuracy with acceptably low errors and false alarms for people of various ethnicity and gender in real road driving conditions.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Oyini Mbouna, Ralph and Kong, Seong G. and Chun, Myung-Geun},
	month = sep,
	year = {2013},
	pages = {1462--1469},
	file = {Oyini Mbouna et al. - 2013 - Visual Analysis of Eye State and Head Pose for Dri.pdf:/home/simeon/Zotero/storage/7PJDAU2B/Oyini Mbouna et al. - 2013 - Visual Analysis of Eye State and Head Pose for Dri.pdf:application/pdf},
}

@incollection{chaki_feature_2019,
	address = {Singapore},
	title = {Feature {Selection} for {Driver} {Drowsiness} {Detection}},
	volume = {28},
	isbn = {9789811364587 9789811364594},
	url = {http://link.springer.com/10.1007/978-981-13-6459-4_14},
	abstract = {Driver fatigue and sleepiness result in fatal accidents on road, many times. Drowsiness of driver is the major symptom of fatigue. Driver’s attention can be checked from time to time to avoid such situations. This paper aims at detecting the driver’s drowsiness using eye movement to detect open/close eyes. We give a generic design of the system that uses face detection, feature extraction and decision making through a trained model using support vector machine. The paper contribution is in comparing the performance of various feature extraction techniques and evaluating them using standard validation parameters. Features evaluated are the Canny edge, Local Binary Patterns, Histogram of Oriented Gradients (HOG) and Gabor ﬁlter bank, along with the normal gray image. They are evaluated for accuracy and “F1 score.” Among All, HOG outperforms other methods and is a good choice for the application under consideration.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of {International} {Conference} on {Computational} {Intelligence} and {Data} {Engineering}},
	publisher = {Springer Singapore},
	author = {Panda, Saurav and Kolhekar, Megha},
	editor = {Chaki, Nabendu and Devarakonda, Nagaraju and Sarkar, Anirban and Debnath, Narayan C.},
	year = {2019},
	doi = {10.1007/978-981-13-6459-4_14},
	note = {Series Title: Lecture Notes on Data Engineering and Communications Technologies},
	pages = {127--140},
	file = {Panda and Kolhekar - 2019 - Feature Selection for Driver Drowsiness Detection.pdf:/home/simeon/Zotero/storage/5RPVB95B/Panda and Kolhekar - 2019 - Feature Selection for Driver Drowsiness Detection.pdf:application/pdf;10.1007@978-981-13-6459-414.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/10.1007@978-981-13-6459-414.pdf:application/pdf},
}

@article{picot_detection_nodate,
	title = {Détection d'hypovigilance chez le conducteur par fusion d'informations physiologiques et vidéo},
	language = {fr},
	author = {Picot, Antoine},
	pages = {201},
	file = {Picot - Détection d'hypovigilance chez le conducteur par f.pdf:/home/simeon/Zotero/storage/2YGAKF75/Picot - Détection d'hypovigilance chez le conducteur par f.pdf:application/pdf;these.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/these.pdf:application/pdf},
}

@inproceedings{polychronopoulos_information_2004,
	address = {Parma, Italy},
	title = {Information data flow in awake multi-sensor driver monitoring system},
	isbn = {978-0-7803-8310-4},
	url = {http://ieeexplore.ieee.org/document/1336505/},
	doi = {10.1109/IVS.2004.1336505},
	abstract = {Hypovigilance detection and warning systems are currently based on stand alone sensor approaches. This paper presents a multi sensor system that allows the information fision of dflerent sources (vehicle, driver and environmental sensing parameters) and contributes to the decrease of false alarms and misses of the hypovigilance detection system. A hybrid scheme centralized communication and dataflow management of integratedstand alone systems - is adopted, which in turn, allows the real time application to monitor the driver and provide imminent and information messages according to hisher state and adapted to the external traflc and environmental scenario. The data flow between all systems, sensors and modules is described to synthesize the finctional architecture. The system development is .fundedby the European so-called A WAKEproject.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {{IEEE} {Intelligent} {Vehicles} {Symposium}, 2004},
	publisher = {IEEE},
	author = {Polychronopoulos, A. and Amditis, A. and Bekiaris, E.},
	year = {2004},
	pages = {902--906},
	file = {information-data-flow-in-awake-multisensor-driver-monitoring-sys.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/information-data-flow-in-awake-multisensor-driver-monitoring-sys.pdf:application/pdf},
}

@article{ramzan_survey_2019,
	title = {A {Survey} on {State}-of-the-{Art} {Drowsiness} {Detection} {Techniques}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8704263/},
	doi = {10.1109/ACCESS.2019.2914373},
	abstract = {Drowsiness or fatigue is a major cause of road accidents and has significant implications for road safety. Several deadly accidents can be prevented if the drowsy drivers are warned in time. A variety of drowsiness detection methods exist that monitor the drivers’ drowsiness state while driving and alarm the drivers if they are not concentrating on driving. The relevant features can be extracted from facial expressions such as yawning, eye closure and head movements for inferring the level of drowsiness. The biological condition of the drivers’ body, as well as vehicle behavior, is analyzed for driver drowsiness detection. This paper presents a comprehensive analysis of the existing methods of driver drowsiness detection and presents a detailed analysis of widely used classification techniques in this regard. In this research study, first we classify the existing techniques into three categories: behavioral, vehicular and physiological parameters-based techniques. Secondly, top supervised learning techniques used for drowsiness detection are reviewed. Thirdly, the pros and cons and comparative study of the diverse method are discussed. In addition, the research frameworks are elaborated in diagrams for better understanding. In the end, overall research findings based on the extensive survey are concluded which will help young researchers for finding potential future work in the relevant field.},
	language = {en},
	urldate = {2021-02-17},
	journal = {IEEE Access},
	author = {Ramzan, Muhammad and Khan, Hikmat Ullah and Awan, Shahid Mahmood and Ismail, Amina and Ilyas, Mahwish and Mahmood, Ahsan},
	year = {2019},
	pages = {61904--61919},
	file = {Ramzan et al. - 2019 - A Survey on State-of-the-Art Drowsiness Detection .pdf:/home/simeon/Zotero/storage/9FM7WP4C/Ramzan et al. - 2019 - A Survey on State-of-the-Art Drowsiness Detection .pdf:application/pdf;08704263.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/08704263.pdf:application/pdf;A Survey on state-of-the-art Drowsiness Detection Techniques.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_Usefull/A Survey on state-of-the-art Drowsiness Detection Techniques.pdf:application/pdf},
}

@inproceedings{reddy_real-time_2017,
	address = {Honolulu, HI, USA},
	title = {Real-{Time} {Driver} {Drowsiness} {Detection} for {Embedded} {System} {Using} {Model} {Compression} of {Deep} {Neural} {Networks}},
	isbn = {978-1-5386-0733-6},
	url = {http://ieeexplore.ieee.org/document/8014793/},
	doi = {10.1109/CVPRW.2017.59},
	abstract = {Driver’s status is crucial because one of the main reasons for motor vehicular accidents is related to driver’s inattention or drowsiness. Drowsiness detector on a car can reduce numerous accidents. Accidents occur because of a single moment of negligence, thus driver monitoring system which works in real-time is necessary. This detector should be deployable to an embedded device and perform at high accuracy. In this paper, a novel approach towards real-time drowsiness detection based on deep learning which can be implemented on a low cost embedded board and performs with a high accuracy is proposed. Main contribution of our paper is compression of heavy baseline model to a light weight model deployable to an embedded board. Moreover, minimized network structure was designed based on facial landmark input to recognize whether driver is drowsy or not. The proposed model achieved an accuracy of 89.5\% on 3-class classification and speed of 14.9 frames per second (FPS) on Jetson TK1.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Reddy, Bhargava and Kim, Ye-Hoon and Yun, Sojung and Seo, Chanwon and Jang, Junik},
	month = jul,
	year = {2017},
	pages = {438--445},
	file = {Reddy et al. - 2017 - Real-Time Driver Drowsiness Detection for Embedded.pdf:/home/simeon/Zotero/storage/G5WDHRIG/Reddy et al. - 2017 - Real-Time Driver Drowsiness Detection for Embedded.pdf:application/pdf;Reddy_Real-Time_Driver_Drowsiness_CVPR_2017_paper.pdf:/home/simeon/Documents/ING5/Stage/Article/Reddy_Real-Time_Driver_Drowsiness_CVPR_2017_paper.pdf:application/pdf;Reddy_Real-Time_Driver_Drowsiness_CVPR_2017_paper.pdf:/home/simeon/Documents/ING5/Stage/Article/Reddy_Real-Time_Driver_Drowsiness_CVPR_2017_paper.pdf:application/pdf},
}

@incollection{bhatia_investigation_2017,
	address = {Singapore},
	title = {Investigation of {Effectiveness} of {Simple} {Thresholding} for {Accurate} {Yawn} {Detection}},
	volume = {553},
	isbn = {978-981-10-3769-6 978-981-10-3770-2},
	url = {http://link.springer.com/10.1007/978-981-10-3770-2_8},
	abstract = {Drowsiness of a person is major cause for accidents and to avoid accidents alerting person at right time is very necessary. Yawning is one of the signs, which indicates whether the person is drowsy or not. Most of the algorithms in literature detect yawn state considering the region between the lips. Mouth localization is the fundamental step in yawn detection. Region between the lips is segmented using algorithms of different complexities. In this work, a simple segmentation algorithm like thresholding is investigated for its effectiveness. The segmented region with maximum area within the mouth region is considered to classify the frame as yawn frame or otherwise. Yawn video sequences from YawDD dataset are used to test and validate the algorithm. Yawn detection accuracy using the proposed algorithm is 76\% which is bit higher than the accuracy obtained with more complex algorithm. Such simple algorithms might be more useful for real-time applications. The time consumption of the implementation is to be veriﬁed.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Advances in {Computer} and {Computational} {Sciences}},
	publisher = {Springer Singapore},
	author = {Reddy, Viswanath K. and Swathi, K. S.},
	editor = {Bhatia, Sanjiv K. and Mishra, Krishn K. and Tiwari, Shailesh and Singh, Vivek Kumar},
	year = {2017},
	doi = {10.1007/978-981-10-3770-2_8},
	note = {Series Title: Advances in Intelligent Systems and Computing},
	pages = {81--89},
	file = {Reddy and Swathi - 2017 - Investigation of Effectiveness of Simple Threshold.pdf:/home/simeon/Zotero/storage/TCD8WTG7/Reddy and Swathi - 2017 - Investigation of Effectiveness of Simple Threshold.pdf:application/pdf;reddy2017.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/reddy2017.pdf:application/pdf},
}

@inproceedings{rondik_cognitive_2013,
	address = {Hangzhou, China},
	title = {Cognitive event-related potential waveform latency determination: {Based} on result of matching pursuit algorithm and {Hilbert}-{Huang} transform},
	isbn = {978-1-4799-2761-6 978-1-4799-2760-9},
	shorttitle = {Cognitive event-related potential waveform latency determination},
	url = {http://ieeexplore.ieee.org/document/6746935/},
	doi = {10.1109/BMEI.2013.6746935},
	abstract = {According to the statistics of car accident causes [11] given by Police of the Czech Republic, about 17.5 \% of all car accidents are caused by lack of dedication to driving, including microsleep. A lot of car factories develop systems for fatigue prediction and microsleep detection. These systems are usually based on eye movement tracking or steering wheel movement analysis. But both these methods detect consequences of fatigue. From road safety point of view, it would be useful to be able to detect fatigue itself before it affects dedication to driving. We know there could be a correlation between cognitive eventrelated potential (ERP) waveform latency and the rate of attention – the longest the latency is, the more tired the measured subject is. This paper deals with determination of latency of a cognitive ERP waveform from outputs of two algorithms we use for its detection and which we have the best experience with.},
	language = {en},
	urldate = {2020-11-02},
	booktitle = {2013 6th {International} {Conference} on {Biomedical} {Engineering} and {Informatics}},
	publisher = {IEEE},
	author = {Rondik, Tomas and Mautner, Pavel},
	month = dec,
	year = {2013},
	pages = {208--213},
	file = {Rondik and Mautner - 2013 - Cognitive event-related potential waveform latency.pdf:/home/simeon/Zotero/storage/MQ9UHYFE/Rondik and Mautner - 2013 - Cognitive event-related potential waveform latency.pdf:application/pdf;Rondik and Mautner - 2013 - Cognitive event-related potential waveform latency.pdf:/home/simeon/Zotero/storage/P7DV9N3K/Rondik and Mautner - 2013 - Cognitive event-related potential waveform latency.pdf:application/pdf;rondik2013.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/rondik2013.pdf:application/pdf;PID2978121.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/PID2978121.pdf:application/pdf},
}

@article{rosekind_crew_2000,
	title = {Crew {Factors} in {Flight} {Operations} {XIII}: {A} {Survey} of {Fatigue} {Factors} in {Corporate}/{Executive} {Aviation} {Operations}},
	language = {en},
	author = {Rosekind, R and Co, L and Gregory, Kevin B},
	year = {2000},
	pages = {74},
	file = {Rosekind et al. - 2000 - Crew Factors in Flight Operations XIII A Survey o.pdf:/home/simeon/Zotero/storage/KGBL3HCD/Rosekind et al. - 2000 - Crew Factors in Flight Operations XIII A Survey o.pdf:application/pdf;20010039028.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/20010039028.pdf:application/pdf},
}

@inproceedings{thum_chia_chieh_driver_2003,
	address = {Putrajaya, Malaysia},
	title = {Driver fatigue detection using steering grip force},
	isbn = {978-0-7803-8173-5},
	url = {http://ieeexplore.ieee.org/document/1459661/},
	doi = {10.1109/SCORED.2003.1459661},
	abstract = {This paper describes an automobile driver fatigue detection method by monitoring the driver's grip force on the steering wheel, based on the variation in steering grip force due to fatigue or loosing alertness. Steering grip force data is obtained by using two resistive force sensors attached to the steering wheel and connected to a personal computer with the aid of a data acquisition module. The alertness of the driver is then assessed by utilizing change detection algorithm based on Iog-likelihood ratio. The aforementioned system is a module of a driver safety system for smart vehicle, which uses sensor fusion technology to prevent driverrelated road accidents.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings. {Student} {Conference} on {Research} and {Development}, 2003. {SCORED} 2003.},
	publisher = {IEEE},
	author = {{Thum Chia Chieh} and Mustafa, M.M. and Hussain, A. and Zahedi, E. and Majlis, B.Y.},
	year = {2003},
	pages = {45--48},
	file = {driver-fatigue-detection-using-steering-grip-force.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/driver-fatigue-detection-using-steering-grip-force.pdf:application/pdf},
}

@article{sahayadhas_detecting_2012,
	title = {Detecting {Driver} {Drowsiness} {Based} on {Sensors}: {A} {Review}},
	volume = {12},
	issn = {1424-8220},
	shorttitle = {Detecting {Driver} {Drowsiness} {Based} on {Sensors}},
	url = {http://www.mdpi.com/1424-8220/12/12/16937},
	doi = {10.3390/s121216937},
	abstract = {In recent years, driver drowsiness has been one of the major causes of road accidents and can lead to severe physical injuries, deaths and significant economic losses. Statistics indicate the need of a reliable driver drowsiness detection system which could alert the driver before a mishap happens. Researchers have attempted to determine driver drowsiness using the following measures: (1) vehicle-based measures; (2) behavioral measures and (3) physiological measures. A detailed review on these measures will provide insight on the present systems, issues associated with them and the enhancements that need to be done to make a robust system. In this paper, we review these three measures as to the sensors used and discuss the advantages and limitations of each. The various ways through which drowsiness has been experimentally manipulated is also discussed. We conclude that by designing a hybrid drowsiness detection system that combines non-intusive physiological measures with other measures one would accurately determine the drowsiness level of a driver. A number of road accidents might then be avoided if an alert is sent to a driver that is deemed drowsy.},
	language = {en},
	number = {12},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Sahayadhas, Arun and Sundaraj, Kenneth and Murugappan, Murugappan},
	month = dec,
	year = {2012},
	pages = {16937--16953},
	file = {Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:/home/simeon/Zotero/storage/B2TQCHWI/Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:application/pdf;Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:/home/simeon/Zotero/storage/29WLX7HI/Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:application/pdf;sensors-12-16937.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/sensors-12-16937.pdf:application/pdf;Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:/home/simeon/Zotero/storage/TFUVQ3FK/Sahayadhas et al. - 2012 - Detecting Driver Drowsiness Based on Sensors A Re.pdf:application/pdf},
}

@article{schleicher_blinks_2008,
	title = {Blinks and saccades as indicators of fatigue in sleepiness warnings: looking tired?},
	volume = {51},
	issn = {0014-0139, 1366-5847},
	shorttitle = {Blinks and saccades as indicators of fatigue in sleepiness warnings},
	url = {https://www.tandfonline.com/doi/full/10.1080/00140130701817062},
	doi = {10.1080/00140130701817062},
	language = {en},
	number = {7},
	urldate = {2021-02-17},
	journal = {Ergonomics},
	author = {Schleicher, R. and Galley, N. and Briest, S. and Galley, L.},
	month = jul,
	year = {2008},
	pages = {982--1010},
	file = {Schleicher et al. - 2008 - Blinks and saccades as indicators of fatigue in sl.pdf:/home/simeon/Zotero/storage/EER5MEZD/Schleicher et al. - 2008 - Blinks and saccades as indicators of fatigue in sl.pdf:application/pdf;Schleicher et al. - 2008 - Blinks and saccades as indicators of fatigue in sl.pdf:/home/simeon/Zotero/storage/96W8TLGF/Schleicher et al. - 2008 - Blinks and saccades as indicators of fatigue in sl.pdf:application/pdf;schleicher2008.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/schleicher2008.pdf:application/pdf},
}

@incollection{chen_mstn_2017,
	address = {Cham},
	title = {{MSTN}: {Multistage} {Spatial}-{Temporal} {Network} for {Driver} {Drowsiness} {Detection}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	shorttitle = {{MSTN}},
	url = {http://link.springer.com/10.1007/978-3-319-54526-4_11},
	abstract = {Recent survey has shown that drowsy driving is one of the main factors in fatal motor vehicle crashes. In this paper, given only the visual information of the driver, we propose a Multistage SpatialTemporal Network (MSTN) to eﬃciently and accurately detect driver drowsiness. The proposed MSTN consists of a spatial CNN, a temporal LSTM, and then followed by a temporal smoothing. Firstly, we use the spatial CNN to eﬀectively extract drowsiness-related features from the face region detected from each video frame. Then, we model the temporal variation of the drowsiness status by feeding a sequence of frame-level features into the Long Short Term Memory (LSTM). Finally, we conduct the temporal smoothing to smooth the predicted drowsiness scores in order to avoid noisy predictions. We evaluate the proposed MSTN using NTHU Drowsy Driver Detection Video Dataset and achieve 82.61\% overall accuracy on the testing set.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Shih, Tun-Huai and Hsu, Chiou-Ting},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_11},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {a résumer},
	pages = {146--153},
	file = {Shih and Hsu - 2017 - MSTN Multistage Spatial-Temporal Network for Driv.pdf:/home/simeon/Zotero/storage/Q2EIRJ2I/Shih and Hsu - 2017 - MSTN Multistage Spatial-Temporal Network for Driv.pdf:application/pdf;MSTN\: Multistage Spatial-Temporal Network for Driver Drowsiness Detection.pdf:/home/simeon/Documents/ING5/Stage/Article/MSTN\: Multistage Spatial-Temporal Network for Driver Drowsiness Detection.pdf:application/pdf},
}

@inproceedings{siegmund_correlation_1996,
	title = {Correlation of {Steering} {Behavior} with {Heavy}-{Truck} {Driver} {Fatigue}},
	url = {https://www.sae.org/content/961683/},
	doi = {10.4271/961683},
	abstract = {This paper continues the analysis of data published previously, focusing on steering wheel behavior and its correlation with driver fatigue (as measured by EEG, heart rate, and subjective evaluation of drowsiness from video). New steering-based weighting functions devised from observed changes in steering wheel motions are presented. Significant correlations between the weighting functions and the measures of driver fatigue suggest that some of the functions could form the basis of a fatigue-detection algorithm.},
	language = {en},
	urldate = {2021-02-17},
	author = {Siegmund, Gunter P. and King, David J. and Mumford, David K.},
	month = aug,
	year = {1996},
	pages = {961683},
	file = {siegmund1996.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/siegmund1996.pdf:application/pdf},
}

@inproceedings{sigari_driver_2009,
	address = {Kolkata, West Bengal, India},
	title = {Driver {Hypo}-vigilance {Detection} {Based} on {Eyelid} {Behavior}},
	isbn = {978-0-7695-3520-3 978-1-4244-3335-3},
	url = {http://ieeexplore.ieee.org/document/4782824/},
	doi = {10.1109/ICAPR.2009.108},
	abstract = {Driver face monitoring system is a real-time system that can detect driver fatigue and driver distraction using machine vision approaches. In this paper, a new algorithm is proposed for driver hypo-vigilance detection based on eye-region processing and without explicit eye detection stage. In this method, horizontal projection of top half-segment of facial image is used to extract symptoms of fatigue and distraction. Percentage of eye closure (PERCLOS) and eyelid distance changes during time are used for fatigue detection; and eye closure rate is used for distraction detection. The novelty of our method is in adaptive feature extraction using spatio-temporal processing without explicit eye detection. Processing rate of proposed method is more than 5 frames per second.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2009 {Seventh} {International} {Conference} on {Advances} in {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Sigari, Mohamad Hoseyn},
	month = feb,
	year = {2009},
	pages = {426--429},
	file = {Sigari - 2009 - Driver Hypo-vigilance Detection Based on Eyelid Be.pdf:/home/simeon/Zotero/storage/TAFUTX86/Sigari - 2009 - Driver Hypo-vigilance Detection Based on Eyelid Be.pdf:application/pdf},
}

@article{sikander_driver_2019,
	title = {Driver {Fatigue} {Detection} {Systems}: {A} {Review}},
	volume = {20},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Driver {Fatigue} {Detection} {Systems}},
	url = {https://ieeexplore.ieee.org/document/8482470/},
	doi = {10.1109/TITS.2018.2868499},
	abstract = {Driver fatigue has been attributed to trafﬁc accidents; therefore, fatigue-related trafﬁc accidents have a higher fatality rate and cause more damage to the surroundings compared with accidents where the drivers are alert. Recently, many automobile companies have installed driver assistance technologies in vehicles for driver assistance. Third party companies are also manufacturing fatigue detection devices; however, much research is still required for improvement. In the ﬁeld of driver fatigue detection, continuous research is being performed and several articles propose promising results in constrained environments, still much progress is required. This paper presents state-of-the-art review of recent advancement in the ﬁeld of driver fatigue detection. Methods are categorized into ﬁve groups, i.e., subjective reporting, driver biological features, driver physical features, vehicular features while driving, and hybrid features depending on the features used for driver fatigue detection. Various approaches have been compared for fatigue detection, and areas open for improvements are deduced.},
	language = {en},
	number = {6},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Sikander, Gulbadan and Anwar, Shahzad},
	month = jun,
	year = {2019},
	pages = {2339--2352},
	file = {Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:/home/simeon/Zotero/storage/GLHTA7S3/Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:application/pdf;Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:/home/simeon/Zotero/storage/49SPGSRQ/Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:application/pdf;Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:/home/simeon/Zotero/storage/3BYHBHW8/Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:application/pdf;Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:/home/simeon/Zotero/storage/7TGE48YQ/Sikander and Anwar - 2019 - Driver Fatigue Detection Systems A Review.pdf:application/pdf;Driver Fatigue Detection Systems A Review.pdf:/home/simeon/Documents/ING5/Stage/Article/Driver Fatigue Detection Systems A Review.pdf:application/pdf},
}

@article{solaz_drowsiness_2016,
	title = {Drowsiness {Detection} {Based} on the {Analysis} of {Breathing} {Rate} {Obtained} from {Real}-time {Image} {Recognition}},
	volume = {14},
	issn = {23521465},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352146516304793},
	doi = {10.1016/j.trpro.2016.05.472},
	language = {en},
	urldate = {2021-02-17},
	journal = {Transportation Research Procedia},
	author = {Solaz, José and Laparra-Hernández, José and Bande, Daniel and Rodríguez, Noelia and Veleff, Sergio and Gerpe, José and Medina, Enrique},
	year = {2016},
	pages = {3867--3876},
	file = {Solaz et al. - 2016 - Drowsiness Detection Based on the Analysis of Brea.pdf:/home/simeon/Zotero/storage/ZI2I8RWU/Solaz et al. - 2016 - Drowsiness Detection Based on the Analysis of Brea.pdf:application/pdf;solaz2016.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/solaz2016.pdf:application/pdf;Solaz et al. - 2016 - Drowsiness Detection Based on the Analysis of Brea.pdf:/home/simeon/Zotero/storage/7TMQHB35/Solaz et al. - 2016 - Drowsiness Detection Based on the Analysis of Brea.pdf:application/pdf},
}

@article{thiffault_monotony_2003,
	title = {Monotony of road environment and driver fatigue: a simulator study},
	volume = {35},
	issn = {00014575},
	shorttitle = {Monotony of road environment and driver fatigue},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457502000143},
	doi = {10.1016/S0001-4575(02)00014-3},
	abstract = {Studies have shown that drowsiness and hypovigilance frequently occur during highway driving and that they may have serious implications in terms of accident causation. This paper focuses on the task induced factors that are involved in the development of these phenomena. A driving simulator study was conducted in order to evaluate the impact of the monotony of roadside visual stimulation using a steering wheel movement (SWM) analysis procedure. Fifty-six male subjects each drove during two different 40-min periods. In one case, roadside visual stimuli were essentially repetitive and monotonous, while in the other one, the environment contained disparate visual elements aiming to disrupt monotony without changing road geometry. Subject’s driving performance was compared across these conditions in order to determine whether disruptions of monotony can have a positive effect and help alleviate driver fatigue. Results reveal an early time-on-task effect on driving performance for both driving periods and more frequent large SWM when driving in the more monotonous road environment, which implies greater fatigue and vigilance decrements. Implications in terms of environmental countermeasures for driver fatigue are discussed. © 2002 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Accident Analysis \& Prevention},
	author = {Thiffault, Pierre and Bergeron, Jacques},
	month = may,
	year = {2003},
	pages = {381--391},
	file = {Thiffault and Bergeron - 2003 - Monotony of road environment and driver fatigue a.pdf:/home/simeon/Zotero/storage/PNF68LMK/Thiffault and Bergeron - 2003 - Monotony of road environment and driver fatigue a.pdf:application/pdf;thiffault2003.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/thiffault2003.pdf:application/pdf},
}

@article{ting_driver_2008,
	title = {Driver fatigue and highway driving: {A} simulator study},
	volume = {94},
	issn = {00319384},
	shorttitle = {Driver fatigue and highway driving},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031938408000681},
	doi = {10.1016/j.physbeh.2008.02.015},
	abstract = {Long duration of driving is a signiﬁcant cause of fatigue-related accidents on motorways or major roadways. The fatigue caused by driving for extended periods acutely impairs driver alertness and performance and can compromise transportation safety. This study quantitatively measured the progression of driver fatigue and identiﬁed the conservative safe duration of continuous highway driving. Thirty young male subjects were analyzed during 90 min of laboratory-simulated highway driving. Sleepiness ratings (SSS) and reaction time (RT) tests were used to assess impairment of driver alertness and vigilance. Additionally, various measures of driving performance recorded throughout the experiment were used to measure temporal deterioration of driver performance from alert to fatigued using principal component analysis (PCA). The analytical results revealed that SSS scores, reaction times (RTs) and unstable driving performance signiﬁcantly increased over time, indicating that excessive driving time is a signiﬁcant fatigue factor and potential cause of fatigue-related accidents. Moreover, the analytical results indicated that 80 min was the safe limit for monotonous highway driving. Based on the experimental ﬁndings of this study, public awareness of the adverse affects of driver fatigue during long-distance driving should be enhanced. This study provides explicit information of fatigue development that can be used to prevent fatigue-related accidents.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {Physiology \& Behavior},
	author = {Ting, Ping-Huang and Hwang, Jiun-Ren and Doong, Ji-Liang and Jeng, Ming-Chang},
	month = jun,
	year = {2008},
	pages = {448--453},
	file = {Ting et al. - 2008 - Driver fatigue and highway driving A simulator st.pdf:/home/simeon/Zotero/storage/6C3ARN75/Ting et al. - 2008 - Driver fatigue and highway driving A simulator st.pdf:application/pdf;ting2008.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/ting2008.pdf:application/pdf},
}

@article{vicente_drowsiness_2016,
	title = {Drowsiness detection using heart rate variability},
	volume = {54},
	issn = {0140-0118, 1741-0444},
	url = {http://link.springer.com/10.1007/s11517-015-1448-7},
	doi = {10.1007/s11517-015-1448-7},
	language = {en},
	number = {6},
	urldate = {2020-11-02},
	journal = {Medical \& Biological Engineering \& Computing},
	author = {Vicente, José and Laguna, Pablo and Bartra, Ariadna and Bailón, Raquel},
	month = jun,
	year = {2016},
	pages = {927--937},
	file = {Vicente et al. - 2016 - Drowsiness detection using heart rate variability.pdf:/home/simeon/Zotero/storage/XK74CRM3/Vicente et al. - 2016 - Drowsiness detection using heart rate variability.pdf:application/pdf;Vicente et al. - 2016 - Drowsiness detection using heart rate variability.pdf:/home/simeon/Zotero/storage/QGMG7B7N/Vicente et al. - 2016 - Drowsiness detection using heart rate variability.pdf:application/pdf;vicente2016.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/vicente2016.pdf:application/pdf;PepoHRV.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/PepoHRV.pdf:application/pdf},
}

@inproceedings{weiwei_liu_driver_2010,
	address = {Chengdu, China},
	title = {Driver fatigue detection through pupil detection and yawing analysis},
	isbn = {978-1-4244-6775-4},
	url = {http://ieeexplore.ieee.org/document/5478931/},
	doi = {10.1109/ICBBT.2010.5478931},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2010 {International} {Conference} on {Bioinformatics} and {Biomedical} {Technology}},
	publisher = {IEEE},
	author = {{Weiwei Liu} and {Haixin Sun} and {Weijie Shen}},
	year = {2010},
	pages = {404--407},
	file = {Weiwei Liu et al. - 2010 - Driver fatigue detection through pupil detection a.pdf:/home/simeon/Zotero/storage/QAMRDZ3L/Weiwei Liu et al. - 2010 - Driver fatigue detection through pupil detection a.pdf:application/pdf;weiweiliu2010.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/weiweiliu2010.pdf:application/pdf},
}

@article{yang_driver_2010,
	title = {A driver fatigue recognition model based on information fusion and dynamic {Bayesian} network},
	volume = {180},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025510000253},
	doi = {10.1016/j.ins.2010.01.011},
	abstract = {We propose a driver fatigue recognition model based on the dynamic Bayesian network, information fusion and multiple contextual and physiological features. We include features such as the contact physiological features (e.g., ECG and EEG), and apply the ﬁrst-order Hidden Markov Model to compute the dynamics of the Bayesian network at different time slices. The experimental validation shows the effectiveness of the proposed system; also it indicates that the contact physiological features (especially ECG and EEG) are signiﬁcant factors for inferring the fatigue state of a driver.},
	language = {en},
	number = {10},
	urldate = {2021-02-17},
	journal = {Information Sciences},
	author = {Yang, Guosheng and Lin, Yingzi and Bhattacharya, Prabir},
	month = may,
	year = {2010},
	pages = {1942--1954},
	file = {Yang et al. - 2010 - A driver fatigue recognition model based on inform.pdf:/home/simeon/Zotero/storage/26BH3TB8/Yang et al. - 2010 - A driver fatigue recognition model based on inform.pdf:application/pdf},
}

@inproceedings{zhenhai_driver_2017,
	address = {Changsha, China},
	title = {Driver {Drowsiness} {Detection} {Based} on {Time} {Series} {Analysis} of {Steering} {Wheel} {Angular} {Velocity}},
	isbn = {978-1-5090-4868-7},
	url = {http://ieeexplore.ieee.org/document/7832194/},
	doi = {10.1109/ICMTMA.2017.0031},
	abstract = {A novel driver drowsiness detection method based on time series analysis of the steering wheel angular velocity is proposed in this paper. Firstly, the steering behavior under the fatigue state is analyzed, followed by the determination of the temporal detection window; and then, the data series of the steering wheel angular velocity in the temporal detection window is selected as the detection feature. IF the detection feature satisfies the extent constraint and the variability constraint in the temporal window, a drowsiness state is detected accordingly. At last, experiment tests validate our method has good performance and could be well used in the real world.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2017 9th {International} {Conference} on {Measuring} {Technology} and {Mechatronics} {Automation} ({ICMTMA})},
	publisher = {IEEE},
	author = {Zhenhai, Gao and DinhDat, Le and Hongyu, Hu and Ziwen, Yu and Xinyu, Wu},
	month = jan,
	year = {2017},
	pages = {99--101},
	file = {zhenhai2017.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/zhenhai2017.pdf:application/pdf},
}

@article{delgado-bonal_approximate_2019,
	title = {Approximate {Entropy} and {Sample} {Entropy}: {A} {Comprehensive} {Tutorial}},
	volume = {21},
	issn = {1099-4300},
	shorttitle = {Approximate {Entropy} and {Sample} {Entropy}},
	url = {https://www.mdpi.com/1099-4300/21/6/541},
	doi = {10.3390/e21060541},
	abstract = {Approximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different ﬁelds. While initially developed for physiological applications, both algorithms have been used in other ﬁelds such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.},
	language = {en},
	number = {6},
	urldate = {2021-02-17},
	journal = {Entropy},
	author = {Delgado-Bonal, Alfonso and Marshak, Alexander},
	month = may,
	year = {2019},
	pages = {541},
	file = {delgado-bonal2019.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/delgado-bonal2019.pdf:application/pdf},
}

@article{dasgupta_vision-based_2013,
	title = {A {Vision}-{Based} {System} for {Monitoring} the {Loss} of {Attention} in {Automotive} {Drivers}},
	volume = {14},
	issn = {1524-9050, 1558-0016},
	url = {https://ieeexplore.ieee.org/document/6565376},
	doi = {10.1109/TITS.2013.2271052},
	abstract = {Onboard monitoring of the alertness level of an automotive driver has been challenging to research in transportation safety and management. In this paper, we propose a robust realtime embedded platform to monitor the loss of attention of the driver during day and night driving conditions. The percentage of eye closure has been used to indicate the alertness level. In this approach, the face is detected using Haar-like features and is tracked using a Kalman ﬁlter. The eyes are detected using principal component analysis during daytime and using the block local-binary-pattern features during nighttime. Finally, the eye state is classiﬁed as open or closed using support vector machines. In-plane and off-plane rotations of the driver’s face have been compensated using afﬁne transformation and perspective transformation, respectively. Compensation in illumination variation is carried out using bihistogram equalization. The algorithm has been cross-validated using brain signals and, ﬁnally, has been implemented on a single-board computer that has an Intel Atom processor with a 1.66-GHz clock, a random access memory of 1 GB, ×86 architecture, and a Windows-embedded XP operating system. The system is found to be robust under actual driving conditions.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Dasgupta, Anirban and George, Anjith and Happy, S. L. and Routray, Aurobinda},
	month = dec,
	year = {2013},
	pages = {1825--1838},
	file = {Dasgupta et al. - 2013 - A Vision-Based System for Monitoring the Loss of A.pdf:/home/simeon/Zotero/storage/8893FCQE/Dasgupta et al. - 2013 - A Vision-Based System for Monitoring the Loss of A.pdf:application/pdf;dasgupta2013.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/dasgupta2013.pdf:application/pdf},
}

@article{damousis_fuzzy_2009,
	title = {A fuzzy expert system for the early warning of accidents due to driver hypo-vigilance},
	volume = {13},
	issn = {1617-4909, 1617-4917},
	url = {http://link.springer.com/10.1007/s00779-007-0170-3},
	doi = {10.1007/s00779-007-0170-3},
	abstract = {In this paper a fuzzy expert system for the prediction of hypovigilance-related accidents is presented. The system uses physiological modalities in order to detect signs of extreme hypovigilance. An advantage of such a system is its extensibility regarding the physiological modalities and features that it can use as inputs. In that way, even though at present only eyelid-related features are exploited, in the future and for prototypes designed for professionals other physiological modalities, such as EEG can be easily integrated into the existing system in order to make it more robust and reliable.},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {Personal and Ubiquitous Computing},
	author = {Damousis, I. G. and Tzovaras, D. and Strintzis, M. G.},
	month = jan,
	year = {2009},
	pages = {43--49},
	file = {Damousis et al. - 2009 - A fuzzy expert system for the early warning of acc.pdf:/home/simeon/Zotero/storage/XM2E2RHU/Damousis et al. - 2009 - A fuzzy expert system for the early warning of acc.pdf:application/pdf;damousis2007.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/damousis2007.pdf:application/pdf},
}

@inproceedings{dorazio_sensor_2011,
	address = {Grenoble},
	title = {Sensor networks on the car: {State} of the art and future challenges},
	isbn = {978-3-9810801-8-6 978-1-61284-208-0 978-3-9810801-7-9},
	shorttitle = {Sensor networks on the car},
	url = {http://ieeexplore.ieee.org/document/5763169/},
	doi = {10.1109/DATE.2011.5763169},
	abstract = {Modern cars are equipped with hundreds of sensors, not only used in the traditional powertrain, chassis, and body areas, but also in more advanced applications related to multimedia, infotainment, and x-by-wire systems. Such a big quantity of sensing elements require a particular attention in the design phase of the in-vehicle communication networks. This paper provides an overview of the most commonly used automotive sensors and describes the traditional networks nowadays used to collect their measurements. Moreover, it considers some possible alternative solutions that could be used in the future to have a single uniform network as asked by the automotive industry in order to reduce weight, space, and cost of the communication system.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2011 {Design}, {Automation} \& {Test} in {Europe}},
	publisher = {IEEE},
	author = {D'Orazio, L and Visintainer, F and Darin, M},
	month = mar,
	year = {2011},
	pages = {1--6},
	file = {10.1109@DATE.2011.5763169.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/10.1109@DATE.2011.5763169.pdf:application/pdf},
}

@article{choi_wearable_2018,
	title = {Wearable {Device}-{Based} {System} to {Monitor} a {Driver}’s {Stress}, {Fatigue}, and {Drowsiness}},
	volume = {67},
	issn = {0018-9456, 1557-9662},
	url = {http://ieeexplore.ieee.org/document/8234669/},
	doi = {10.1109/TIM.2017.2779329},
	abstract = {This paper proposes a wearable device-based system to monitor the abnormal conditions of a driver, including stress, fatigue, and drowsiness. The system measures the motional and physiological information of the driver using the developed wearable device on the wrist. Preprocessing is used to distinguish the valid signal parts of the measured signals, because various noises can occur in wearable sensors. Features are extracted from the signal parts, and an optimal feature set is determined by an analysis of variance and a sequential ﬂoating forward selection algorithm. To classify the driver’s state, a support vector machine-based classiﬁcation method is used to obtain high generalization performance considering interdriver variance. Experiments were conducted on an indoor driving simulator, with 28 subjects, to gather data for each state. The classiﬁcation accuracy was 98.43\% for ﬁvefold cross validation on the data. In a subject-independent test, the accuracy was 68.31\% for the four states and 84.46\% for the three states consisting of normal, stressed, and fatigued or drowsy states. Using the proposed system, the abnormal conditions of the driver can be detected and distinguished. This advantage contributes to safer and more comfortable driving. Furthermore, the utilization of the wearable device makes the system easy to use.},
	language = {en},
	number = {3},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Instrumentation and Measurement},
	author = {Choi, Minho and Koo, Gyogwon and Seo, Minseok and Kim, Sang Woo},
	month = mar,
	year = {2018},
	pages = {634--645},
	file = {Choi et al. - 2018 - Wearable Device-Based System to Monitor a Driver’s.pdf:/home/simeon/Zotero/storage/EPRRUYBN/Choi et al. - 2018 - Wearable Device-Based System to Monitor a Driver’s.pdf:application/pdf;choi2017.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/choi2017.pdf:application/pdf},
}

@article{choi_driver-adaptive_2018,
	title = {Driver-{Adaptive} {Vehicle} {Interaction} {System} for the {Advanced} {Digital} {Cockpit}},
	abstract = {In this paper, we introduce three key components of the next-generation digital cockpit system to provide the drivercustomized driving environment, which indicates automotive sensor network, driver-adaptive interaction engine, and advanced digital cockpit platform. Our concept of driver-adaptive vehicle interaction system includes driving performance evaluation, driver status recognition, and driver emotion recognition. To realize driver-adaptive interaction engine of the advanced digital cockpit system, we explain the hierarchical customization levels and the cycle of the driver-vehicle interaction process.},
	language = {en},
	author = {Choi, Jin-Kyu and Kim, Kyongho and Kim, Dohyun and Choi, Hyunkyun and Jang, Byungtae},
	year = {2018},
	pages = {4},
	file = {Choi et al. - 2018 - Driver-Adaptive Vehicle Interaction System for the.pdf:/home/simeon/Zotero/storage/8FPMNT8V/Choi et al. - 2018 - Driver-Adaptive Vehicle Interaction System for the.pdf:application/pdf;choi2018.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/choi2018.pdf:application/pdf;choi2018.pdf:/Users/simeon/Desktop/Recherche/Article/choi2018.pdf:application/pdf},
}

@article{cheng_driver_2012,
	title = {Driver drowsiness detection based on multisource information: {Driver} {Drowsiness} {Detection} {Based} on {Multisource} {Information}},
	volume = {22},
	issn = {10908471},
	shorttitle = {Driver drowsiness detection based on multisource information},
	url = {http://doi.wiley.com/10.1002/hfm.20395},
	doi = {10.1002/hfm.20395},
	abstract = {Driver drowsiness is one of the major causes of on-road accidents. Abnormal eye behavior, steering wheel activity, and vehicle trajectory during different drowsiness stages were studied in detail to overcome the limitations of single-sensor approaches. Some measures, such as percentage of eyelid closure, maximum close duration, and percentage of nonsteering were analyzed using analysis of variance (ANOVA) methods. Moreover, a two-stage data fusion framework was developed for the modeling combination of information from different sources. Fisher’s linear discriminant was implied as the feature-level fusion method, and Dempster-Shafer evidence theory was introduced in the decision-level fusion process. The results suggest that the recognition system proposed here provided 90.7\% accuracy. The reliability and accuracy of the fusion method were signiﬁcantly higher than those of single sensors. C 2012 Wiley Periodicals, Inc.},
	language = {en},
	number = {5},
	urldate = {2021-02-17},
	journal = {Human Factors and Ergonomics in Manufacturing \& Service Industries},
	author = {Cheng, Bo and Zhang, Wei and Lin, Yingzi and Feng, Ruijia and Zhang, Xibo},
	month = sep,
	year = {2012},
	pages = {450--467},
	file = {Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:/home/simeon/Zotero/storage/YZVLK59V/Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:application/pdf;Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:/home/simeon/Zotero/storage/MZIENGMU/Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:application/pdf;Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:/home/simeon/Zotero/storage/PX69YD43/Cheng et al. - 2012 - Driver drowsiness detection based on multisource i.pdf:application/pdf;Driver Drowsiness Detection Based on Multisource Information.pdf:/home/simeon/Documents/ING5/Stage/Article/Driver Drowsiness Detection Based on
Multisource Information.pdf:application/pdf},
}

@article{chen_identification_2015,
	title = {Identification of common features of vehicle motion under drowsy/distracted driving: {A} case study in {Wuhan}, {China}},
	volume = {81},
	issn = {00014575},
	shorttitle = {Identification of common features of vehicle motion under drowsy/distracted driving},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457515000706},
	doi = {10.1016/j.aap.2015.02.021},
	language = {en},
	urldate = {2021-02-17},
	journal = {Accident Analysis \& Prevention},
	author = {Chen, Zhijun and Wu, Chaozhong and Zhong, Ming and Lyu, Nengchao and Huang, Zhen},
	month = aug,
	year = {2015},
	pages = {251--259},
	file = {chen2015.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/chen2015.pdf:application/pdf},
}

@article{bishop_intelligent_2000,
	title = {Intelligent vehicle applications worldwide},
	volume = {15},
	issn = {1094-7167},
	url = {http://ieeexplore.ieee.org/document/820333/},
	doi = {10.1109/5254.820333},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {IEEE Intelligent Systems},
	author = {Bishop, R.},
	month = jan,
	year = {2000},
	pages = {78--81},
	file = {Bishop - 2000 - Intelligent vehicle applications worldwide.pdf:/home/simeon/Zotero/storage/MCM2RTBB/Bishop - 2000 - Intelligent vehicle applications worldwide.pdf:application/pdf;5254.820333.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/5254.820333.pdf:application/pdf;bishop2000.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/bishop2000.pdf:application/pdf},
}

@inproceedings{bianco_multimodal_2019,
	address = {Trento Italy},
	title = {Multimodal {Car} {Driver} {Stress} {Recognition}},
	isbn = {978-1-4503-6126-2},
	url = {https://dl.acm.org/doi/10.1145/3329189.3329221},
	doi = {10.1145/3329189.3329221},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of the 13th {EAI} {International} {Conference} on {Pervasive} {Computing} {Technologies} for {Healthcare}},
	publisher = {ACM},
	author = {Bianco, Simone and Napoletano, Paolo and Schettini, Raimondo},
	month = may,
	year = {2019},
	pages = {302--307},
	file = {Bianco et al. - 2019 - Multimodal Car Driver Stress Recognition.pdf:/home/simeon/Zotero/storage/5T6Y8C36/Bianco et al. - 2019 - Multimodal Car Driver Stress Recognition.pdf:application/pdf;3329189.3329221.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/3329189.3329221.pdf:application/pdf},
}

@article{bergasa_real-time_2006,
	title = {Real-{Time} {System} for {Monitoring} {Driver} {Vigilance}},
	volume = {7},
	issn = {1524-9050},
	url = {http://ieeexplore.ieee.org/document/1603553/},
	doi = {10.1109/TITS.2006.869598},
	abstract = {This paper presents a nonintrusive prototype computer vision system for monitoring a driver’s vigilance in real time. It is based on a hardware system for the real-time acquisition of a driver’s images using an active IR illuminator and the software implementation for monitoring some visual behaviors that characterize a driver’s level of vigilance. Six parameters are calculated: Percent eye closure (PERCLOS), eye closure duration, blink frequency, nodding frequency, face position, and ﬁxed gaze. These parameters are combined using a fuzzy classiﬁer to infer the level of inattentiveness of the driver. The use of multiple visual parameters and the fusion of these parameters yield a more robust and accurate inattention characterization than by using a single parameter. The system has been tested with different sequences recorded in night and day driving conditions in a motorway and with different users. Some experimental results and conclusions about the performance of the system are presented.},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Bergasa, L.M. and Nuevo, J. and Sotelo, M.A. and Barea, R. and Lopez, M.E.},
	month = mar,
	year = {2006},
	pages = {63--77},
	file = {Bergasa et al. - 2006 - Real-Time System for Monitoring Driver Vigilance.pdf:/home/simeon/Zotero/storage/DJMDDZ6Z/Bergasa et al. - 2006 - Real-Time System for Monitoring Driver Vigilance.pdf:application/pdf},
}

@inproceedings{bergasa_real-time_2005,
	address = {Dubrovnik, Croatia},
	title = {Real-time system for monitoring driver vigilance},
	isbn = {978-0-7803-8738-6},
	url = {http://ieeexplore.ieee.org/document/1529113/},
	doi = {10.1109/ISIE.2005.1529113},
	abstract = {This paper presents a nonintrusive prototype computer vision system for monitoring a driver’s vigilance in real time. It is based on a hardware system for the real-time acquisition of a driver’s images using an active IR illuminator and the software implementation for monitoring some visual behaviors that characterize a driver’s level of vigilance. Six parameters are calculated: Percent eye closure (PERCLOS), eye closure duration, blink frequency, nodding frequency, face position, and ﬁxed gaze. These parameters are combined using a fuzzy classiﬁer to infer the level of inattentiveness of the driver. The use of multiple visual parameters and the fusion of these parameters yield a more robust and accurate inattention characterization than by using a single parameter. The system has been tested with different sequences recorded in night and day driving conditions in a motorway and with different users. Some experimental results and conclusions about the performance of the system are presented.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of the {IEEE} {International} {Symposium} on {Industrial} {Electronics}, 2005. {ISIE} 2005.},
	publisher = {IEEE},
	author = {Bergasa, L.M. and Nuevo, J.},
	year = {2005},
	pages = {1303--1308 vol. 3},
	file = {Bergasa and Nuevo - 2005 - Real-time system for monitoring driver vigilance.pdf:/home/simeon/Zotero/storage/RYY8LPKL/Bergasa and Nuevo - 2005 - Real-time system for monitoring driver vigilance.pdf:application/pdf},
}

@article{azim_fully_2014,
	title = {Fully automated real time fatigue detection of drivers through {Fuzzy} {Expert} {Systems}},
	volume = {18},
	issn = {15684946},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494614000398},
	doi = {10.1016/j.asoc.2014.01.020},
	language = {en},
	urldate = {2021-02-17},
	journal = {Applied Soft Computing},
	author = {Azim, Tayyaba and Jaffar, M. Arfan and Mirza, Anwar M.},
	month = may,
	year = {2014},
	pages = {25--38},
	file = {Azim et al. - 2014 - Fully automated real time fatigue detection of dri.pdf:/home/simeon/Zotero/storage/6X6FDA5Z/Azim et al. - 2014 - Fully automated real time fatigue detection of dri.pdf:application/pdf;azim2014.pdf:/Users/simeon/Desktop/Recherche/Article/comportement-measure/azim2014.pdf:application/pdf;azim2014.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/azim2014.pdf:application/pdf},
}

@article{alioua_drivers_2014,
	title = {Driver’s {Fatigue} {Detection} {Based} on {Yawning} {Extraction}},
	volume = {2014},
	issn = {1687-5702, 1687-5710},
	url = {https://www.hindawi.com/journals/ijvt/2014/678786/},
	doi = {10.1155/2014/678786},
	abstract = {The increasing number of traffic accidents is principally caused by fatigue. In fact, the fatigue presents
a real danger on road since it reduces driver capacity to react and analyze information. In this paper we propose an efficient and nonintrusive system for monitoring driver fatigue using yawning extraction. The proposed scheme uses face extraction based support vector machine (SVM) and a new approach for mouth detection, based on circular Hough transform (CHT), applied on mouth extracted regions. Our system does not require any training data at any step or special cameras. Some experimental results showing system performance are reported. These experiments are applied over real video sequences acquired by low cost web camera and recorded in various lighting conditions.},
	language = {en},
	urldate = {2021-02-17},
	journal = {International Journal of Vehicular Technology},
	author = {Alioua, Nawal and Amine, Aouatif and Rziza, Mohammed},
	month = aug,
	year = {2014},
	pages = {1--7},
	file = {Alioua et al. - 2014 - Driver’s Fatigue Detection Based on Yawning Extrac.pdf:/home/simeon/Zotero/storage/ZIRSNSSV/Alioua et al. - 2014 - Driver’s Fatigue Detection Based on Yawning Extrac.pdf:application/pdf;alioua2014.pdf:/Users/simeon/Desktop/Recherche/Article/comportement-measure/alioua2014.pdf:application/pdf;alioua2014.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/alioua2014.pdf:application/pdf},
}

@article{abdul_rahim_detecting_2015,
	title = {Detecting {Drowsy} {Driver} {Using} {Pulse} {Sensor}},
	volume = {73},
	issn = {2180-3722, 0127-9696},
	url = {https://journals.utm.my/index.php/jurnalteknologi/article/view/4238},
	doi = {10.11113/jt.v73.4238},
	abstract = {The driver’s condition, which involves staying focus on the road, is the most important aspect to consider whenever one is driving. To ignore the importance of this could result in severe physical injuries, deaths and economic losses. Again, previous researches were focused mainly on the physical conditions of the driver; eg movement of head and drowsiness. However, this research is focused on the driver’s heart rate by using an infrared heart-rate sensor or pulse sensor. These sensors are non-intrusively measured heart pulse wave from the driver’s heart. By doing experiment, the results show clear pulse wave signal can be obtained by looking at the low to high frequency (LF/HF ratio) which calculate HRV frequency domain of the driver’s heart rate time series. The LF/HF ratio shows decreasing trends as the drivers go from the state of being awake and alert to the state of drowsiness. Therefore, accidents can be avoided if there is an alert system to keep the drivers alert and focused on the road.},
	language = {en},
	number = {3},
	urldate = {2020-11-02},
	journal = {Jurnal Teknologi},
	author = {Abdul Rahim, Herlina and Dalimi, Ahmad and Jaafar, Haliza},
	month = mar,
	year = {2015},
	file = {Abdul Rahim et al. - 2015 - Detecting Drowsy Driver Using Pulse Sensor.pdf:/home/simeon/Zotero/storage/K7XEWJ2H/Abdul Rahim et al. - 2015 - Detecting Drowsy Driver Using Pulse Sensor.pdf:application/pdf;Abdul Rahim et al. - 2015 - Detecting Drowsy Driver Using Pulse Sensor.pdf:/home/simeon/Zotero/storage/7QLC6G7C/Abdul Rahim et al. - 2015 - Detecting Drowsy Driver Using Pulse Sensor.pdf:application/pdf;abdulrahim2015.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/abdulrahim2015.pdf:application/pdf;207488670.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/207488670.pdf:application/pdf},
}

@article{friedrichs_drowsiness_nodate,
	title = {{DROWSINESS} {MONITORING} {BY} {STEERING} {AND} {LANE} {DATA} {BASED} {FEATURES} {UNDER} {REAL} {DRIVING} {CONDITIONS}},
	abstract = {Experts state that driver drowsiness is responsible for about 30\% of severe trafﬁc accidents. Driver monitoring systems, such as the Mercedes-Benz Attention Assist aim to reduce these road-crashes caused by fatigued drivers using standard equipment sensors. In this article, new measures (features) for detecting drowsiness are proposed in addition to promising features in literature. Most studies in literature are based on driving simulator data, whereas this article focuses on real world driving. External inﬂuences such as road condition, road bumps and cross-wind are furthermore taken into account. The presented results are based on a large selection of the Mercedes-Benz drowsiness database which covers over 1.2 million kilometers of measurements. Features are analyzed for their correlation with the subjective Karolinska Sleepiness Scale (KSS). The performance of a combination of features is assessed by sophisticated classiﬁers and dimension reduction techniques. Even after these improvements, the classiﬁcation results do not reach the results obtained in a driving simulator.},
	language = {en},
	author = {Friedrichs, Fabian and Yang, Bin},
	pages = {5},
	file = {1569292275.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/1569292275.pdf:application/pdf},
}

@inproceedings{yan_real-time_2016,
	address = {Xi'an, China},
	title = {Real-{Time} {Driver} {Drowsiness} {Detection} {System} {Based} on {PERCLOS} and {Grayscale} {Image} {Processing}},
	isbn = {978-1-5090-3071-2},
	url = {http://ieeexplore.ieee.org/document/7545182/},
	doi = {10.1109/IS3C.2016.72},
	abstract = {This study develops a real-time drowsiness detection system based on grayscale image processing and PERCLOS to determine if the driver is fatigued. The proposed system comprises three parts: first, it calculates the approximate position of the driver’s face in grayscale images, and then uses a small template to analyze the eye positions; second, it uses the data from the previous step and PERCLOS to establish a fatigue model; and finally, based on the driver’s personal fatigue model, the system continuously monitors the driver’s state. Once the driver exhibits fatigue, the system alerts the driver to stop driving and take a rest.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2016 {International} {Symposium} on {Computer}, {Consumer} and {Control} ({IS3C})},
	publisher = {IEEE},
	author = {Yan, Jun-Juh and Kuo, Hang-Hong and Lin, Ying-Fan and Liao, Teh-Lu},
	month = jul,
	year = {2016},
	pages = {243--246},
	file = {IS3C.2016.72.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/IS3C.2016.72.pdf:application/pdf;Yan et al. - 2016 - Real-Time Driver Drowsiness Detection System Based.pdf:/home/simeon/Zotero/storage/LLTV3VFP/Yan et al. - 2016 - Real-Time Driver Drowsiness Detection System Based.pdf:application/pdf},
}

@article{mistry_driver_2020,
	title = {Driver {Drowsiness} {Detection} {System}},
	volume = {5},
	abstract = {A Driver Pattern Recognition System was developed, using concepts based on the concept of a nondisruptive machine. The machine uses a small monochrome safety camera that points directly to the driver's face and monitors the driver's eyes to detect fatigue. In such a case when fatigue is detected, the driver is alerted with a warning signal and if the driver is distracted he will also warn the driver to be careful. This report explains how the eyes can be found, and how to determine if the eyes are open or closed. The advanced algorithm differs from any currently published documents which is the main objective of the project. The device deals with finding facial edges using information obtained from the binary version of the image, which reduces the area where the eyes will be. When the surface area is defined, the eyes are obtained by measuring the horizontal area. Recalling the knowledge that the circuits of the eyes on the face bring about a great change in strength, The eyes are obtained by experiencing major changes in facial pressure. When the eyes are in a good position, measuring the distances between the size changes in the eye area determines whether the eyes are open or closed. The long distance is associated with blindfolds. If the eyes are found closed with five consecutive frames, the machine assumes the driver is asleep and sends an alarm. Also, the system can detect when the eyes are not available and operate under appropriate lighting conditions.},
	language = {en},
	number = {11},
	author = {Mistry, Nikunj and Student, UG},
	year = {2020},
	pages = {5},
	file = {IJISRT20NOV620_(1).pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/IJISRT20NOV620_(1).pdf:application/pdf},
}

@inproceedings{ueno_development_1994,
	address = {Yokohama, Japan},
	title = {Development of drowsiness detection system},
	isbn = {978-0-7803-2105-2},
	url = {http://ieeexplore.ieee.org/document/396873/},
	doi = {10.1109/VNIS.1994.396873},
	abstract = {The development of technologies for preventing drowsiness at the wheel is a major challenge in the field of accident avoidance systems. Preventing drowsiness during driving requires a method for accurately detecting a decline in driver alertness and a method for alerting and refreshing the driver. As a detection method, the authors have developed a system that uses image processing technology to analyze images of the driver's face taken with a video camera. Diminished alertness is detected on the basis of the degree to which the driver's eyes are open or closed. This detection system provides a noncontact technique for judging various levels of driver alertness and facilitates early detection of a decline in alertness during driving.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of {VNIS}'94 - 1994 {Vehicle} {Navigation} and {Information} {Systems} {Conference}},
	publisher = {IEEE},
	author = {Ueno, H. and Kaneda, M. and Tsukino, M.},
	year = {1994},
	pages = {15--20},
	file = {VNIS.1994.396873.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/VNIS.1994.396873.pdf:application/pdf;Ueno et al. - 1994 - Development of drowsiness detection system.pdf:/home/simeon/Zotero/storage/8BAEBDC7/Ueno et al. - 1994 - Development of drowsiness detection system.pdf:application/pdf},
}

@article{jung_real-time_2011,
	title = {Real-time physiological and vision monitoring of vehicle driver for non-intrusive drowsiness detection},
	volume = {5},
	issn = {1751-8628, 1751-8636},
	url = {https://digital-library.theiet.org/content/journals/10.1049/iet-com.2010.0925},
	doi = {10.1049/iet-com.2010.0925},
	abstract = {This study presents a novel approach to detect driver’s drowsiness by applying two distinct methods in computer vision and image processing. The objective of this study is to combine both methods under one single proﬁle instead of relied solely on a detection method to enhance the driver’s drowsiness detection resolution. Therefore a non-intrusive drowsy-monitoring system is developed to alert the driver if driver falls into low arousal state. In physiological part, photoplethysmography (PPG) is analysed for its changes in signals waveform from awake to drowsy state. Meanwhile, eyes pattern or motion in image processing is addressed to detect driver fatigue. Genetic algorithm with template-matching approach is designed to detect eye region and estimate the drowsiness in different metric standard based on eyes behaviour. Moreover, PPG drowsy signals are integrated with eyes motion to derive the ﬁnal probability model for delivering valid and reliable drowsiness detection system. Indeed, the proposed system provides high competitive edge over existing arbitrary drowsiness detection system where the driver’s health and mental states can be monitored in real-time without constraints.},
	language = {en},
	number = {17},
	urldate = {2021-02-17},
	journal = {IET Communications},
	author = {Jung, S.-J. and Chung, W.-Y. and Lee, B.-G.},
	month = nov,
	year = {2011},
	pages = {2461--2469},
	file = {iet-communications.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/iet-communications.pdf:application/pdf;Jung et al. - 2011 - Real-time physiological and vision monitoring of v.pdf:/home/simeon/Zotero/storage/AN7J6DY7/Jung et al. - 2011 - Real-time physiological and vision monitoring of v.pdf:application/pdf},
}

@article{wang_drowsy_2016,
	title = {Drowsy behavior detection based on driving information},
	volume = {17},
	issn = {1229-9138, 1976-3832},
	url = {http://link.springer.com/10.1007/s12239-016-0016-y},
	doi = {10.1007/s12239-016-0016-y},
	abstract = {Drowsy behavior is more likely to occur in sleep-deprived drivers. Individuals’ drowsy behavior detection technology should be developed to prevent drowsiness related crashes. Driving information such as acceleration, steering angle and velocity, and physiological signals of drivers such as electroencephalogram (EEG), and eye tracking are adopted in present drowsy behavior detection technologies. However, it is difficult to measure physiological signal, and eye tracking requires complex experiment equipment. As a result, driving information is adopted for drowsy driving detection. In order to achieve this purpose, driving experiment is performed for obtaining driving information through driving simulator. Moreover, this paper investigates effects of using different input parameter combinations, which is consisted of lateral acceleration, longitudinal acceleration, and steering angles with different time window sizes (i.e. 4 s, 10 s, 20 s, 30 s, 60 s), on drowsy driving detection using random forest algorithm. 20 s-size datasets using parameter combination of accelerations in lateral and longitudinal directions, compared to the other combination cases of driving information such as steering angles combined with lateral and longitudinal acceleration, steering angles only, longitudinal acceleration only, and lateral acceleration only, is considered the most effective information for drivers’ drowsy behavior detection. Moreover, comparing to ANN algorithm, RF algorithm performs better on processing complex input data for drowsy behavior detection. The results, which reveal high accuracy 84.8 \% on drowsy driving behavior detection, can be applied on condition of operating real vehicles.},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {International Journal of Automotive Technology},
	author = {Wang, M. S. and Jeong, N. T. and Kim, K. S. and Choi, S. B. and Yang, S. M. and You, S. H. and Lee, J. H. and Suh, M. W.},
	month = feb,
	year = {2016},
	pages = {165--173},
	file = {wang2016.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/wang2016.pdf:application/pdf},
}

@article{xiao_fatigue_2019,
	title = {Fatigue driving recognition network: fatigue driving recognition via convolutional neural network and long short‐term memory units},
	volume = {13},
	issn = {1751-9578, 1751-9578},
	shorttitle = {Fatigue driving recognition network},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-its.2018.5392},
	doi = {10.1049/iet-its.2018.5392},
	abstract = {Fatigue driving has become one of the major causes of traffic accidents. The authors propose an effective method capable of detecting fatigue state via the spatial–temporal feature of driver's eyes. In this work, the authors consider fatigue detection as image-based sequence recognition and an end-to-end trainable convolutional neural network with long short-term memory (LSTM) units is designed. First, the authors apply a deep cascaded multi-task framework to extract eye region from infrared videos. Then the spatial features are learned by deep convolutional layers and the relationships between adjacent frames are analysed via LSTM units. Finally, through authors’ model, a sequence-level prediction for driving state is produced. The proposed method achieves superior accuracy over the state-of-the-art techniques on authors’ own dataset. Experimental results demonstrate the feasibility of authors’ method.},
	language = {en},
	number = {9},
	urldate = {2021-02-17},
	journal = {IET Intelligent Transport Systems},
	author = {Xiao, Zhitao and Hu, Zhiqiang and Geng, Lei and Zhang, Fang and Wu, Jun and Li, Yuelong},
	month = sep,
	year = {2019},
	pages = {1410--1416},
	file = {iet-its.2018.5392.pdf:/home/simeon/Zotero/storage/7S56XKBA/iet-its.2018.5392.pdf:application/pdf;Xiao et al. - 2019 - Fatigue driving recognition network fatigue drivi.pdf:/home/simeon/Zotero/storage/BIJH73MU/Xiao et al. - 2019 - Fatigue driving recognition network fatigue drivi.pdf:application/pdf},
}

@inproceedings{byrnes_using_2018,
	address = {Maui, HI},
	title = {On {Using} {Drivers}' {Eyes} to {Predict} {Accident}-{Causing} {Drowsiness} {Levels}},
	isbn = {978-1-72810-321-1 978-1-72810-323-5},
	url = {https://ieeexplore.ieee.org/document/8569293/},
	doi = {10.1109/ITSC.2018.8569293},
	abstract = {We examine the use of video data to determine a driver’s drowsiness level. We conduct a user study to collect video of a user reading, watching a driving simulation, and playing a video game that simulates driving. Alongside each video is the user’s sleepiness as measured by the Stanford Sleepiness Scale, the Epworth Sleepiness Scale, and eight questions that have been shown to coincide with unsafe driving. Using this data, we replicate the results of prior art, showing that on average, changes in eye movement do correlate with drowsiness. We ﬁnd however, that the measurements appear to have no predictive value for the drowsiness metrics that are known to coincide with unsafe driving. We determine that additional research in detecting driver drowsiness is needed. Our user study data is publicly available.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2018 21st {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE},
	author = {Byrnes, Alyssa and Sturton, Cynthia},
	month = nov,
	year = {2018},
	pages = {2092--2097},
	file = {ByrnesITSC2018.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/ByrnesITSC2018.pdf:application/pdf},
}

@article{zhang_joint_2016,
	title = {Joint {Face} {Detection} and {Alignment} {Using} {Multitask} {Cascaded} {Convolutional} {Networks}},
	volume = {23},
	issn = {1070-9908, 1558-2361},
	url = {http://ieeexplore.ieee.org/document/7553523/},
	doi = {10.1109/LSP.2016.2603342},
	language = {en},
	number = {10},
	urldate = {2021-02-17},
	journal = {IEEE Signal Processing Letters},
	author = {Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
	month = oct,
	year = {2016},
	pages = {1499--1503},
	file = {Zhang et al. - 2016 - Joint Face Detection and Alignment Using Multitask.pdf:/home/simeon/Zotero/storage/HW8EPMVP/Zhang et al. - 2016 - Joint Face Detection and Alignment Using Multitask.pdf:application/pdf;Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_Usefull/Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks.pdf:application/pdf},
}

@article{khushaba_driver_2011,
	title = {Driver {Drowsiness} {Classification} {Using} {Fuzzy} {Wavelet}-{Packet}-{Based} {Feature}-{Extraction} {Algorithm}},
	volume = {58},
	issn = {0018-9294, 1558-2531},
	url = {http://ieeexplore.ieee.org/document/5580017/},
	doi = {10.1109/TBME.2010.2077291},
	abstract = {Driver drowsiness and loss of vigilance are a major cause of road accidents. Monitoring physiological signals while driving provides the possibility of detecting and warning of drowsiness and fatigue. The aim of this paper is to maximize the amount of drowsiness-related information extracted from a set of electroencephalogram (EEG), electrooculogram (EOG), and electrocardiogram (ECG) signals during a simulation driving test. Speciﬁcally, we develop an efﬁcient fuzzy mutual-information (MI)- based wavelet packet transform (FMIWPT) feature-extraction method for classifying the driver drowsiness state into one of predeﬁned drowsiness levels. The proposed method estimates the required MI using a novel approach based on fuzzy memberships providing an accurate-information content-estimation measure. The quality of the extracted features was assessed on datasets collected from 31 drivers on a simulation test. The experimental results proved the signiﬁcance of FMIWPT in extracting features that highly correlate with the different drowsiness levels achieving a classiﬁcation accuracy of 95\%–97\% on an average across all subjects.},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Khushaba, R N and Kodagoda, S and Lal, S and Dissanayake, G},
	month = jan,
	year = {2011},
	pages = {121--131},
	file = {Driver Drowsiness Classification Using Fuzzy Wavelet-Packet-Based Feature-Extraction Algorithm.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_Usefull/Driver Drowsiness Classification Using Fuzzy Wavelet-Packet-Based Feature-Extraction Algorithm.pdf:application/pdf;Khushaba et al. - 2011 - Driver Drowsiness Classification Using Fuzzy Wavel.pdf:/home/simeon/Zotero/storage/AC7KDZTL/Khushaba et al. - 2011 - Driver Drowsiness Classification Using Fuzzy Wavel.pdf:application/pdf},
}

@incollection{chen_representation_2017,
	address = {Cham},
	title = {Representation {Learning}, {Scene} {Understanding}, and {Feature} {Fusion} for {Drowsiness} {Detection}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	url = {http://link.springer.com/10.1007/978-3-319-54526-4_13},
	abstract = {We propose a novel drowsiness detection method based on 3D-Deep Convolutional Neural Network (3D-DCNN). We design a learning architecture for the drowsiness detection, which consists of three building blocks for representation learning, scene understanding, and feature fusion. In this framework, the model generates a spatio-temporal representation from multiple consecutive frames and analyze the scene conditions which are deﬁned as head, eye, and mouth movements. The result of analysis from the scene condition understanding model is used to auxiliary information for the drowsiness detection. Then the method subsequently generates fusion features using the spatio-temporal representation and the results of the classiﬁcation of scene conditions. By using the fusion features, we show that the proposed method can boost the performance of drowsiness detection. The proposed method demonstrates with the NTHU Drowsy Driver Detection (NTHU-DDD) video dataset.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Yu, Jongmin and Park, Sangwoo and Lee, Sangwook and Jeon, Moongu},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {165--177},
	file = {Representation Learning, Scene Understanding, and Feature Fusion for Drowsiness Detection.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_Usefull/Representation Learning, Scene Understanding, and Feature Fusion for Drowsiness Detection.pdf:application/pdf},
}

@inproceedings{rigas_reasoning-based_2008,
	address = {Ajaccio, France},
	title = {A reasoning-based framework for car driver\&\#x2019;s stress prediction},
	isbn = {978-1-4244-2504-4},
	url = {http://ieeexplore.ieee.org/document/4602162/},
	doi = {10.1109/MED.2008.4602162},
	abstract = {In this work, we present a novel methodology based on a Dynamic Bayesian Network for the estimation of car drivers stress produced due to speciﬁc driving events. The proposed methodology monitors driver’s stress using selected biosignals and provides a probabilistic framework in order to infer the driving events resulting in stress level increase. We conducted a series of experiments under real driving conditions. The extracted results indicate a strong correlation between the level of the stress as reported by the driver and the outcome of our model.},
	language = {en},
	urldate = {2020-11-17},
	booktitle = {2008 16th {Mediterranean} {Conference} on {Control} and {Automation}},
	publisher = {IEEE},
	author = {Rigas, George and Katsis, Christos D. and Bougia, Penny and Fotiadis, Dimitrios I.},
	month = jun,
	year = {2008},
	pages = {627--632},
	file = {Rigas et al. - 2008 - A reasoning-based framework for car driver&#x2019\;.pdf:/home/simeon/Zotero/storage/7S6TQRDN/Rigas et al. - 2008 - A reasoning-based framework for car driver&#x2019\;.pdf:application/pdf;rigas2008.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/rigas2008.pdf:application/pdf},
}

@article{bando_evaluation_2017,
	title = {Evaluation of dynamics of forehead skin temperature under induced drowsiness: {EVALUATION} {OF} {DYNAMICS} {OF} {FOREHEAD} {SKIN} {TEMPERATURE}},
	volume = {12},
	issn = {19314973},
	shorttitle = {Evaluation of dynamics of forehead skin temperature under induced drowsiness},
	url = {http://doi.wiley.com/10.1002/tee.22423},
	doi = {10.1002/tee.22423},
	language = {en},
	urldate = {2020-11-17},
	journal = {IEEJ Transactions on Electrical and Electronic Engineering},
	author = {Bando, Shizuka and Oiwa, Kosuke and Nozawa, Akio},
	month = jun,
	year = {2017},
	pages = {S104--S109},
	file = {Bando et al. - 2017 - Evaluation of dynamics of forehead skin temperatur.pdf:/home/simeon/Zotero/storage/GKDXYEZ3/Bando et al. - 2017 - Evaluation of dynamics of forehead skin temperatur.pdf:application/pdf;bando2017.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/bando2017.pdf:application/pdf},
}

@article{kumar_wavelet_2003,
	title = {Wavelet analysis of surface electromyography to determine muscle fatigue},
	volume = {11},
	issn = {1534-4320},
	url = {http://ieeexplore.ieee.org/document/1261751/},
	doi = {10.1109/TNSRE.2003.819901},
	abstract = {Muscle fatigue is often a result of unhealthy work practice. It has been known for some time that there is a significant change in the spectrum of the electromyography (EMG) of the muscle when it is fatigued. Due to the very complex nature of this signal however, it has been difficult to use this information to reliably automate the process of fatigue onset determination. If such a process implementation were feasible, it could be used as an indicator to reduce the chances of work-place injury. This research report on the effectiveness of the wavelet transform applied to the EMG signal as a means of identifying muscle fatigue. We report that with the appropriate choice of wavelet functions and scaling factors, it is possible to achieve reliable discrimination of the fatigue phenomenon, appropriate to an automated fatigue identification system.},
	language = {en},
	number = {4},
	urldate = {2020-11-16},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Kumar, D.K. and Pah, N.D. and Bradley, A.},
	month = dec,
	year = {2003},
	pages = {400--406},
	file = {Kumar et al. - 2003 - Wavelet analysis of surface electromyography.pdf:/home/simeon/Zotero/storage/QYP6JKC8/Kumar et al. - 2003 - Wavelet analysis of surface electromyography.pdf:application/pdf;kumar2003.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/kumar2003.pdf:application/pdf},
}

@article{shinar_autonomic_2006,
	title = {Autonomic changes during wake–sleep transition: {A} heart rate variability based approach},
	volume = {130},
	issn = {15660702},
	shorttitle = {Autonomic changes during wake–sleep transition},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566070206001135},
	doi = {10.1016/j.autneu.2006.04.006},
	abstract = {Autonomic function during sleep and wakefulness has been extensively investigated, however information concerning autonomic changes during the wake to sleep transition is scarce. The objective of the present study was to non-invasively characterize autonomic function and additional physiologic changes during sleep onset in normal and abnormal sleep. The estimation of autonomic function was based on time–frequency analysis of the RR interval series, using the power components in the very-low-frequency range (0.005–0.04 Hz), low-frequency (0.04–0.15 Hz), and high-frequency range (0.15–0.5 Hz). The ratio of low to high frequency power represented the sympathovagal balance. Thirty-four subjects who underwent whole night polysomnography were divided into 3 groups according to their complaints and study results: normal subjects, apneic patients (OSAS), and subjects with various sleep disorders (VSD).},
	language = {en},
	number = {1-2},
	urldate = {2020-11-16},
	journal = {Autonomic Neuroscience},
	author = {Shinar, Zvi and Akselrod, Solange and Dagan, Yaron and Baharav, Armanda},
	month = dec,
	year = {2006},
	pages = {17--27},
	file = {Shinar et al. - 2006 - Autonomic changes during wake–sleep transition A .pdf:/home/simeon/Zotero/storage/T6G6XRJ8/Shinar et al. - 2006 - Autonomic changes during wake–sleep transition A .pdf:application/pdf;shinar2006.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/shinar2006.pdf:application/pdf},
}

@misc{noauthor_sci-hub_nodate-1,
	title = {Sci-{Hub}: removing barriers in the way of science},
	shorttitle = {Sci-{Hub}},
	url = {https://sci-hub.st/},
	abstract = {The first pirate website in the world to open mass and public access to tens of millions research papers},
	urldate = {2020-11-16},
	file = {Snapshot:/home/simeon/Zotero/storage/KZKPFQQR/sci-hub.st.html:text/html},
}

@article{guo_impairing_2016,
	title = {The {Impairing} {Effect} of {Mental} {Fatigue} on {Visual} {Sustained} {Attention} under {Monotonous} {Multi}-{Object} {Visual} {Attention} {Task} in {Long} {Durations}: {An} {Event}-{Related} {Potential} {Based} {Study}},
	volume = {11},
	issn = {1932-6203},
	shorttitle = {The {Impairing} {Effect} of {Mental} {Fatigue} on {Visual} {Sustained} {Attention} under {Monotonous} {Multi}-{Object} {Visual} {Attention} {Task} in {Long} {Durations}},
	url = {https://dx.plos.org/10.1371/journal.pone.0163360},
	doi = {10.1371/journal.pone.0163360},
	abstract = {The impairing effects of mental fatigue on visual sustained attention were assessed by event-related potentials (ERPs). Subjects performed a dual visual task, which includes a continuous tracking task (primary task) and a random signal detection task (secondary task), for 63 minutes nonstop in order to elicit ERPs. In this period, the data such as subjective levels of mental fatigue, behavioral performance measures, and electroencephalograms were recorded for each subject. Comparing data from the first interval (0–25 min) to that of the second, the following phenomena were observed: the subjective fatigue ratings increased with time, which indicates that performing the tasks leads to increase in mental fatigue levels; reaction times prolonged and accuracy rates decreased in the second interval, which indicates that subjects’ sustained attention decreased.; In the ERP data, the P3 amplitudes elicited by the random signals decreased, while the P3 latencies increased in the second interval. These results suggest that mental fatigue can modulate the higherlevel cognitive processes, in terms of less attentional resources allocated to the random stimuli, which leads to decreased speed in information evaluating and decision making against the stimuli. These findings provide new insights into the question that how mental fatigue affects visual sustained attention and, therefore, can help to design countermeasures to prevent accidents caused by low visual sustained attention.},
	language = {en},
	number = {9},
	urldate = {2020-11-16},
	journal = {PLOS ONE},
	author = {Guo, Zizheng and Chen, Ruiya and Zhang, Kan and Pan, Yirun and Wu, Jianhui},
	editor = {Di Russo, Francesco},
	month = sep,
	year = {2016},
	pages = {e0163360},
	file = {Guo et al. - 2016 - The Impairing Effect of Mental Fatigue on Visual S.pdf:/home/simeon/Zotero/storage/VTTSZ8NK/Guo et al. - 2016 - The Impairing Effect of Mental Fatigue on Visual S.pdf:application/pdf;guo2016.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/guo2016.pdf:application/pdf},
}

@article{zhao_electroencephalogram_2012,
	title = {Electroencephalogram and electrocardiograph assessment of mental fatigue in a driving simulator},
	volume = {45},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457511003241},
	doi = {10.1016/j.aap.2011.11.019},
	language = {en},
	urldate = {2020-11-02},
	journal = {Accident Analysis \& Prevention},
	author = {Zhao, Chunlin and Zhao, Min and Liu, Jianpin and Zheng, Chongxun},
	month = mar,
	year = {2012},
	keywords = {Driving mental fatigue, ECG, EEG, HRV, P300},
	pages = {83--90},
	file = {Zhao et al. - 2012 - Electroencephalogram and electrocardiograph assess.pdf:/home/simeon/Zotero/storage/NZJ2ADLG/Zhao et al. - 2012 - Electroencephalogram and electrocardiograph assess.pdf:application/pdf;zhao2012.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/zhao2012.pdf:application/pdf},
}

@inproceedings{thum_chia_chieh_development_2005,
	address = {Kuala Lumpur, Malaysia},
	title = {Development of vehicle driver drowsiness detection system using electrooculogram ({EOG})},
	isbn = {978-1-4244-0011-9},
	url = {http://ieeexplore.ieee.org/document/4977181/},
	doi = {10.1109/CCSP.2005.4977181},
	abstract = {Driver drowsiness is one of the major causes of road accident. Various driver drowsiness detection systems have been designed to detect and warn the driver of impending drowsiness. Most available prototype and ongoing research have focused on video-based eye tracking system, which demands high computing power due to real time video processing. In our research, the use of electrooculogram (EOG) as an alternative to video-based systems in detecting eye activities caused by drowsiness is evaluated. The EOG, which is the electrical signal generated by eye movements, is acquired by a mobile biosignal acquisition module and are processed offline using personal computer. Digital signal differentiation and simple information fusion techniques are used to detect signs of drowsiness in the EOG signal. EOG signal is found to be a promising drowsiness detector, with detection rate of more than 800/0. Based on the tested offline processing techniques, an online fatigue monitoring system prototype based on a Personal Digital Assistant (PDA) has been designed to detect driver dozing off through EOG signal.},
	language = {en},
	urldate = {2020-11-02},
	booktitle = {2005 1st {International} {Conference} on {Computers}, {Communications}, \& {Signal} {Processing} with {Special} {Track} on {Biomedical} {Engineering}},
	publisher = {IEEE},
	author = {{Thum Chia Chieh} and Mustafa, Mohd. Marzuki and Hussain, Aini and Hendi, Seyed Farshad and Majlis, Burhanuddin Yeop},
	month = nov,
	year = {2005},
	pages = {165--168},
	file = {Thum Chia Chieh et al. - 2005 - Development of vehicle driver drowsiness detection.pdf:/home/simeon/Zotero/storage/UNULWDFL/Thum Chia Chieh et al. - 2005 - Development of vehicle driver drowsiness detection.pdf:application/pdf;thumchiachieh2005.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/thumchiachieh2005.pdf:application/pdf},
}

@inproceedings{yu_support_2013,
	address = {Alexandria, VA, USA},
	title = {Support {Vector} {Machine} {Based} {Detection} of {Drowsiness} {Using} {Minimum} {EEG} {Features}},
	isbn = {978-0-7695-5137-1},
	url = {http://ieeexplore.ieee.org/document/6693421/},
	doi = {10.1109/SocialCom.2013.124},
	abstract = {Drowsiness presents major safety concerns for tasks that require long periods of focus and alertness. While there is a body of work on drowsiness detection using EEG signals in neuroscience and engineering, there exist unanswered questions pertaining to the best mechanisms to use for detecting drowsiness. Targeting a range of practical safety-awareness applications, this study adopts a machine learning based approach to build support vector machine (SVM) classiﬁers to distinguish between awake and drowsy states. While broadband alpha, beta, delta, and theta waves are often used as features in the existing work, lack of widely agreed precise deﬁnitions of such broadband signals and difﬁculty in accounting for interpersonal variability has led to poor classiﬁcation performance as demonstrated in this study. Furthermore, the transition from wakefulness to drowsiness and deeper sleep stages is a complex multifaceted process. The richness of this process calls for inclusion of sub-band features for more accurate drowsiness detection. To shed light on the effectiveness of sub-banding, we quantitatively compare the performances of a large set of SVM classiﬁers trained upon a varying number of 1Hz subband features. More importantly, we identify a compact set of neuroscientifcally motivated EEG features and demonstrate that the resulting classiﬁer not only outperforms traditional broadband based classiﬁers but also is on a par with or superior than the best sub-band classiﬁers found by thorough search in a large space of 1Hz subband features.},
	language = {en},
	urldate = {2020-11-02},
	booktitle = {2013 {International} {Conference} on {Social} {Computing}},
	publisher = {IEEE},
	author = {Yu, Shaoda and Li, Peng and Lin, Honghuang and Rohani, Ehsan and Choi, Gwan and Shao, Botang and Wang, Qian},
	month = sep,
	year = {2013},
	pages = {827--835},
	file = {Yu et al. - 2013 - Support Vector Machine Based Detection of Drowsine.pdf:/home/simeon/Zotero/storage/XU4CKLJ6/Yu et al. - 2013 - Support Vector Machine Based Detection of Drowsine.pdf:application/pdf;Support_vector_machine_based_detection_o.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/Support_vector_machine_based_detection_o.pdf:application/pdf},
}

@article{simon_eeg_2011,
	title = {{EEG} alpha spindle measures as indicators of driver fatigue under real traffic conditions},
	volume = {122},
	issn = {13882457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1388245710007911},
	doi = {10.1016/j.clinph.2010.10.044},
	abstract = {Objective: The purpose of this study is to show the effectiveness of EEG alpha spindles, deﬁned by short narrowband bursts in the alpha band, as an objective measure for assessing driver fatigue under real driving conditions.
Methods: An algorithm for the identiﬁcation of alpha spindles is described. The performance of the algorithm is tested based on simulated data. The method is applied to real data recorded under real trafﬁc conditions and compared with the performance of traditional EEG fatigue measures, i.e. alpha-band power. As a highly valid fatigue reference, the last 20 min of driving from participants who aborted the drive due to heavy fatigue were used in contrast to the initial 20 min of driving.
Results: Statistical analysis revealed signiﬁcant increases from the ﬁrst to the last driving section of several alpha spindle parameters and among all traditional EEG frequency bands, only of alpha-band power; with larger effect sizes for the alpha spindle based measures. An increased level of fatigue over the same time periods for drop-outs, as compared to participants who did not abort the drive, was observed only by means of alpha spindle parameters.
Conclusions: EEG alpha spindle parameters increase both fatigue detection sensitivity and speciﬁcity as compared to EEG alpha-band power. Signiﬁcance: It is demonstrated that alpha spindles are superior to EEG band power measures for assessing driver fatigue under real trafﬁc conditions. Ó 2011 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.},
	language = {en},
	number = {6},
	urldate = {2020-11-02},
	journal = {Clinical Neurophysiology},
	author = {Simon, Michael and Schmidt, Eike A. and Kincses, Wilhelm E. and Fritzsche, Martin and Bruns, Andreas and Aufmuth, Claus and Bogdan, Martin and Rosenstiel, Wolfgang and Schrauf, Michael},
	month = jun,
	year = {2011},
	pages = {1168--1178},
	file = {Simon et al. - 2011 - EEG alpha spindle measures as indicators of driver.pdf:/home/simeon/Zotero/storage/GRJPUUVT/Simon et al. - 2011 - EEG alpha spindle measures as indicators of driver.pdf:application/pdf;simon2011.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/simon2011.pdf:application/pdf},
}

@article{patel_applying_2011,
	title = {Applying neural network analysis on heart rate variability data to assess driver fatigue},
	volume = {38},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417410013916},
	doi = {10.1016/j.eswa.2010.12.028},
	abstract = {Long duration driving is a signiﬁcant cause of fatigue related accidents on motorways. Fatigue caused by driving for extended hours can acutely impair driver’s alertness and performance. This papers presents an artiﬁcial intelligence based system which could detect early onset of fatigue in drivers using heart rate variability (HRV) as the human physiological measure. The detection performance of neural network was tested using a set of electrocardiogram (ECG) data recorded under laboratory conditions. The neural network gave an accuracy of 90\%. This HRV based fatigue detection technique can be used as a fatigue countermeasure.},
	language = {en},
	number = {6},
	urldate = {2020-11-02},
	journal = {Expert Systems with Applications},
	author = {Patel, M. and Lal, S.K.L. and Kavanagh, D. and Rossiter, P.},
	month = jun,
	year = {2011},
	pages = {7235--7242},
	file = {Patel et al. - 2011 - Applying neural network analysis on heart rate var.pdf:/home/simeon/Zotero/storage/2C6FXUYH/Patel et al. - 2011 - Applying neural network analysis on heart rate var.pdf:application/pdf;Patel et al. - 2011 - Applying neural network analysis on heart rate var.pdf:/home/simeon/Zotero/storage/ANWIQZI8/Patel et al. - 2011 - Applying neural network analysis on heart rate var.pdf:application/pdf;patel2011.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/patel2011.pdf:application/pdf},
}

@article{nelesen_relationship_2008,
	title = {The {Relationship} {Between} {Fatigue} and {Cardiac} {Functioning}},
	volume = {168},
	issn = {0003-9926},
	url = {http://archinte.jamanetwork.com/article.aspx?doi=10.1001/archinte.168.9.943},
	doi = {10.1001/archinte.168.9.943},
	language = {en},
	number = {9},
	urldate = {2020-11-02},
	journal = {Archives of Internal Medicine},
	author = {Nelesen, Richard and Dar, Yasmin and Thomas, KaMala and Dimsdale, Joel E.},
	month = may,
	year = {2008},
	pages = {943},
	file = {Nelesen et al. - 2008 - The Relationship Between Fatigue and Cardiac Funct.pdf:/home/simeon/Zotero/storage/5BJRGGVP/Nelesen et al. - 2008 - The Relationship Between Fatigue and Cardiac Funct.pdf:application/pdf;nelesen2008.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/nelesen2008.pdf:application/pdf},
}

@article{malathi_electrodermal_2018,
	title = {Electrodermal {Activity} {Based} {Wearable} {Device} for {Drowsy} {Drivers}},
	volume = {1000},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1000/1/012048},
	doi = {10.1088/1742-6596/1000/1/012048},
	abstract = {Road safety and road accident mortality rate are a serious concern for the government. With rise in fatal road accidents, who’s leading cause is the driver being drowsy behind the wheel, measures to alleviate this problem becomes the prime task. To meet the purpose, methods adopted must be of minimum discomfort for the driver, easy to install, provide good detection accuracy and timely alert to circumvent a probable accident. A good candidate to meet these specifications is EDA. As it detects the level of sweat which directly corresponds to the mental state of the person, using EDA for the purposes of driver safety forms a good option. The novelty of this project lies in making use of EDA as a measure to detect if a person is drowsy or not. Much of the challenge lies in building a device equipped with the necessary sensors and processing the data on real-time. The novelty of this work lies in development of an embedded device interfaced with sensors and actuators to detect and alert a driver when found drowsy using sweat as a parameter.},
	language = {en},
	urldate = {2020-11-02},
	journal = {Journal of Physics: Conference Series},
	author = {Malathi, D and Dorathi Jayaseeli, Jd and Madhuri, S and Senthilkumar, K},
	month = apr,
	year = {2018},
	pages = {012048},
	file = {Malathi et al. - 2018 - Electrodermal Activity Based Wearable Device for D.pdf:/home/simeon/Zotero/storage/698494BE/Malathi et al. - 2018 - Electrodermal Activity Based Wearable Device for D.pdf:application/pdf;malathi2018.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/malathi2018.pdf:application/pdf},
}

@article{lohani_review_2019,
	title = {A {Review} of {Psychophysiological} {Measures} to {Assess} {Cognitive} {States} in {Real}-{World} {Driving}},
	volume = {13},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2019.00057/full},
	doi = {10.3389/fnhum.2019.00057},
	abstract = {As driving functions become increasingly automated, motorists run the risk of becoming cognitively removed from the driving process. Psychophysiological measures may provide added value not captured through behavioral or self-report measures alone. This paper provides a selective review of the psychophysiological measures that can be utilized to assess cognitive states in real-world driving environments. First, the importance of psychophysiological measures within the context of trafﬁc safety is discussed. Next, the most commonly used physiology-based indices of cognitive states are considered as potential candidates relevant for driving research. These include: electroencephalography and event-related potentials, optical imaging, heart rate and heart rate variability, blood pressure, skin conductance, electromyography, thermal imaging, and pupillometry. For each of these measures, an overview is provided, followed by a discussion of the methods for measuring it in a driving context. Drawing from recent empirical driving and psychophysiology research, the relative strengths and limitations of each measure are discussed to highlight each measures’ unique value. Challenges and recommendations for valid and reliable quantiﬁcation from lab to (less predictable) real-world driving settings are considered. Finally, we discuss measures that may be better candidates for a near real-time assessment of motorists’ cognitive states that can be utilized in applied settings outside the lab. This review synthesizes the literature on in-vehicle psychophysiological measures to advance the development of effective human-machine driving interfaces and driver support systems.},
	language = {en},
	urldate = {2020-11-02},
	journal = {Frontiers in Human Neuroscience},
	author = {Lohani, Monika and Payne, Brennan R. and Strayer, David L.},
	month = mar,
	year = {2019},
	pages = {57},
	file = {Lohani et al. - 2019 - A Review of Psychophysiological Measures to Assess.pdf:/home/simeon/Zotero/storage/PPQ6PQX4/Lohani et al. - 2019 - A Review of Psychophysiological Measures to Assess.pdf:application/pdf;lohani2019.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/lohani2019.pdf:application/pdf},
}

@article{jiang_denoising_2019,
	title = {Denoising and {Chaotic} {Feature} {Extraction} of {Electrocardial} {Signals} for {Driver} {Fatigue} {Detection} by {Kolmogorov} {Entropy}},
	volume = {141},
	issn = {0022-0434, 1528-9028},
	url = {https://asmedigitalcollection.asme.org/dynamicsystems/article/doi/10.1115/1.4041355/400882/Denoising-and-Chaotic-Feature-Extraction-of},
	doi = {10.1115/1.4041355},
	abstract = {This paper proposes a detection method of driver fatigue by use of electrocardial signals. First, lifting wavelet transform (LWT) was used to reduce signal noise and its effect was confirmed by applying it to the denoising of a white-noise-mixed Lorenz signal. Second, phase space reconstruction was conducted for extracting chaotic features of the measured electrocardial signals. The phase diagrams show fractal geometry features even under a strong noise background. Finally, Kolmogorov entropy, which is a factor reflecting the uncertainty in and the chaotic level of a nonlinear dynamic system, was used as an indicator of driver fatigue. The effectiveness of Kolmogorov entropy in the judgment of driver fatigue was confirmed by comparison with a semantic differential (SD) subjective evaluation experiment. It was demonstrated that Kolmogorov entropy has a strong relationship with driver fatigue. It decreases when fatigue occurs. Furthermore, the influences of delay time and sampling points on Kolmogorov entropy were investigated, since the two factors are important to the actual use of the proposed detection method. Delay time may have significant influence on fatigue determination, but sampling points are relatively inconsequential. This result indicates that real-time detection can be realized by selecting a reasonably small number of sampling points.},
	language = {en},
	number = {2},
	urldate = {2020-11-02},
	journal = {Journal of Dynamic Systems, Measurement, and Control},
	author = {Jiang, Yongxiang and Guo, Shijie and Deng, Sanpeng},
	month = feb,
	year = {2019},
	pages = {021013},
	file = {Jiang et al. - 2019 - Denoising and Chaotic Feature Extraction of Electr.pdf:/home/simeon/Zotero/storage/QC87TI7V/Jiang et al. - 2019 - Denoising and Chaotic Feature Extraction of Electr.pdf:application/pdf;jiang2018.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/jiang2018.pdf:application/pdf},
}

@inproceedings{furman_early_2008,
	address = {Bologna, Italy},
	title = {Early detection of falling asleep at the wheel: {A} {Heart} {Rate} {Variability} approach},
	isbn = {978-1-4244-3706-1},
	shorttitle = {Early detection of falling asleep at the wheel},
	url = {http://ieeexplore.ieee.org/document/4749240/},
	doi = {10.1109/CIC.2008.4749240},
	abstract = {In this study we check the feasibility of a new ECGbased approach to detect drivers’ propensity to fall asleep at the wheel. Ten healthy volunteers, under conditions of increasing sleep deprivation (up to 34 hours), were asked to alternately undergo a Maintenance of Wakefulness Test or a Driving Simulation test every 2 hours while ECG, EEG, EMG, eye movement and video were recorded. Results from 59 falling asleep (FA) events tracked from the first 5 volunteers during MWT provide promising trends: Heart Rate Variability in the VLF range decreases consistently and significantly minutes before FA events. The sympatho-vagal balance is very low compared to baseline wake values for about 5 minutes before the events. The mean HR and overall RR variability decrease during FA events by 2.2 SD and 2.9 SD below regional means. These changes found during MWT suggest that ECG derived parameters in the time and time-frequency domains may provide a useful tool for monitoring drivers' drowsiness and preventing traffic accidents.},
	language = {en},
	urldate = {2020-11-02},
	booktitle = {2008 {Computers} in {Cardiology}},
	publisher = {IEEE},
	author = {Furman, G. Dorfman and Baharav, A. and Cahan, C. and Akselrod, S.},
	month = sep,
	year = {2008},
	pages = {1109--1112},
	file = {Furman et al. - 2008 - Early detection of falling asleep at the wheel A .pdf:/home/simeon/Zotero/storage/KNF59EBB/Furman et al. - 2008 - Early detection of falling asleep at the wheel A .pdf:application/pdf;furman2008.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/furman2008.pdf:application/pdf},
}

@article{united_states_federal_motor_carrier_safety_administration_technology_division_perclos_1998,
	title = {{PERCLOS}: {A} {Valid} {Psychophysiological} {Measure} of {Alertness} {As} {Assessed} by {Psychomotor} {Vigilance}},
	url = {https://rosap.ntl.bts.gov/view/dot/113},
	doi = {10.21949/1502740},
	abstract = {This Tech Brief summarizes an Intelligent Transportation System (ITS) study titled Evaluation of Techniques for Ocular Measurement as an Index of Fatigue and as the Basis for Alertness Management. The study was funded in part by FHWA’s Office of Motor Carriers and managed by the National Highway Traffic Safety Administration (NHTSA). The project’s goal was to evaluate the validity and reliability of several drowsiness-detection measures and technologies in a controlled laboratory setting, and to analyze the effects of alerting stimuli on drivers’ alertness levels. Of the drowsiness-detection measures and technologies evaluated in this study, the measure referred to as “PERCLOS” was found to be the most reliable and valid determination of a driver’s alertness level. PERCLOS is the percentage of eyelid closure over the pupil over time and reflects slow eyelid closures (“droops”) rather than blinks. A PERCLOS drowsiness metric was established in a 1994 driving simulator study as the proportion of time in a minute that the eyes are at least 80 percent closed. (Wierwille et al., 1994) Based on research by Wierwille and colleagues (1994), FWHA and NHTSA consider PERCLOS to be among the most promising known real-time measures of alertness for in-vehicle drowsiness-detection systems. The results of this research support the development of a “first-ever” real-time drowsiness detection sensor that would measure the percentage of eyelid closure over the pupil, over time (i.e., PERCLOS)},
	language = {English},
	number = {FHWA-MCRT-98-006},
	editor = {{United States. Federal Motor Carrier Safety Administration. Technology Division}},
	month = oct,
	year = {1998},
	keywords = {Commercial transportation},
}

@techreport{european_road_safety_observatory_annual_2019,
	title = {Annual {Accident} {Report}: https://ec.europa.eu/transport/road \_safety/sites/roadsafety/files/pdf/statistics/dacota/asr2018.pdf},
	author = {European Road Safety Observatory, Annual Accident Report},
	year = {2019},
}

@misc{w3c_semantic_nodate,
	title = {{SEMANTIC} {WEB}},
	url = {https://www.w3.org/standards/semanticweb/},
	abstract = {In addition to the classic “Web of documents” W3C is helping to build a technology stack to support a “Web of data,” the sort of data you find in databases. The ultimate goal of the Web of data is to enable computers to do more useful work and to develop systems that can support trusted interactions over the network. The term “Semantic Web” refers to W3C’s vision of the Web of linked data. Semantic Web technologies enable people to create data stores on the Web, build vocabularies, and write rules for handling data. Linked data are empowered by technologies such as RDF, SPARQL, OWL, and SKOS.},
	author = {W3C},
}

@article{gomez-perez_ontological_2004,
	title = {Ontological {Engineering}: {With} {Examples} from the {Areas} of {Knowledge} {Management}, {E}-{Commerce} and the {Semantic} {Web}},
	language = {en},
	author = {Gomez-Perez, Asuncion and Fernandez-Lopez, M and Corcho, O},
	year = {2004},
	pages = {110},
	file = {Ontological_Engineering_With_Examples_from_the_Are.pdf:/Users/simeon/Desktop/Recherche/Article/Ontological_Engineering_With_Examples_from_the_Are.pdf:application/pdf},
}

@article{roussey_ontologies_2010,
	title = {Ontologies in {Agriculture}},
	abstract = {Ontologies have been used for the last decades for a set of tasks, one of which is focused on achieving interoperability between heterogeneous information systems. In this paper, we present different types of ontologies and we explain how next generation of information system will benefit from the use of ontologies to resolve interoperability issues.},
	language = {en},
	author = {Roussey, C and Soulignac, V and Champomier, J C and Abt, V and Chanet, J P},
	year = {2010},
	pages = {11},
	file = {CF2010-PUB00029288.pdf:/Users/simeon/Desktop/Recherche/Article/Ontologie/CF2010-PUB00029288.pdf:application/pdf},
}

@article{studer_knowledge_1998,
	title = {Knowledge engineering: {Principles} and methods},
	volume = {25},
	issn = {0169023X},
	shorttitle = {Knowledge engineering},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169023X97000566},
	doi = {10.1016/S0169-023X(97)00056-6},
	abstract = {This paper gives an overview about the development of the field of Knowledge Engineering over the last 15 years. We discuss the paradigm shift from a transfer view to a modeling view and describe two approaches which considerably shaped research in Knowledge Engineering: Role-limiting Methods and Generic Tasks. To illustrate various concepts and methods which evolved in the last years we describe three modeling frameworks: CommonKADS, MIKE, and PROTÉGÉ-II. This description is supplemented by discussing some important methodological developments in more detail: specification languages for knowledge-based systems, problem-solving methods, and ontologies. We conclude with outlining the relationship of Knowledge Engineering to Software Engineering, Information Integration and Knowledge Management.},
	language = {en},
	number = {1-2},
	urldate = {2021-06-30},
	journal = {Data \& Knowledge Engineering},
	author = {Studer, Rudi and Benjamins, V.Richard and Fensel, Dieter},
	month = mar,
	year = {1998},
	pages = {161--197},
	file = {Studer et al. - 1998 - Knowledge engineering Principles and methods.pdf:/home/simeon/Zotero/storage/MHJI5P4D/Studer et al. - 1998 - Knowledge engineering Principles and methods.pdf:application/pdf},
}

@article{gruber_translation_1993,
	title = {A translation approach to portable ontology specifications},
	volume = {5},
	issn = {1042-8143},
	url = {https://www.sciencedirect.com/science/article/pii/S1042814383710083},
	doi = {10.1006/knac.1993.1008},
	abstract = {To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse—definitions of classes, relations, functions, and other objects—is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.},
	language = {en},
	number = {2},
	urldate = {2021-06-30},
	journal = {Knowledge Acquisition},
	author = {Gruber, Thomas R.},
	month = jun,
	year = {1993},
	pages = {199--220},
	file = {ScienceDirect Snapshot:/home/simeon/Zotero/storage/NBSY445Q/S1042814383710083.html:text/html;Version soumise:/home/simeon/Zotero/storage/ACUPCZSC/Gruber - 1993 - A translation approach to portable ontology specif.pdf:application/pdf},
}

@article{noauthor_perclos_1998,
	title = {{PERCLOS}: {A} {VALID} {PSYCHOPHYSIOLOGICAL} {MEASURE} {OF} {ALERTNESS} {AS} {ASSESSED} {BY} {PSYCHOMOTOR} {VIGILANCE}},
	shorttitle = {{PERCLOS}},
	url = {https://trid.trb.org/view.aspx?id=498744},
	urldate = {2021-06-30},
	journal = {Tech Brief},
	month = oct,
	year = {1998},
	note = {Number: FHWA-MCRT-98-006},
	file = {PERCLOS A Valid Psychophysiological Measure of Al.pdf:/home/simeon/Zotero/storage/D775Y4IG/PERCLOS A Valid Psychophysiological Measure of Al.pdf:application/pdf;Snapshot:/home/simeon/Zotero/storage/KE4RXS9W/view.html:text/html},
}

@phdthesis{thorslund_electrooculogram_2003,
	title = {Electrooculogram analysis and development of a system for defining stages of drowsiness},
	author = {Thorslund, B.},
	year = {2003},
	file = {FULLTEXT01 (2).pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/FULLTEXT01 (2).pdf:application/pdf},
}

@article{yue_eog_2011,
	title = {{EOG} {Signals} in {Drowsiness} {Research}},
	language = {en},
	author = {Yue, Chongshi},
	year = {2011},
	pages = {59},
	file = {Yue - EOG Signals in Drowsiness Research.pdf:/home/simeon/Zotero/storage/62URKSLR/Yue - EOG Signals in Drowsiness Research.pdf:application/pdf;FULLTEXT01 (1).pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/FULLTEXT01 (1).pdf:application/pdf},
}

@inproceedings{yin_driver_2016,
	address = {Lake Placid, NY, USA},
	title = {A driver fatigue detection method based on multi-sensor signals},
	isbn = {978-1-5090-0641-0},
	url = {http://ieeexplore.ieee.org/document/7477672/},
	doi = {10.1109/WACV.2016.7477672},
	abstract = {Fatigue during long-time driving threatens the safety of drivers and transportation. In this paper, we provide an effective method based on multi-sensor signals collected from Kinect2.0 camera and PPG pulse sensor to build a driver fatigue detection system. Unlike most traditional works, we define the transitional process of fatigue and elaborate its effect on training classifiers. The simulation experiments are then designed and 15 groups of data are collected. Our method works in the following steps: 1) feature extraction and fusion, 2) sample labelling and 3) SVM classifier designing. The 10-fold cross-validation accuracy of the classifier is 90.10\% and the test accuracy is 83.82\%. Experimental results verify that our method to deal with samples in transitional process is universal and more accurate than traditional methods. Moreover, our method based on multi-sensor works better than those dealing with single-sensor.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2016 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Yin, Hao and Su, Yuanqi and Liu, Yuehu and Zhao, Danchen},
	year = {2016},
	keywords = {Eye features, eye blink detection, mulit sensor, PPG, image segmentation},
	pages = {1--7},
	file = {Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:/home/simeon/Zotero/storage/S9Z7VRXZ/Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:application/pdf;Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:/home/simeon/Zotero/storage/IM6U26MM/Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:application/pdf;Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:/home/simeon/Zotero/storage/ZKN6ZK5H/Yin et al. - 2016 - A driver fatigue detection method based on multi-s.pdf:application/pdf},
}

@article{sun_-vehicle_2011,
	title = {{AN} {IN}-{VEHICLE} {PHYSIOLOGICAL} {SIGNAL} {MONITORING} {SYSTEM} {FOR} {DRIVER} {FATIGUE} {DETECTION}},
	abstract = {This paper describes the development of an in-vehicle measurement system that monitors the physiological signals (i.e., heart rate, heart rate variation, breathing and eye brinking) of drivers. These physiological signals will be utilized to detect the onset of driver fatigue, crucial for timely applying drowsiness countermeasures. Fatigue driving is one of the most significant factors causing traffic accidents. Clinic research has found physiological signals are good indicators of drowsiness. A conventional bioelectrical signal measurement system requires the electrodes to be in contact with human body. This not only interferes with the normal driver operation, but also is not feasible for long term monitoring purpose. This study developed a non-contact sensing platform that can remotely detect bioelectrical signals in real time. With delicate sensor electronics design, the bioelectrical signals associated with electrocardiography (ECG), breathing and eye blinking can be measured. The current sensor can detect the Electrocardiography (ECG) signals with an effective distance of up to 30 cm away from the body. It also provides sensitive measurement of physiological signals such as heart rate, breathing, eye blinking etc. The sensor performance was validated on a high fidelity driving simulator. Digital signal processing algorithms has been developed to decimate the signal noise and automate signal analyses. The characteristics of physiological signals indicative of driver fatigue, i.e., the heart rate (HR), heart rate variability (HRV), breath frequency and eye blinking frequency, can be determined. A robust drowsiness indicator is being developed by coupling the multiple physiological parameters to achieve high reliability in drowsiness detection.},
	language = {en},
	author = {Sun, Ye and Yu, Xiong and Berilla, Jim and Liu, Zhen},
	year = {2011},
	pages = {16},
	file = {Sun et al. - AN IN-VEHICLE PHYSIOLOGICAL SIGNAL MONITORING SYST.pdf:/home/simeon/Zotero/storage/IFFLGMXZ/Sun et al. - AN IN-VEHICLE PHYSIOLOGICAL SIGNAL MONITORING SYST.pdf:application/pdf;Sun,Y.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/Sun,Y.pdf:application/pdf},
}

@article{sun_self-adaptive_2015,
	title = {A {Self}-{Adaptive} {Dynamic} {Recognition} {Model} for {Fatigue} {Driving} {Based} on {Multi}-{Source} {Information} and {Two} {Levels} of {Fusion}},
	volume = {15},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/15/9/24191},
	doi = {10.3390/s150924191},
	language = {en},
	number = {9},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Sun, Wei and Zhang, Xiaorui and Peeta, Srinivas and He, Xiaozheng and Li, Yongfu and Zhu, Senlai},
	year = {2015},
	pages = {24191--24213},
	file = {A Self-Adaptive Dynamic Recognition Model for Fatigue Driving Based on Multi-Source Information and Two Levels of Fusion.pdf:/home/simeon/Documents/ING5/Stage/Article/A Self-Adaptive Dynamic Recognition Model for Fatigue Driving Based on Multi-Source Information and Two Levels of Fusion.pdf:application/pdf;Sun et al. - 2015 - A Self-Adaptive Dynamic Recognition Model for Fati.pdf:/home/simeon/Zotero/storage/TEK6BQWP/Sun et al. - 2015 - A Self-Adaptive Dynamic Recognition Model for Fati.pdf:application/pdf},
}

@article{svensson_blink_2004,
	title = {Blink behaviour based drowsiness detection – method development and validation},
	abstract = {Electrooculogram (EOG) data was used to develop, adjust and validate a method for drowsiness detection in drivers. The drowsiness detection was based on changes in blink behaviour and classification was made on a four graded scale. The purpose was to detect early signs of drowsiness in order to warn a driver. MATLAB was used for implementation.},
	language = {en},
	author = {Svensson, Ulrika},
	year = {2004},
	pages = {87},
	file = {Svensson - Blink behaviour based drowsiness detection – metho.pdf:/home/simeon/Zotero/storage/AG58ACBY/Svensson - Blink behaviour based drowsiness detection – metho.pdf:application/pdf;FULLTEXT01.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/FULLTEXT01.pdf:application/pdf;FULLTEXT01.pdf:/Users/simeon/Desktop/Recherche/Article/physiologie-measure/FULLTEXT01.pdf:application/pdf},
}

@article{federal_highway_administration_perclos_1998,
	title = {{PERCLOS}: {A} {Valid} {Psychophysiological} {Measure} of {Alertness} {As} {Assessed} by {Psychomotor} {Vigilance}},
	language = {en},
	author = {Federal Highway Administration},
	year = {1998},
	pages = {4},
	file = {dot_113_DS1.pdf:/Users/simeon/Desktop/Recherche/Article/comportement-measure/dot_113_DS1.pdf:application/pdf;dot_113_DS1.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/dot_113_DS1.pdf:application/pdf},
}

@article{dosovitskiy_carla_2017,
	title = {{CARLA}: {An} {Open} {Urban} {Driving} {Simulator}},
	abstract = {We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports ﬂexible speciﬁcation of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an endto-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difﬁculty, and their performance is examined via metrics provided by CARLA, illustrating the platform’s utility for autonomous driving research.},
	language = {en},
	author = {Dosovitskiy, Alexey},
	year = {2017},
	pages = {16},
	file = {dosovitskiy17a.pdf:/Users/simeon/Desktop/Recherche/Article/vehicule-measure/dosovitskiy17a.pdf:application/pdf;dosovitskiy17a.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/dosovitskiy17a.pdf:application/pdf},
}

@book{karray_soft_2004,
	title = {Soft {Computing} and {Intelligent} {Systems} {Design}: {Theory}, {Tools}, and {Applications}},
	isbn = {978-0-321-11617-8},
	shorttitle = {Soft {Computing} and {Intelligent} {Systems} {Design}},
	abstract = {Traditional artificial intelligence (AI) techniques are based around mathematical techniques of symbolic logic, with programming in languages such as Prolog and LISP invented in the 1960s. These are referred to as "crisp" techniques by the soft computing community. The new wave of AI methods seeks inspiration from the world of biology, and is being used to create numerous real-world intelligent systems with the aid of soft computing tools. These new methods are being increasingly taught at the upper end of the curriculum, sometimes as an adjunct to traditional AI courses, and sometimes as a replacement for them. Where a more radical approach is taken and the course is being taught at an introductory level, we have recently published Negnevitsky's book. Karray and Silva will be suitable for the majority of courses which will be found at an advanced level. Karray and de Silva cover the problem of control and intelligent systems design using soft-computing techniques in an integrated manner. They present both theory and applications, including industrial applications, and the book contains numerous worked examples, problems and case studies. Covering the state-of-the-art in soft-computing techniques, the book gives the reader sufficient knowledge to tackle a wide range of complex systems for which traditional techniques are inadequate.},
	language = {en},
	publisher = {Pearson Education},
	author = {Karray, Fakhreddine and Karray, Fakhreddine O. and Silva, Clarence W. De},
	year = {2004},
	keywords = {Computers / Artificial Intelligence / General, Computers / Software Development \& Engineering / General},
}

@article{albus_theory_1992,
	title = {A {Theory} of {Intelligent} {Systems}},
	abstract = {A theoretical model is proposed consisting of seven basic elements: actuators, sensors, sensory processing, world modeling, task decomposition, value judgment, and global memorylcommunications. These elements are integrated into a hierarchical system architecture wherein: a ) control bandwidth decreases about an order of magnitude at each higher level, b) perceptual resolutionof spatial and temporal patterns contracts about an order-ofmagnitude at each higher level, c) goals expand in scope and planning horizons expand in space and time about an order-ofmagnitude at each higher level, and d ) models of the world and memories of events expand in space and time by about an order-ofmagnitude at each higher level. At each level, tightly coupled functional modules perform task decomposition, world modeling, sensory processing, and value judgment. Feedback control loops are closed at every level.},
	language = {en},
	author = {Albus, James S},
	year = {1992},
	pages = {10},
	file = {Albus - A Theory of Intelligent Systems.pdf:/home/simeon/Zotero/storage/BFHUDZIP/Albus - A Theory of Intelligent Systems.pdf:application/pdf;Albus_A Theory of Intelligent Systems.pdf:/home/simeon/Zotero/storage/4HWPQYYN/Albus_A Theory of Intelligent Systems.pdf:application/pdf;a-theory-of-intelligent-systems.pdf:/Users/simeon/Desktop/Recherche/Article/a classer/a-theory-of-intelligent-systems.pdf:application/pdf;a-theory-of-intelligent-systems.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/a-theory-of-intelligent-systems.pdf:application/pdf},
}

@book{paul_jorion_principes_1989,
	title = {Principes {Des} {Systemes} {Intelligents}},
	author = {Paul Jorion},
	year = {1989},
}

@techreport{road_traffic_injuries_world_2018,
	title = {World {Health} {Organization}. (2018). {Road} {Traffic} {Injuries}. [{Online}]. {Available}: https://www.who.int/en/news-room/fact-sheets/detail/road- traffic-injuries},
	author = {Road Traffic Injuries},
	year = {2018},
}

@misc{organisation_for_economic_co-operation_and_development_2017_road_2017,
	title = {Road {Safety} {Annual} {Report} 2017. [{Online}]. {Available}: https://www. oecd-ilibrary.org/transport/road-safety-annual-report-2017\_irtad-2017- en},
	author = {Organisation for Economic Co-operation {and} Development. (2017).},
	year = {2017},
}

@techreport{world_health_organization_world_2013,
	title = {World {Health} {Organization}. (2013). {Global} {Health} {Observatory} ({GHO}) {Data}. [{Online}]. [{Online}]. {Available}: https://www.who.int/gho/ road\_safety/en/},
	author = {World Health Organization},
	year = {2013},
}

@techreport{world_health_organization_world_2018,
	title = {World {Health} {Organization}. (2018). {Global} {Status} {Report} on {Road} {Safety} 2018. [{Online}]. {Available}: https://www.who.int/violence \_injury\_prevention/road\_safety\_status/2018/en/},
	author = {World Health Organization.},
	year = {2018},
}

@techreport{european_commission_european_2018,
	title = {European {Commission}. ({Nov}. 11, 2018). {European} {Commission} {Presents} {Final} {Road} {Safety} {Figures} for 2017 on {World} {Day} of {Remem}- brance for {Road} {Traffic} {Victims}. [{Online}]. {Available}: https://ec.europa. eu/transport/media/news/2018-11-16-road-safety-figures-2017\_en},
	author = {European Commission},
	year = {2018},
}

@article{le_application_2019,
	title = {Application of {Long} {Short}-{Term} {Memory} ({LSTM}) {Neural} {Network} for {Flood} {Forecasting}},
	volume = {11},
	doi = {10.3390/w11071387},
	abstract = {Flood forecasting is an essential requirement in integrated water resource management. This paper suggests a Long Short-Term Memory (LSTM) neural network model for flood forecasting, where the daily discharge and rainfall were used as input data. Moreover, characteristics of the data sets which may influence the model performance were also of interest. As a result, the Da River basin in Vietnam was chosen and two different combinations of input data sets from before 1985 (when the Hoa Binh dam was built) were used for one-day, two-day, and three-day flowrate forecasting ahead at Hoa Binh Station. The predictive ability of the model is quite impressive: The Nash–Sutcliffe efficiency (NSE) reached 99\%, 95\%, and 87\% corresponding to three forecasting cases, respectively. The findings of this study suggest a viable option for flood forecasting on the Da River in Vietnam, where the river basin stretches between many countries and downstream flows (Vietnam) may fluctuate suddenly due to flood discharge from upstream hydroelectric reservoirs.},
	journal = {Water},
	author = {Le, Xuan Hien and Ho, Hung and Lee, Giha and Jung, Sungho},
	month = jul,
	year = {2019},
	pages = {1387},
	file = {Full Text PDF:/home/simeon/Zotero/storage/U4FZQAH7/Le et al. - 2019 - Application of Long Short-Term Memory (LSTM) Neura.pdf:application/pdf},
}

@inproceedings{kazemi_one_2014,
	address = {Columbus, OH},
	title = {One millisecond face alignment with an ensemble of regression trees},
	isbn = {978-1-4799-5118-5},
	url = {https://ieeexplore.ieee.org/document/6909637},
	doi = {10.1109/CVPR.2014.241},
	abstract = {This paper addresses the problem of Face Alignment for a single image. We show how an ensemble of regression trees can be used to estimate the face’s landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. We present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. We show how using appropriate priors exploiting the structure of image data helps with efﬁcient feature selection. Different regularization strategies and its importance to combat overﬁtting are also investigated. In addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.},
	language = {en},
	urldate = {2021-06-28},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Kazemi, Vahid and Sullivan, Josephine},
	month = jun,
	year = {2014},
	pages = {1867--1874},
	file = {Kazemi and Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:/home/simeon/Zotero/storage/9FLL2AYL/Kazemi and Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:application/pdf;Kazemi and Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:/home/simeon/Zotero/storage/IRBADG84/Kazemi and Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:application/pdf;Kazemi et Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:/home/simeon/Zotero/storage/RVPBQ8HF/Kazemi et Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:application/pdf},
}

@misc{noauthor_ipazcmtcnn_nodate,
	title = {ipazc/mtcnn: {MTCNN} face detection implementation for {TensorFlow}, as a {PIP} package.},
	url = {https://github.com/ipazc/mtcnn},
	urldate = {2021-06-28},
	file = {ipazc/mtcnn\: MTCNN face detection implementation for TensorFlow, as a PIP package.:/home/simeon/Zotero/storage/6ANJRWI4/mtcnn.html:text/html},
}

@inproceedings{dalal_histograms_2005,
	address = {San Diego, CA, USA},
	title = {Histograms of {Oriented} {Gradients} for {Human} {Detection}},
	volume = {1},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467360/},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors signiﬁcantly outperform existing feature sets for human detection. We study the inﬂuence of each stage of the computation on performance, concluding that ﬁne-scale gradients, ﬁne orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	language = {en},
	urldate = {2021-06-28},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {Dalal, N. and Triggs, B.},
	year = {2005},
	pages = {886--893},
	file = {Dalal et Triggs - 2005 - Histograms of Oriented Gradients for Human Detecti.pdf:/home/simeon/Zotero/storage/VTS48LLR/Dalal et Triggs - 2005 - Histograms of Oriented Gradients for Human Detecti.pdf:application/pdf},
}

@inproceedings{williamson_audio_2020,
	address = {Montreal, QC, Canada},
	title = {Audio, {Visual}, and {Electrodermal} {Arousal} {Signals} as {Predictors} of {Mental} {Fatigue} {Following} {Sustained} {Cognitive} {Work}},
	isbn = {978-1-72811-990-8},
	url = {https://ieeexplore.ieee.org/document/9175951/},
	doi = {10.1109/EMBC44109.2020.9175951},
	abstract = {Lapses in vigilance and slowed reactions due to mental fatigue can increase risk of accidents and injuries and degrade performance. This paper describes a method for rapid, unobtrusive detection of mental fatigue based on changes in electrodermal arousal (EDA), and changes in neuromotor coordination derived from speaking. Twenty-nine Soldiers completed a 2-hour battery of cognitive tasks intended to induce fatigue. Behavioral markers derived from audio and video during speech were acquired before and after the 2hour cognitive load tasks, as was EDA. Exposure to cognitive load produced detectable increases in neuromotor variability in speech and facial measures after load and even after a recovery period. A Gaussian mixture model classiﬁer with crossvalidation and fusion across speech, video, and EDA produced an accuracy of AUC=0.99 in detecting a change in cognitive fatigue relative to a personalized baseline.},
	language = {en},
	urldate = {2021-05-26},
	booktitle = {2020 42nd {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} \& {Biology} {Society} ({EMBC})},
	publisher = {IEEE},
	author = {Williamson, James R. and Heaton, Kristin J. and Lammert, Adam and Finkelstein, Katherine and Sturim, Doug and Smalt, Christopher and Ciccarelli, Gregory and Quatieri, Thomas F.},
	month = jul,
	year = {2020},
	pages = {832--836},
	file = {Williamson et coll., 2020_Audio, Visual, and Electrodermal Arousal Signals as Predictors of Mental Fatigue Following Sustained Cognitive Work.pdf:/home/simeon/Téléchargements/Williamson et coll., 2020_Audio, Visual, and Electrodermal Arousal Signals as Predictors of Mental Fatigue Following Sustained Cognitive Work.pdf:application/pdf},
}

@article{brown_driver_1994,
	title = {Driver {Fatigue}},
	volume = {36},
	issn = {0018-7208},
	url = {https://doi.org/10.1177/001872089403600210},
	doi = {10.1177/001872089403600210},
	abstract = {Psychological fatigue is defined as a subjectively experienced disinclination to continue performing the task at hand. It generally impairs human efficiency when individuals continue working after they have become aware of their fatigue. It does not depend on energy expenditure and. cannot be measured simply in terms of performance impairment. The interacting causal contributions to fatigue are the length of continuous work spells and daily duty periods, time available for rest and continuous sleep, and the arrangement of duty, rest, and sleep periods within each 24-h cycle. Empirical evidence for the separate and combined effects of these factors on fatigue, performance decrement, and accident risk are briefly reviewed, and the implications of these findings for driving and road safety are considered, with particular reference to the professional driver. This study shows that fatigue is insufficiently recognized and reported as a cause of road accidents and that its effects stem largely from prolonged and irregular working hours, rather than simply from time spent at the wheel.},
	language = {en},
	number = {2},
	urldate = {2021-05-26},
	journal = {Human Factors},
	author = {Brown, Ivan D.},
	month = jun,
	year = {1994},
	note = {Publisher: SAGE Publications Inc},
	pages = {298--314},
}

@inproceedings{nguyen_efficient_2017,
	address = {Da Nang, Vietnam},
	title = {An efficient real-time emotion detection using camera and facial landmarks},
	isbn = {978-1-5090-5401-5},
	url = {http://ieeexplore.ieee.org/document/7926765/},
	doi = {10.1109/ICIST.2017.7926765},
	abstract = {Emotion recognition has many useful applications in daily lives. In this paper, we present a potential approach to detect human emotion in real time. For any face detected in camera, we extract the corresponding facial landmarks and examine different kinds of features and models for predicting human emotion. The experiments show that our proposed system can naturally detect human emotion in real time and achieve an average accuracy about 70.65\%.},
	language = {en},
	urldate = {2021-05-26},
	booktitle = {2017 {Seventh} {International} {Conference} on {Information} {Science} and {Technology} ({ICIST})},
	publisher = {IEEE},
	author = {Nguyen, Binh T. and Trinh, Minh H. and Phan, Tan V. and Nguyen, Hien D.},
	month = apr,
	year = {2017},
	pages = {251--255},
	file = {nguyen2017.pdf:/home/simeon/Téléchargements/nguyen2017.pdf:application/pdf},
}

@article{noauthor_notitle_nodate,
}

@misc{noauthor_zotero_nodate-1,
	title = {Zotero {\textbar} {Your} personal research assistant},
	url = {https://www.zotero.org/start},
	urldate = {2021-05-26},
	file = {Zotero | Your personal research assistant:/home/simeon/Zotero/storage/QUCHYR2B/start.html:text/html},
}

@misc{noauthor_rapport_nodate,
	title = {Rapport},
	url = {https://docs.google.com/document/d/12f0rOjZ1E_N9xu4R-cPcp2VA3XqYR8uRCDCyWNxp5Qo/edit?usp=drive_web&ouid=108912698028632509718&usp=embed_facebook},
	abstract = {Rapport    Introduction	2 Paramètres relatifs à la fatigue	3 Paramètres véhicules	3 Paramètres physionomiques	3 Méthode d'acquisition des paramètres	3 Méthode basé sur les caméras	3 Méthode basé sur le vehicule	3 Les modèles utilisé pour représenter la fatigue	4 Les systèmes d’apprentissage auto...},
	language = {fr},
	urldate = {2021-04-01},
	journal = {Google Docs},
	file = {Snapshot:/home/simeon/Zotero/storage/KLBEIKP4/edit.html:text/html},
}

@article{kretzmer_costs_1974,
	title = {The {Costs} of {Accidents}: {A} {Legal} and {Economic} {Analysis}. {By} {Guido} {Calabresi}. [{Yale} {University} {Press}, {New} {Haven} and {London}. 1970, 340 pp.]},
	volume = {9},
	issn = {2047-9336, 0021-2237},
	shorttitle = {The {Costs} of {Accidents}},
	url = {https://www.cambridge.org/core/journals/israel-law-review/article/abs/costs-of-accidents-a-legal-and-economic-analysis-by-guido-calabresi-yale-university-press-new-haven-and-london-1970-340-pp/C54475C91C418FC86FC07283FEA4D42A},
	doi = {10.1017/S0021223700004581},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0021223700004581/resource/name/firstPage-S0021223700004581a.jpg},
	language = {en},
	number = {1},
	urldate = {2021-04-01},
	journal = {Israel Law Review},
	author = {Kretzmer, David},
	month = jan,
	year = {1974},
	note = {Publisher: Cambridge University Press},
	pages = {148--156},
	file = {Snapshot:/home/simeon/Zotero/storage/7CHE2PXK/C54475C91C418FC86FC07283FEA4D42A.html:text/html},
}

@misc{noauthor_ventes_nodate,
	title = {Ventes internationales de voitures 1990-2019},
	url = {https://fr.statista.com/statistiques/558755/ventes-de-voitures-a-l-echelle-mondiale/},
	abstract = {Cette statistique représente le nombre de voitures vendues dans le monde de 1990 à 2018.},
	language = {fr},
	urldate = {2021-03-22},
	journal = {Statista},
	keywords = {statistiques},
	file = {Snapshot:/home/simeon/Zotero/storage/Q9XHUECE/ventes-de-voitures-a-l-echelle-mondiale.html:text/html;Snapshot:/home/simeon/Zotero/storage/JZU2D5N6/ventes-de-voitures-a-l-echelle-mondiale.html:text/html},
}

@article{savas_real_2020,
	title = {Real {Time} {Driver} {Fatigue} {Detection} {System} {Based} on {Multi}-{Task} {ConNN}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8949469/},
	doi = {10.1109/ACCESS.2020.2963960},
	abstract = {Changes and progresses in information technologies have played an important role in the development of intelligent vehicle systems in recent years. Driver fatigue is an important factor in vehicle accidents. For this reason, trafﬁc accidents involving driver fatigue and driver carelessness have been followed by researchers. In this article, a Multi-tasking Convulational Neural Network (ConNN∗) model is proposed to detect driver drowsiness/fatigue. Eye and mouth characteristics are utilized for driver’s behavior model. Changes to these characteristics are used to monitor driver fatigue. With the proposed Multi-task ConNN model, unlike the studies in the literature, both mouth and eye information are classiﬁed into a single model at the same time. Driver fatigue is determined by calculating eyes’ closure duration/Percentage of eye closure (PERCLOS) and yawning frequency/frequency of mouth (FOM). In this study, the fatigue degree of the driver is divided into 3 classes. The proposed model achieved 98.81\% fatigue detection on YawdDD and NthuDDD dataset. The success of the model is presented comparatively.},
	language = {en},
	urldate = {2021-02-17},
	journal = {IEEE Access},
	author = {Savas, Burcu Kir and Becerikli, Yasar},
	year = {2020},
	keywords = {done, drive},
	pages = {12491--12498},
	file = {Savas and Becerikli - 2020 - Real Time Driver Fatigue Detection System Based on.pdf:/home/simeon/Zotero/storage/9XGUWL6G/Savas and Becerikli - 2020 - Real Time Driver Fatigue Detection System Based on.pdf:application/pdf;Savas and Becerikli - 2020 - Real Time Driver Fatigue Detection System Based on.pdf:/home/simeon/Zotero/storage/XPGGWRM9/Savas and Becerikli - 2020 - Real Time Driver Fatigue Detection System Based on.pdf:application/pdf},
}

@article{sayed_unobtrusive_2001,
	title = {Unobtrusive drowsiness detection by neural network learning of driver steering},
	volume = {215},
	issn = {0954-4070, 2041-2991},
	url = {http://journals.sagepub.com/doi/10.1243/0954407011528536},
	doi = {10.1243/0954407011528536},
	abstract = {The purpose of this study is to detect drowsiness in drivers unobtrusively to prevent accidents and to improve safety on the highways. A method for detecting drowsiness/sleepiness in drivers is developed. This method is based on an arti cial neural network (ANN ). Steering angle signals are preprocessed and presented to the ANN which classi es them into drowsy and non-drowsy driving intervals. The method presented here relies on signals from the vehicle steering only (steering angle) and thus presents no obstruction to the driver. A feedforward ANN was trained using an error back-propagation algorithm and tested. The training and testing data were obtained from a previous experiment in a driving simulator driven by 12 drivers, each under diVerent levels of sleep deprivation. The network classi es driving intervals into drowsy and non-drowsy intervals with high accuracy.},
	language = {en},
	number = {9},
	urldate = {2021-02-17},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering},
	author = {Sayed, R and Eskandarian, A},
	month = sep,
	year = {2001},
	keywords = {done, drive},
	pages = {969--975},
	file = {Unobtrusive drowsiness detection by neural network learning of driver steering.pdf:/home/simeon/Documents/ING5/Stage/Article/Unobtrusive drowsiness detection by neural network
learning of driver steering.pdf:application/pdf;Sayed and Eskandarian - 2001 - Unobtrusive drowsiness detection by neural network.pdf:/home/simeon/Zotero/storage/G7I3956G/Sayed and Eskandarian - 2001 - Unobtrusive drowsiness detection by neural network.pdf:application/pdf},
}

@article{tsai_vision-based_2020,
	title = {Vision-{Based} {Instant} {Measurement} {System} for {Driver} {Fatigue} {Monitoring}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9058685/},
	doi = {10.1109/ACCESS.2020.2986234},
	abstract = {In this paper, a vision-based physiological signal measurement system is proposed to instantly measure driver fatigue. A remote photoplethysmography (rPPG) signal is a type of physiological signal measured by a camera without any contact device, and it also retains the characteristics of the PPG, which is useful to evaluate fatigue. To solve the inconvenience caused by the traditional contact-based physiological fatigue detection system and to improve the accuracy, the system measures both the motional and physiological information by using one image sensor. In a practical application, the environmental noise would affect the measured signal, and therefore, we performed a preprocessing step on the signal to extract a clear signal. The experiment was designed in collaboration with Taipei Medical University, and a questionnaire-based method was used to deﬁne fatigue. The questionnaire that could directly react to the feeling of the subject was treated as our ground truth. The evaluated correlation was 0.89 and the root mean square error was 0.65 for ten-fold cross-validation on the dataset. The trend of driver fatigue could be evaluated without a contact device by the proposed system. This advantage ensures the safety of the driver and reliability of the system.},
	language = {en},
	urldate = {2021-02-17},
	journal = {IEEE Access},
	author = {Tsai, Yin-Cheng and Lai, Peng-Wen and Huang, Po-Wei and Lin, Tzu-Min and Wu, Bing-Fei},
	year = {2020},
	keywords = {done, drive},
	pages = {67342--67353},
	file = {Tsai et al. - 2020 - Vision-Based Instant Measurement System for Driver.pdf:/home/simeon/Zotero/storage/5E855KSW/Tsai et al. - 2020 - Vision-Based Instant Measurement System for Driver.pdf:application/pdf;Tsai et al. - 2020 - Vision-Based Instant Measurement System for Driver.pdf:/home/simeon/Zotero/storage/A65DHECU/Tsai et al. - 2020 - Vision-Based Instant Measurement System for Driver.pdf:application/pdf;Vision-Based Instant Measurement System for Driver Fatigue Monitoring.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/Vision-Based Instant Measurement System for Driver Fatigue Monitoring.pdf:application/pdf},
}

@article{geng_real-time_2019,
	title = {Real-time {Fatigue} {Driving} {Recognition} {System} {Based} on {Deep} {Learning} and {Embedded} {Platform}},
	volume = {53},
	abstract = {The frequent occurrence of automobile traffic accidents seriously threatens the safety of human life and property. Therefore, fatigue driving detection has important social value and research significance. In consideration of the market demand of intelligent assistant driving system, we design a real-time driver fatigue detection system based on deep learning and ARM platform, which uses Samsung 6818A53 series ARM as the driver fatigue real-time detection platform. In order to reduce the interference caused by the change of light and the occlusion of sunglasses in the actual driving environment, the driver's face image is captured by USB infrared camera. Firstly, face detection and alignment are carried out by multi-task cascaded convolutional neural network; Then the eye region is obtained according to geometric relationship between the feature points; Moreover, the driver's eye state is identified by Convolutional Neural Network (CNN); Finally, fatigue judgment is made based on PERCLOS criterion. The system has been tested in the experimental simulation environment and the actual driving environment. The experimental results show that detection speed of the system can reach more than 20 frames per second, which meets the requirement of real-time detection.},
	language = {en},
	number = {1},
	author = {Geng, Lei and Hu, ZhiQiang and Xiao, ZhiTao},
	year = {2019},
	keywords = {done, drive},
	pages = {12},
	file = {235050787.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_read/235050787.pdf:application/pdf;Geng et al. - 2019 - Real-time Fatigue Driving Recognition System Based.pdf:/home/simeon/Zotero/storage/WQFIANIF/Geng et al. - 2019 - Real-time Fatigue Driving Recognition System Based.pdf:application/pdf},
}

@article{daza_fusion_2014,
	title = {Fusion of {Optimized} {Indicators} from {Advanced} {Driver} {Assistance} {Systems} ({ADAS}) for {Driver} {Drowsiness} {Detection}},
	volume = {14},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/14/1/1106},
	doi = {10.3390/s140101106},
	abstract = {This paper presents a non-intrusive approach for monitoring driver drowsiness using the fusion of several optimized indicators based on driver physical and driving performance measures, obtained from ADAS (Advanced Driver Assistant Systems) in simulated conditions. The paper is focused on real-time drowsiness detection technology rather than on long-term sleep/awake regulation prediction technology. We have developed our own vision system in order to obtain robust and optimized driver indicators able to be used in simulators and future real environments. These indicators are principally based on driver physical and driving performance skills. The fusion of several indicators, proposed in the literature, is evaluated using a neural network and a stochastic optimization method to obtain the best combination. We propose a new method for ground-truth generation based on a supervised Karolinska Sleepiness Scale (KSS). An extensive evaluation of indicators, derived from trials over a third generation simulator with several test subjects during different driving sessions, was performed. The main conclusions about the performance of single indicators and the best combinations of them are included, as well as the future works derived from this study.},
	language = {en},
	number = {1},
	urldate = {2021-02-19},
	journal = {Sensors},
	author = {Daza, Iván and Bergasa, Luis and Bronte, Sebastián and Yebes, J. and Almazán, Javier and Arroyo, Roberto},
	month = jan,
	year = {2014},
	keywords = {done, drive},
	pages = {1106--1131},
	file = {Daza et al. - 2014 - Fusion of Optimized Indicators from Advanced Drive.pdf:/home/simeon/Zotero/storage/42XSDTVF/Daza et al. - 2014 - Fusion of Optimized Indicators from Advanced Drive.pdf:application/pdf;sensors-14-01106-v2.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/sensors-14-01106-v2.pdf:application/pdf;Daza et al. - 2014 - Fusion of Optimized Indicators from Advanced Drive.pdf:/home/simeon/Zotero/storage/6VUD7E9E/Daza et al. - 2014 - Fusion of Optimized Indicators from Advanced Drive.pdf:application/pdf},
}

@inproceedings{dwivedi_drowsy_2014,
	address = {Gurgaon, India},
	title = {Drowsy driver detection using representation learning},
	isbn = {978-1-4799-2572-8 978-1-4799-2571-1},
	url = {http://ieeexplore.ieee.org/document/6779459/},
	doi = {10.1109/IAdCC.2014.6779459},
	abstract = {The advancement of computing technology over the years has provided assistance to drivers mainly in the form of intelligent vehicle systems. Driver fatigue is a significant factor in a large number of vehicle accidents. Thus, driver drowsiness detection has been considered a major potential area so as to prevent a huge number of sleep induced road accidents. This paper proposes a vision based intelligent algorithm to detect driver drowsiness. Previous approaches are generally based on blink rate, eye closure, yawning, eye brow shape and other hand engineered facial features. The proposed algorithm makes use of features learnt using convolutional neural network so as to explicitly capture various latent facial features and the complex non-linear feature interactions. A softmax layer is used to classify the driver as drowsy or non-drowsy. This system is hence used for warning the driver of drowsiness or in attention to prevent traffic accidents.We present both qualitative and quantitative results to substantiate the claims made in the paper.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2014 {IEEE} {International} {Advance} {Computing} {Conference} ({IACC})},
	publisher = {IEEE},
	author = {Dwivedi, Kartik and Biswaranjan, Kumar and Sethi, Amit},
	month = feb,
	year = {2014},
	keywords = {done, drive},
	pages = {995--999},
	file = {Dwivedi et al. - 2014 - Drowsy driver detection using representation learn.pdf:/home/simeon/Zotero/storage/JXAGQ6LM/Dwivedi et al. - 2014 - Drowsy driver detection using representation learn.pdf:application/pdf;Drowsy Driver Detection using Representation Learning.pdf:/home/simeon/Documents/ING5/Stage/Article/Drowsy Driver Detection using Representation Learning.pdf:application/pdf},
}

@article{jeong_drivers_2018,
	title = {Driver’s {Facial} {Expression} {Recognition} in {Real}-{Time} for {Safe} {Driving}},
	volume = {18},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/18/12/4270},
	doi = {10.3390/s18124270},
	abstract = {In recent years, researchers of deep neural networks (DNNs)-based facial expression recognition (FER) have reported results showing that these approaches overcome the limitations of conventional machine learning-based FER approaches. However, as DNN-based FER approaches require an excessive amount of memory and incur high processing costs, their application in various fields is very limited and depends on the hardware specifications. In this paper, we propose a fast FER algorithm for monitoring a driver’s emotions that is capable of operating in low specification devices installed in vehicles. For this purpose, a hierarchical weighted random forest (WRF) classifier that is trained based on the similarity of sample data, in order to improve its accuracy, is employed. In the first step, facial landmarks are detected from input images and geometric features are extracted, considering the spatial position between landmarks. These feature vectors are then implemented in the proposed hierarchical WRF classifier to classify facial expressions. Our method was evaluated experimentally using three databases, extended Cohn-Kanade database (CK+), MMI and the Keimyung University Facial Expression of Drivers (KMU-FED) database, and its performance was compared with that of state-of-the-art methods. The results show that our proposed method yields a performance similar to that of deep learning FER methods as 92.6\% for CK+ and 76.7\% for MMI, with a significantly reduced processing cost approximately 3731 times less than that of the DNN method. These results confirm that the proposed method is optimized for real-time embedded applications having limited computing resources.},
	language = {en},
	number = {12},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Jeong, Mira and Ko, Byoung Chul},
	month = dec,
	year = {2018},
	keywords = {done, drive},
	pages = {4270},
	file = {Jeong and Ko - 2018 - Driver’s Facial Expression Recognition in Real-Tim.pdf:/home/simeon/Zotero/storage/Z98MYA6A/Jeong and Ko - 2018 - Driver’s Facial Expression Recognition in Real-Tim.pdf:application/pdf;jeong2018.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/comportement-measure/jeong2018.pdf:application/pdf;Jeong and Ko - 2018 - Driver’s Facial Expression Recognition in Real-Tim.pdf:/home/simeon/Zotero/storage/6YDB2WAC/Jeong and Ko - 2018 - Driver’s Facial Expression Recognition in Real-Tim.pdf:application/pdf},
}

@article{guo_driver_2019,
	title = {Driver drowsiness detection using hybrid convolutional neural network and long short-term memory},
	volume = {78},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-018-6378-6},
	doi = {10.1007/s11042-018-6378-6},
	abstract = {Drowsiness and fatigue of the drivers are amongst the significant causes of the car accidents. Every year the number of deaths and fatalities are tremendously increasing due to multifaceted issues and henceforth requires an intelligent processing system for accident avoidance. In relevant with this, an effective driver drowsiness detection system is proposed. The main challenges are robustness of the algorithm towards variation of the human face and real-time processing capability. The first challenge pertaining to the facial variation has been handled well using conventional image processing and handcraft features of computer vision algorithms. Yet, variations such as facial expression, lighting condition, intra-class variation, and pose variation are additional issues that conventional method failed to address. Deep learning is an alternative solution which provides a better performance by learning features automatically. Thus, this paper proposed a new concept for handling the real-time driver drowsiness detection using the hybrid of convolutional neural network (CNN) and long short-term memory (LSTM). The performance of the system has been tested using the public drowsy driver dataset from ACCV 2016 competition. The results show that it can outperform the former schemes in the literature.},
	language = {en},
	number = {20},
	urldate = {2021-02-17},
	journal = {Multimedia Tools and Applications},
	author = {Guo, Jing-Ming and Markoni, Herleeyandi},
	month = oct,
	year = {2019},
	keywords = {a résumer, done, drive},
	pages = {29059--29087},
	file = {Guo and Markoni - 2019 - Driver drowsiness detection using hybrid convoluti.pdf:/home/simeon/Zotero/storage/Y62NNWIH/Guo and Markoni - 2019 - Driver drowsiness detection using hybrid convoluti.pdf:application/pdf},
}

@incollection{chen_driver_2017,
	address = {Cham},
	title = {Driver {Drowsiness} {Detection} {System} {Based} on {Feature} {Representation} {Learning} {Using} {Various} {Deep} {Networks}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	url = {http://link.springer.com/10.1007/978-3-319-54526-4_12},
	abstract = {Statistics have shown that 20\% of all road accidents are fatigue-related, and drowsy detection is a car safety algorithm that can alert a snoozing driver in hopes of preventing an accident. This paper proposes a deep architecture referred to as deep drowsiness detection (DDD) network for learning eﬀective features and detecting drowsiness given a RGB input video of a driver. The DDD network consists of three deep networks for attaining global robustness to background and environmental variations and learning local facial movements and head gestures important for reliable detection. The outputs of the three networks are integrated and fed to a softmax classiﬁer for drowsiness detection. Experimental results show that DDD achieves 73.06\% detection accuracy on NTHU-drowsy driver detection benchmark dataset.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Park, Sanghyuk and Pan, Fei and Kang, Sunghun and Yoo, Chang D.},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_12},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {Physical, cnn, features exctraction, multiple cnn, done, drive},
	pages = {154--164},
	file = {Park et al. - 2017 - Driver Drowsiness Detection System Based on Featur.pdf:/home/simeon/Zotero/storage/DRMBHAD9/Park et al. - 2017 - Driver Drowsiness Detection System Based on Featur.pdf:application/pdf},
}

@inproceedings{jabbar_driver_2020,
	address = {Doha, Qatar},
	title = {Driver {Drowsiness} {Detection} {Model} {Using} {Convolutional} {Neural} {Networks} {Techniques} for {Android} {Application}},
	isbn = {978-1-72814-821-2},
	url = {https://ieeexplore.ieee.org/document/9089484/},
	doi = {10.1109/ICIoT48696.2020.9089484},
	abstract = {A sleepy driver is arguably much more dangerous on the road than the one who is speeding as he is a victim of microsleeps. Automotive researchers and manufacturers are trying to curb this problem with several technological solutions that will avert such a crisis. This article focuses on the detection of such micro sleep and drowsiness using neural networkbased methodologies. Our previous work in this ﬁeld involved using machine learning with multi-layer perceptron to detect the same. In this paper, accuracy was increased by utilizing facial landmarks which are detected by the camera and that is passed to a Convolutional Neural Network (CNN) to classify drowsiness. The achievement with this work is the capability to provide a lightweight alternative to heavier classiﬁcation models with more than 88\% for the category without glasses, more than 85\% for the category night without glasses. On average, more than 83\% of accuracy was achieved in all categories. Moreover, as for model size, complexity and storage, there is a marked reduction in the new proposed model in comparison to the benchmark model where the maximum size is 75 KB. The proposed CNN based model can be used to build a real-time driver drowsiness detection system for embedded systems and Android devices with high accuracy and ease of use.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {2020 {IEEE} {International} {Conference} on {Informatics}, {IoT}, and {Enabling} {Technologies} ({ICIoT})},
	publisher = {IEEE},
	author = {Jabbar, Rateb and Shinoy, Mohammed and Kharbeche, Mohamed and Al-Khalifa, Khalifa and Krichen, Moez and Barkaoui, Kamel},
	month = feb,
	year = {2020},
	keywords = {done, drive},
	pages = {237--242},
	file = {Driver Drowsiness Detection Model Using Convolutional Neural Networks Techniques for Android Application.pdf:/home/simeon/Documents/ING5/Stage/Article/Driver Drowsiness Detection Model Using Convolutional Neural Networks Techniques for Android Application.pdf:application/pdf;Jabbar et al. - 2020 - Driver Drowsiness Detection Model Using Convolutio.pdf:/home/simeon/Zotero/storage/T4252HGD/Jabbar et al. - 2020 - Driver Drowsiness Detection Model Using Convolutio.pdf:application/pdf},
}

@article{jacobe_de_naurois_detection_2019,
	title = {Detection and prediction of driver drowsiness using artificial neural network models},
	volume = {126},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457517304347},
	doi = {10.1016/j.aap.2017.11.038},
	abstract = {Not just detecting but also predicting impairment of a car driver’s operational state is a challenge. This study aims to determine whether the standard sources of information used to detect drowsiness can also be used to predict when a given drowsiness level will be reached. Moreover, we explore whether adding data such as driving time and participant information improves the accuracy of detection and prediction of drowsiness. Twenty-one participants drove a car simulator for 110 min under conditions optimized to induce drowsiness. We measured physiological and behavioral indicators such as heart rate and variability, respiration rate, head and eyelid movements (blink duration, frequency and PERCLOS) and recorded driving behavior such as time-to-lanecrossing, speed, steering wheel angle, position on the lane. Diﬀerent combinations of this information were tested against the real state of the driver, namely the ground truth, as deﬁned from video recordings via the Trained Observer Rating. Two models using artiﬁcial neural networks were developed, one to detect the degree of drowsiness every minute, and the other to predict every minute the time required to reach a particular drowsiness level (moderately drowsy). The best performance in both detection and prediction is obtained with behavioral indicators and additional information. The model can detect the drowsiness level with a mean square error of 0.22 and can predict when a given drowsiness level will be reached with a mean square error of 4.18 min. This study shows that, on a controlled and very monotonous environment conducive to drowsiness in a driving simulator, the dynamics of driver impairment can be predicted.},
	language = {en},
	urldate = {2021-02-17},
	journal = {Accident Analysis \& Prevention},
	author = {Jacobé de Naurois, Charlotte and Bourdin, Christophe and Stratulat, Anca and Diaz, Emmanuelle and Vercher, Jean-Louis},
	month = may,
	year = {2019},
	keywords = {done, drive},
	pages = {95--104},
	file = {Jacobé de Naurois et al. - 2019 - Detection and prediction of driver drowsiness usin.pdf:/home/simeon/Zotero/storage/VYJ5KWYX/Jacobé de Naurois et al. - 2019 - Detection and prediction of driver drowsiness usin.pdf:application/pdf},
}

@article{samiee_data_2014,
	title = {Data {Fusion} to {Develop} a {Driver} {Drowsiness} {Detection} {System} with {Robustness} to {Signal} {Loss}},
	volume = {14},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/14/9/17832},
	doi = {10.3390/s140917832},
	abstract = {This study proposes a drowsiness detection approach based on the combination of several different detection methods, with robustness to the input signal loss. Hence, if one of the methods fails for any reason, the whole system continues to work properly. To choose correct combination of the available methods and to utilize the benefits of methods of different categories, an image processing-based technique as well as a method based on driver-vehicle interaction is used. In order to avoid driving distraction, any use of an intrusive method is prevented. A driving simulator is used to gather real data and then artificial neural networks are used in the structure of the designed system. Several tests were conducted on twelve volunteers while their sleeping situations during one day prior to the tests, were fully under control. Although the impact of the proposed system on the improvement of the detection accuracy is not remarkable, the results indicate the main advantages of the system are the reliability of the detections and robustness to the loss of the input signals. The high reliability of the drowsiness detection systems plays an important role to reduce drowsiness related road accidents and their associated costs.},
	language = {en},
	number = {9},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Samiee, Sajjad and Azadi, Shahram and Kazemi, Reza and Nahvi, Ali and Eichberger, Arno},
	month = sep,
	year = {2014},
	keywords = {done, drive},
	pages = {17832--17847},
	file = {Samiee et al. - 2014 - Data Fusion to Develop a Driver Drowsiness Detecti.pdf:/home/simeon/Zotero/storage/VI85X56E/Samiee et al. - 2014 - Data Fusion to Develop a Driver Drowsiness Detecti.pdf:application/pdf;Samiee et al. - 2014 - Data Fusion to Develop a Driver Drowsiness Detecti.pdf:/home/simeon/Zotero/storage/9NJ6LEP5/Samiee et al. - 2014 - Data Fusion to Develop a Driver Drowsiness Detecti.pdf:application/pdf;Data Fusion to Develop a Driver Drowsiness Detection System nwith Robustness to Signal Loss.pdf:/home/simeon/Documents/ING5/Stage/Article/Data Fusion to Develop a Driver Drowsiness Detection System nwith Robustness to Signal Loss.pdf:application/pdf},
}

@article{li_automatic_2017,
	title = {Automatic {Detection} of {Driver} {Fatigue} {Using} {Driving} {Operation} {Information} for {Transportation} {Safety}},
	volume = {17},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/17/6/1212},
	doi = {10.3390/s17061212},
	abstract = {Fatigued driving is a major cause of road accidents. For this reason, the method in this paper is based on the steering wheel angles (SWA) and yaw angles (YA) information under real driving conditions to detect drivers’ fatigue levels. It analyzes the operation features of SWA and YA under different fatigue statuses, then calculates the approximate entropy (ApEn) features of a short sliding window on time series. Using the nonlinear feature construction theory of dynamic time series, with the fatigue features as input, designs a “2-6-6-3” multi-level back propagation (BP) Neural Networks classiﬁer to realize the fatigue detection. An approximately 15-h experiment is carried out on a real road, and the data retrieved are segmented and labeled with three fatigue levels after expert evaluation, namely “awake”, “drowsy” and “very drowsy”. The average accuracy of 88.02\% in fatigue identiﬁcation was achieved in the experiment, endorsing the value of the proposed method for engineering applications.},
	language = {en},
	number = {6},
	urldate = {2021-02-17},
	journal = {Sensors},
	author = {Li, Zuojin and Chen, Liukui and Peng, Jun and Wu, Ying},
	month = may,
	year = {2017},
	keywords = {done, drive},
	pages = {1212},
	file = {li2017 (1).pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/vehicule-measure/li2017 (1).pdf:application/pdf;Li et al. - 2017 - Automatic Detection of Driver Fatigue Using Drivin.pdf:/home/simeon/Zotero/storage/AGN4FZTQ/Li et al. - 2017 - Automatic Detection of Driver Fatigue Using Drivin.pdf:application/pdf},
}

@article{jacobe_de_naurois_adapting_2018,
	title = {Adapting artificial neural networks to a specific driver enhances detection and prediction of drowsiness},
	volume = {121},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457518304743},
	doi = {10.1016/j.aap.2018.08.017},
	abstract = {Monitoring car drivers for drowsiness is crucial but challenging. The high inter-individual variability observed in measurements raises questions about the accuracy of the drowsiness detection process. In this study, we sought to enhance the performance of machine learning models (Artiﬁcial Neural Networks: ANNs) by training a model with a group of drivers and then adapting it to a new individual. Twenty-one participants drove a car simulator for 110 min in a monotonous environment. We measured physiological and behavioral indicators and recorded driving behavior. These measurements, in addition to driving time and personal information, served as the ANN inputs. Two ANN-based models were used, one to detect the level of drowsiness every minute, and the other to predict, every minute, how long it would take the driver to reach a speciﬁc drowsiness level (moderately drowsy). The ANNs were trained with 20 participants and subsequently adapted using the earliest part of the data recorded from a 21st participant. Then the adapted ANNs were tested with the remaining data from this 21st participant. The same procedure was run for all 21 participants. Varying amounts of data were used to adapt the ANNs, from 1 to 30 min, Model performance was enhanced for each participant. The overall drowsiness monitoring performance of the models was enhanced by roughly 40\% for prediction and 80\% for detection.},
	language = {en},
	urldate = {2021-02-17},
	journal = {Accident Analysis \& Prevention},
	author = {Jacobé de Naurois, Charlotte and Bourdin, Christophe and Bougard, Clément and Vercher, Jean-Louis},
	month = dec,
	year = {2018},
	keywords = {done, drive},
	pages = {118--128},
	file = {Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:/home/simeon/Zotero/storage/UV64MV9F/Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:application/pdf;Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:/home/simeon/Zotero/storage/WP5YVUDZ/Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:application/pdf;Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:/home/simeon/Zotero/storage/IGKJ7CDY/Jacobé de Naurois et al. - 2018 - Adapting artificial neural networks to a specific .pdf:application/pdf},
}

@article{wang_driver_2016,
	title = {Driver drowsiness detection based on non-intrusive metrics considering individual specifics},
	volume = {95},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457515300609},
	doi = {10.1016/j.aap.2015.09.002},
	abstract = {Objectives: Drowsy driving is a serious highway safety problem. If drivers could be warned before they became too drowsy to drive safely, some drowsiness-related crashes could be prevented. The presentation of timely warnings, however, depends on reliable detection. To date, the effectiveness of drowsiness detection methods has been limited by their failure to consider individual differences. The present study sought to develop a drowsiness detection model that accommodates the varying individual effects of drowsiness on driving performance.
Methods: Nineteen driving behavior variables and four eye feature variables were measured as participants drove a ﬁxed road course in a high ﬁdelity motion-based driving simulator after having worked an 8-h night shift. During the test, participants were asked to report their drowsiness level using the Karolinska Sleepiness Scale at the midpoint of each of the six rounds through the road course. A multilevel ordered logit (MOL) model, an ordered logit model, and an artiﬁcial neural network model were used to determine drowsiness.
Results: The MOL had the highest drowsiness detection accuracy, which shows that consideration of individual differences improves the models’ ability to detect drowsiness. According to the results, percentage of eyelid closure, average pupil diameter, standard deviation of lateral position and steering wheel reversals was the most important of the 23 variables.
Conclusion: The consideration of individual differences on a drowsiness detection model would increase the accuracy of the model’s detection accuracy.},
	language = {en},
	urldate = {2021-02-17},
	journal = {Accident Analysis \& Prevention},
	author = {Wang, Xuesong and Xu, Chuan},
	month = oct,
	year = {2016},
	keywords = {done},
	pages = {350--357},
	file = {Wang and Xu - 2016 - Driver drowsiness detection based on non-intrusive.pdf:/home/simeon/Zotero/storage/KEHQGLZA/Wang and Xu - 2016 - Driver drowsiness detection based on non-intrusive.pdf:application/pdf;Driver drowsiness detection based on non-intrusive metrics considering individual specifics.pdf:/home/simeon/Documents/ING5/Stage/Article/Driver drowsiness detection based on non-intrusive metrics
considering individual specifics.pdf:application/pdf},
}

@incollection{rojas_detecting_2019,
	address = {Cham},
	title = {Detecting {Driver} {Drowsiness} in {Real} {Time} {Through} {Deep} {Learning} {Based} {Object} {Detection}},
	volume = {11506},
	isbn = {978-3-030-20520-1 978-3-030-20521-8},
	url = {http://link.springer.com/10.1007/978-3-030-20521-8_24},
	abstract = {Vehicle accidents due to drowsiness in drivers take thousands of lives each year worldwide. This fact clearly exhibits a need for a drowsiness detection application that can help prevent such accidents and ultimately save lives. In this work, we propose a novel deep learning methodology based on Convolutional Neural Networks (CNN) to tackle this problem. The proposed methodology treats drowsiness detection as an object detection task, and from an incoming video stream of a driver, detects and localizes open and closed eyes. MobileNet CNN architecture with Single Shot Multibox Detector (SSD) is used for this task of object detection. A separate algorithm is then used to detect driver drowsiness based on the output from the MobileNet-SSD architecture. In order to train the MobileNet-SSD Network a custom dataset of about 6000 images was compiled and labeled with the objects face, eye open and eye closed. Out of these, 350 images were randomly separated and used to test the trained model. The trained model was evaluated on the test dataset using the PASCAL VOC metric and achieved a Mean Average Precision (mAP) of 0.84 on these categories. The proposed methodology, while maintaining reasonable accuracy, is also computationally efﬁcient and cost effective, as it can process an incoming video stream in real time on a standalone mobile device without the need of expensive hardware support. It can easily be deployed on cheap embedded devices in vehicles, such as the Raspberry Pi 3 or a mobile smartphone.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Advances in {Computational} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Shakeel, Muhammad Faique and Bajwa, Nabit A. and Anwaar, Ahmad Muhammad and Sohail, Anabia and Khan, Asifullah and {Haroon-ur-Rashid}},
	editor = {Rojas, Ignacio and Joya, Gonzalo and Catala, Andreu},
	year = {2019},
	doi = {10.1007/978-3-030-20521-8_24},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {283--296},
	file = {Detecting Driver Drowsiness in Real Time Through Deep Learning Based Object Detection.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_Usefull/Detecting Driver Drowsiness in Real Time Through Deep Learning Based Object Detection.pdf:application/pdf},
}

@article{hockey_psychology_nodate,
	title = {The {Psychology} of {Fatigue}},
	language = {en},
	author = {Hockey, Robert},
	pages = {290},
	file = {Robert Hockey - The Psychology of Fatigue_ Work, Effort and Control-Cambridge University Press (2013).pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/Robert Hockey - The Psychology of Fatigue_ Work, Effort and Control-Cambridge University Press (2013).pdf:application/pdf},
}

@article{emeritus_fuzzy_nodate,
	title = {Fuzzy {Logic}, {Neural} {Networks}, and {Soft} {Computing}},
	language = {en},
	author = {Emeritus, LOTFI A ZADEH},
	pages = {8},
	file = {9789814261302_0040.pdf:/home/simeon/Zotero/storage/SEV7FCN2/9789814261302_0040.pdf:application/pdf;Emeritus - Fuzzy Logic, Neural Networks, and Soft Computing.pdf:/home/simeon/Zotero/storage/ECKU8HNY/Emeritus - Fuzzy Logic, Neural Networks, and Soft Computing.pdf:application/pdf},
}

@article{noauthor_notitle_nodate-1,
}

@article{ivan_d_brown_driver_nodate,
	title = {Driver {Fatigue}},
	author = {Ivan D. Brown},
	file = {brown1994.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/brown1994.pdf:application/pdf},
}

@inproceedings{gohring_radarlidar_2011,
	address = {Wellington, New Zealand},
	title = {Radar/{Lidar} sensor fusion for car-following on highways},
	isbn = {978-1-4577-0330-0 978-1-4577-0329-4 978-1-4577-0328-7},
	url = {http://ieeexplore.ieee.org/document/6144918/},
	doi = {10.1109/ICARA.2011.6144918},
	abstract = {We present a real-time algorithm which enables an autonomous car to comfortably follow other cars at various speeds while keeping a safe distance. We focus on highway scenarios.},
	language = {en},
	urldate = {2021-02-19},
	booktitle = {The 5th {International} {Conference} on {Automation}, {Robotics} and {Applications}},
	publisher = {IEEE},
	author = {Gohring, Daniel and Wang, Miao and Schnurmacher, Michael and Ganjineh, Tinosch},
	month = dec,
	year = {2011},
	pages = {407--412},
	file = {Gohring et al. - 2011 - RadarLidar sensor fusion for car-following on hig.pdf:/home/simeon/Zotero/storage/62VVGR7A/Gohring et al. - 2011 - RadarLidar sensor fusion for car-following on hig.pdf:application/pdf;gohring2011.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/gohring2011.pdf:application/pdf},
}

@inproceedings{cho_multi-sensor_2014,
	address = {Hong Kong, China},
	title = {A multi-sensor fusion system for moving object detection and tracking in urban driving environments},
	isbn = {978-1-4799-3685-4},
	url = {http://ieeexplore.ieee.org/document/6907100/},
	doi = {10.1109/ICRA.2014.6907100},
	abstract = {A self-driving car, to be deployed in real-world driving environments, must be capable of reliably detecting and effectively tracking of nearby moving objects. This paper presents our new, moving object detection and tracking system that extends and improves our earlier system used for the 2007 DARPA Urban Challenge. We revised our earlier motion and observation models for active sensors (i.e., radars and LIDARs) and introduced a vision sensor. In the new system, the vision module detects pedestrians, bicyclists, and vehicles to generate corresponding vision targets. Our system utilizes this visual recognition information to improve a tracking model selection, data association, and movement classiﬁcation of our earlier system. Through the test using the data log of actual driving, we demonstrate the improvement and performance gain of our new tracking system.},
	language = {en},
	urldate = {2021-02-19},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Cho, Hyunggi and Seo, Young-Woo and Kumar, B.V.K. Vijaya and Rajkumar, Ragunathan Raj},
	month = may,
	year = {2014},
	pages = {1836--1843},
	file = {Cho et al. - 2014 - A multi-sensor fusion system for moving object det.pdf:/home/simeon/Zotero/storage/7JCD58GC/Cho et al. - 2014 - A multi-sensor fusion system for moving object det.pdf:application/pdf;cho2014.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/cho2014.pdf:application/pdf},
}

@article{larue_driving_2011,
	title = {Driving performance impairments due to hypovigilance on monotonous roads},
	volume = {43},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457511001424},
	doi = {10.1016/j.aap.2011.05.023},
	language = {en},
	number = {6},
	urldate = {2021-02-19},
	journal = {Accident Analysis \& Prevention},
	author = {Larue, Grégoire S. and Rakotonirainy, Andry and Pettitt, Anthony N.},
	month = nov,
	year = {2011},
	pages = {2037--2046},
	file = {Larue et al. - 2011 - Driving performance impairments due to hypovigilan.pdf:/home/simeon/Zotero/storage/8PDUJ2UX/Larue et al. - 2011 - Driving performance impairments due to hypovigilan.pdf:application/pdf;j.aap.2011.05.023.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/j.aap.2011.05.023.pdf:application/pdf},
}

@inproceedings{ben_mahria_measuring_2020,
	address = {Budapest, Hungary},
	title = {Measuring {Design} {Complexity} of {Cultural} {Heritage} {Ontologies}:},
	isbn = {978-989-758-474-9},
	shorttitle = {Measuring {Design} {Complexity} of {Cultural} {Heritage} {Ontologies}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010016501330140},
	doi = {10.5220/0010016501330140},
	abstract = {Nowadays, Ontologies have become widely used to design formalism for knowledge representation, and are considered as foundation for Semantic Web. However, with their wide spread usage, a question of their complexity evaluation increased even more, especially in some domains that currently know a cruise number of ontologies like Cultural Heritage. In this paper, we present an analysis of the advanced metrics for measuring the design complexity of existing cultural heritage ontologies (CH). In this context, the main goals of this study are to (i) present advanced metrics such as the size of vocabulary, the tree impurity, coupling, average number of path per concept, and average path length, in order to analyze the advanced complexity features of the CH ontologies and their impact on the reuse and evolution of the CH ontologies; (ii) Help developers to decide whether the ontology is over complex that it needs some simplification or re-building; (iii) Make developers clearly realize the impact of the size and scale of ontology. In order to reach these goals, a set of twenty CH ontologies are gathered from the web to measure and analyze their advanced complexity metrics. By analyzing the size of vocabulary, the average number of paths per concept, and average path length, the evaluation results exhibit that the CH ontologies studied are highly complex. In addition, the CH ontologies cannot be easily maintained due to the findings reached through the analysis of the tree impurity and coupling.},
	language = {en},
	urldate = {2021-02-19},
	booktitle = {Proceedings of the 12th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Ben Mahria, Bilal and Chaker, Ilham and Zahi, Azeddine},
	year = {2020},
	pages = {133--140},
	file = {Ben Mahria et al. - 2020 - Measuring Design Complexity of Cultural Heritage O.pdf:/home/simeon/Zotero/storage/BHVLW58V/Ben Mahria et al. - 2020 - Measuring Design Complexity of Cultural Heritage O.pdf:application/pdf;KEOD_2020_2.pdf:/home/simeon/Documents/ING5/Stage/Article/Article_old/a classer/KEOD_2020_2.pdf:application/pdf},
}

@article{jo_vision-based_2011,
	title = {Vision-based method for detecting driver drowsiness and distraction in driver monitoring system},
	volume = {50},
	issn = {0091-3286},
	url = {http://opticalengineering.spiedigitallibrary.org/article.aspx?doi=10.1117/1.3657506},
	doi = {10.1117/1.3657506},
	language = {en},
	number = {12},
	urldate = {2022-02-09},
	journal = {Optical Engineering},
	author = {Jo, Jaeik},
	month = dec,
	year = {2011},
	pages = {127202},
	file = {Jo - 2011 - Vision-based method for detecting driver drowsines.pdf:/home/simeon/Zotero/storage/XSKF2F7Y/Jo - 2011 - Vision-based method for detecting driver drowsines.pdf:application/pdf},
}

@article{queiroz_consequences_2020,
	title = {The consequences of partial sleep restriction for habitual sleep duration, sleepiness and reaction time in healthy males},
	volume = {6},
	issn = {23527218},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352721820301145},
	doi = {10.1016/j.sleh.2020.04.002},
	abstract = {Objective: To investigate the effect of a reduction of approximately 25\% in total sleep time (TST) on sleep parameters, sleepiness and reaction time (RT) in short, long and intermediate sleepers. Design: Twenty healthy young men with a TST of  6 h (n = 6), between 6 h and 8 h (n = 7) and {\textgreater} 8 h (n = 7), respectively considered as short, intermediate and long sleepers, underwent 5 consecutive nights with an approximately 25\% reduction in TST, produced by delaying their usual bedtimes. All participants were subjected to 6 consecutive nights of polysomnography and assessments of sleep, sleepiness and RT at pre- and post-sleep time. The Linear Mixed Model (LMM) was mainly used to assess the effect of the group, time, and their interaction on the main outcomes.
Results: Long and short sleepers showed the most signiﬁcant changes regarding sleep parameters and sleepiness. However, short sleepers showed more lapses and more sleepiness.
Conclusions: We report novel evidence of the association between cognitive function (assessed via reaction time) and sleep restriction-related risks based on real-life since individual sleep schedules were personally determined. Both long and short sleepers showed the most signiﬁcant alterations of delaying bedtime regarding sleep parameters and sleepiness. However, the short sleepers showed more sleepiness, attention lapses and increased reaction times.},
	language = {en},
	number = {6},
	urldate = {2022-02-09},
	journal = {Sleep Health},
	author = {Queiroz, Sandra and Ruiz, Francieli and Prado, Juliana and Silva, Andressa and Frange, Cristina and Narciso, Fernanda and Cruz, Aline and Tufik, Sergio and de Mello, Marco Túlio},
	month = dec,
	year = {2020},
	pages = {814--821},
	file = {Queiroz et al. - 2020 - The consequences of partial sleep restriction for .pdf:/home/simeon/Zotero/storage/NA8HGJN5/Queiroz et al. - 2020 - The consequences of partial sleep restriction for .pdf:application/pdf},
}

@book{bebis_advances_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Advances in {Visual} {Computing}: 14th {International} {Symposium} on {Visual} {Computing}, {ISVC} 2019, {Lake} {Tahoe}, {NV}, {USA}, {October} 7–9, 2019, {Proceedings}, {Part} {I}},
	volume = {11844},
	isbn = {978-3-030-33719-3 978-3-030-33720-9},
	shorttitle = {Advances in {Visual} {Computing}},
	url = {http://link.springer.com/10.1007/978-3-030-33720-9},
	language = {en},
	urldate = {2022-02-09},
	publisher = {Springer International Publishing},
	editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Ushizima, Daniela and Chai, Sek and Sueda, Shinjiro and Lin, Xin and Lu, Aidong and Thalmann, Daniel and Wang, Chaoli and Xu, Panpan},
	year = {2019},
	doi = {10.1007/978-3-030-33720-9},
	file = {Bebis et al. - 2019 - Advances in Visual Computing 14th International S.pdf:/home/simeon/Zotero/storage/3TJ3TU8T/Bebis et al. - 2019 - Advances in Visual Computing 14th International S.pdf:application/pdf},
}

@incollection{chen_detection_2017,
	address = {Cham},
	title = {Detection of {Driver} {Drowsiness} {Using} {3D} {Deep} {Neural} {Network} and {Semi}-{Supervised} {Gradient} {Boosting} {Machine}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	url = {http://link.springer.com/10.1007/978-3-319-54526-4_10},
	abstract = {Detecting drowsiness of the driver with a reliable and conﬁdent manner is a challenging task since it requires accurate monitoring of facial behavior such as eye-closure, nodding and yawning. It is even harder to deal with it when she wears sunglasses or scarf, appearing in the data set given for this challenge. One of the popular ways to analyze facial behavior has been using standard face models such as active shape model or active appearance model. These models work well for the frontal faces and yet often stumble for the extreme head pose cases. To handle these issues, we propose an approach based on recent machine learning techniques: ﬁrst, 3D convolutional neural network to extract features in spatial-temporal domain; secondly, gradient boosting for drowsiness classiﬁcation; thirdly, semi-supervised learning to enhance overall performance. The highest score from our submissions was 87.46\% accuracy, suggesting that this approach has a potential for real application.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Huynh, Xuan-Phung and Park, Sang-Min and Kim, Yong-Guk},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_10},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {134--145},
	file = {Huynh et al. - 2017 - Detection of Driver Drowsiness Using 3D Deep Neura.pdf:/home/simeon/Zotero/storage/H2B5JTH8/Huynh et al. - 2017 - Detection of Driver Drowsiness Using 3D Deep Neura.pdf:application/pdf},
}

@article{chen_deepphys_2018,
	title = {{DeepPhys}: {Video}-{Based} {Physiological} {Measurement} {Using} {Convolutional} {Attention} {Networks}},
	shorttitle = {{DeepPhys}},
	url = {http://arxiv.org/abs/1805.07888},
	abstract = {Non-contact video-based physiological measurement has many applications in health care and human-computer interaction. Practical applications require measurements to be accurate even in the presence of large head rotations. We propose the ﬁrst end-to-end system for videobased measurement of heart and breathing rate using a deep convolutional network. The system features a new motion representation based on a skin reﬂection model and a new attention mechanism using appearance information to guide motion estimation, both of which enable robust measurement under heterogeneous lighting and major motions. Our approach signiﬁcantly outperforms all current state-of-the-art methods on both RGB and infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological signals to be visualized via the attention mechanism.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:1805.07888 [cs]},
	author = {Chen, Weixuan and McDuff, Daniel},
	month = aug,
	year = {2018},
	note = {arXiv: 1805.07888},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction},
	annote = {Comment: Accepted paper at ECCV 2018. 16 pages, 3 figures, supplementary materials in the ancillary files},
	file = {Chen and McDuff - 2018 - DeepPhys Video-Based Physiological Measurement Us.pdf:/home/simeon/Zotero/storage/A8IN8R8D/Chen and McDuff - 2018 - DeepPhys Video-Based Physiological Measurement Us.pdf:application/pdf},
}

@article{yu_remote_2019,
	title = {Remote {Heart} {Rate} {Measurement} from {Highly} {Compressed} {Facial} {Videos}: an {End}-to-end {Deep} {Learning} {Solution} with {Video} {Enhancement}},
	shorttitle = {Remote {Heart} {Rate} {Measurement} from {Highly} {Compressed} {Facial} {Videos}},
	url = {http://arxiv.org/abs/1907.11921},
	abstract = {Remote photoplethysmography (rPPG), which aims at measuring heart activities without any contact, has great potential in many applications (e.g., remote healthcare). Existing rPPG approaches rely on analyzing very ﬁne details of facial videos, which are prone to be affected by video compression. Here we propose a two-stage, endto-end method using hidden rPPG information enhancement and attention networks, which is the ﬁrst attempt to counter video compression loss and recover rPPG signals from highly compressed videos. The method includes two parts: 1) a Spatio-Temporal Video Enhancement Network (STVEN) for video enhancement, and 2) an rPPG network (rPPGNet) for rPPG signal recovery. The rPPGNet can work on its own for robust rPPG measurement, and the STVEN network can be added and jointly trained to further boost the performance especially on highly compressed videos. Comprehensive experiments are performed on two benchmark datasets to show that, 1) the proposed method not only achieves superior performance on compressed videos with high-quality videos pair, 2) it also generalizes well on novel data with only compressed videos available, which implies the promising potential for realworld applications.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:1907.11921 [cs, eess]},
	author = {Yu, Zitong and Peng, Wei and Li, Xiaobai and Hong, Xiaopeng and Zhao, Guoying},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11921},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: IEEE ICCV2019, accepted},
	file = {Yu et al. - 2019 - Remote Heart Rate Measurement from Highly Compress.pdf:/home/simeon/Zotero/storage/ZL7PXKCQ/Yu et al. - 2019 - Remote Heart Rate Measurement from Highly Compress.pdf:application/pdf},
}

@article{rai_thermal_2017,
	title = {Thermal imaging system and its real time applications: a survey},
	volume = {6},
	abstract = {The IR radiations emitted by Thermal Imaging systems are captured by passive sensors for all the objects having temperature overhead the absolute zero. This method of detection was initially settled for surveillance and night vision device for military purposes, but are now economically more viable, hence there is a wider scope of application than ever. The illumination complications of normal Greyscale and RGB cameras are significantly reduced when this sensor is positioned in vision system. This paper produces real time application of thermal imaging system i.e. application in agriculture, medical diagnosis, detection, tracking and recognition of humans along with their facial expressions. Further, this paper explains the natural surroundings of thermal radiation and the imaging system technology.},
	language = {en},
	number = {2},
	journal = {Journal of Engineering Technology},
	author = {Rai, Mritunjay and Maity, Tanmoy and Yadav, R K},
	year = {2017},
	pages = {15},
	file = {Rai et al. - 2017 - Thermal imaging system and its real time applicati.pdf:/home/simeon/Zotero/storage/4KNWCJM4/Rai et al. - 2017 - Thermal imaging system and its real time applicati.pdf:application/pdf},
}

@article{zhai_scaling_2021,
	title = {Scaling {Vision} {Transformers}},
	url = {http://arxiv.org/abs/2106.04560},
	abstract = {Attention-based neural networks such as the Vision Transformer (ViT) have recently attained state-of-the-art results on many computer vision benchmarks. Scale is a primary ingredient in attaining excellent results, therefore, understanding a model’s scaling properties is a key to designing future generations effectively. While the laws for scaling Transformer language models have been studied, it is unknown how Vision Transformers scale. To address this, we scale ViT models and data, both up and down, and characterize the relationships between error rate, data, and compute. Along the way, we reﬁne the architecture and training of ViT, reducing memory consumption and increasing accuracy of the resulting models. As a result, we successfully train a ViT model with two billion parameters, which attains a new state-of-the-art on ImageNet of 90.45\% top-1 accuracy. The model also performs well on few-shot learning, for example, reaching 84.86\% top-1 accuracy on ImageNet with only 10 examples per class.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:2106.04560 [cs]},
	author = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.04560},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Xiaohua, Alex, and Lucas contributed equally},
	file = {Zhai et al. - 2021 - Scaling Vision Transformers.pdf:/home/simeon/Zotero/storage/GSSJDVNJ/Zhai et al. - 2021 - Scaling Vision Transformers.pdf:application/pdf},
}

@article{yuan_florence_2021,
	title = {Florence: {A} {New} {Foundation} {Model} for {Computer} {Vision}},
	shorttitle = {Florence},
	url = {http://arxiv.org/abs/2111.11432},
	abstract = {Automated visual understanding of our diverse and open world demands computer vision models to generalize well with minimal customization for speciﬁc tasks, similar to human vision. Computer vision foundation models, which are trained on diverse, large-scale dataset and can be adapted to a wide range of downstream tasks, are critical for this mission to solve real-world computer vision applications. While existing vision foundation models such as CLIP (Radford et al., 2021), ALIGN (Jia et al., 2021), and Wu Dao 2.0 (Wud) focus mainly on mapping images and textual representations to a cross-modal shared representation, we introduce a new computer vision foundation model, Florence, to expand the representations from coarse (scene) to ﬁne (object), from static (images) to dynamic (videos), and from RGB to multiple modalities (caption, depth). By incorporating universal visual-language representations from Web-scale image-text data, our Florence model can be easily adapted for various computer vision tasks, such as classiﬁcation, retrieval, object detection, VQA, image caption, video retrieval and action recognition. Moreover, Florence demonstrates outstanding performance in many types of transfer learning: fully sampled ﬁne-tuning, linear probing, few-shot transfer and zero-shot transfer for novel images and objects. All of these properties are critical for our vision foundation model to serve general purpose vision tasks. Florence achieves new state-of-the-art results in majority of 44 representative benchmarks, e.g. ImageNet-1K zero-shot classiﬁcation with top-1 accuracy of 83.74 and the top-5 accuracy of 97.18, 62.4 mAP on COCO ﬁne tuning, 80.36 on VQA, and 87.8 on Kinetics-600.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:2111.11432 [cs]},
	author = {Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and Liu, Ce and Liu, Mengchen and Liu, Zicheng and Lu, Yumao and Shi, Yu and Wang, Lijuan and Wang, Jianfeng and Xiao, Bin and Xiao, Zhen and Yang, Jianwei and Zeng, Michael and Zhou, Luowei and Zhang, Pengchuan},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.11432},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Yuan et al. - 2021 - Florence A New Foundation Model for Computer Visi.pdf:/home/simeon/Zotero/storage/VXTLNG58/Yuan et al. - 2021 - Florence A New Foundation Model for Computer Visi.pdf:application/pdf},
}

@article{he_real-time_2020,
	title = {A {Real}-time {Driver} {Fatigue} {Detection} {Method} {Based} on {Two}-{Stage} {Convolutional} {Neural} {Network}},
	volume = {53},
	issn = {24058963},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896320330263},
	doi = {10.1016/j.ifacol.2020.12.2357},
	abstract = {Fatigue-related traffic accidents have a higher mortality rate and cause more significant damage to the environment. To ensure driving safety, a real-time driver fatigue detection method based on convolutional neural network (CNN) is proposed in this paper. The proposed fatigue driving detection method is cascaded by two CNN-based stages, including a detecting phase and classifying phase. The Location Detection Network is designed to extract facial features and localize the driver’s eyes and mouth regions. Then the State Recognition Network is training to recognize the driver’s eyes and mouth status. Simulations show that the proposed method has good effect of real time process and high accuracy of detection. Experiments conducted on Raspberry Pi 4 embedded system indicate that the proposed method has a good performance in the real driving environment.},
	language = {en},
	number = {2},
	urldate = {2022-02-09},
	journal = {IFAC-PapersOnLine},
	author = {He, Hu and Zhang, Xiaoyong and Jiang, Fu and Wang, Chenglong and Yang, Yingze and Liu, Weirong and Peng, Jun},
	year = {2020},
	pages = {15374--15379},
	file = {He et al. - 2020 - A Real-time Driver Fatigue Detection Method Based .pdf:/home/simeon/Zotero/storage/TRPBR26I/He et al. - 2020 - A Real-time Driver Fatigue Detection Method Based .pdf:application/pdf},
}

@article{brandt_affordable_nodate,
	title = {Affordable {Visual} ]{DriverMonitoring} {System} for {Fatigue} and {Monotony}},
	abstract = {In this contribution we present a visual driver surveillance system to monitor the driver’s head morion as well as the eye blink patterns. Based on these measun?dfeatures the system is able to detect symptoms of farigire and monotony. The main advantages of the presented system in coiitrast to existing ones is the usage of standard equipment to achieve a good cost-performance ratio, fast compiitarion time, the possibility of measurements in darkness and the consideration of monotony. rite image analysis is realized in a coarse-to-finearchitecture. Atfrsr the driver’sface is detected which is based on a boosted cascade of Haar wavelets. Then the eyes are searched in the face and occurring eye blinks measured by analyzing the opticalflow of the q e s ’ region. The perforrnance of the sysreni was rested successfully under ideal and natural conditions.},
	language = {en},
	author = {Brandt, Thomas and Stemmer, Ralf and Rakotonirainy, Andry},
	pages = {6},
	file = {Brandt et al. - Affordable Visual ]DriverMonitoring System for Fat.pdf:/home/simeon/Zotero/storage/D6LT5NGK/Brandt et al. - Affordable Visual ]DriverMonitoring System for Fat.pdf:application/pdf},
}

@article{li_driver_2021,
	title = {Driver fatigue detection based on convolutional neural network and face alignment for edge computing device},
	volume = {235},
	issn = {0954-4070, 2041-2991},
	url = {http://journals.sagepub.com/doi/10.1177/0954407021999485},
	doi = {10.1177/0954407021999485},
	abstract = {Most current vision-based fatigue detection methods don’t have high-performance and robust face detector. They detect driver fatigue using single detection feature and cannot achieve real-time efficiency on edge computing devices. Aimed at solving these problems, this paper proposes a driver fatigue detection system based on convolutional neural network that can run in real-time on edge computing devices. The system firstly uses the proposed face detection network LittleFace to locate the face and classify the face into two states: small yaw angle state ‘‘normal’’ and large yaw angle state ‘‘distract.’’ Secondly, the speed-optimized SDM algorithm is conducted only in the face region of the ‘‘normal’’ state to deal with the problem that the face alignment accuracy decreases at large angle profile, and the ‘‘distract’’ state is used to detect driver distraction. Finally, feature parameters EAR, MAR and head pitch angle are calculated from the obtained landmarks and used to detect driver fatigue respectively. Comprehensive experiments are conducted to evaluate the proposed system and the results show its practicality and superiority. Our face detection network LittleFace can achieve 88.53\% mAP on AFLW test set at 58 FPS on the edge computing device Nvidia Jetson Nano. Evaluation results on YawDD, 300 W, and DriverEyes show the average detection accuracy of the proposed system can reach 89.55\%.},
	language = {en},
	number = {10-11},
	urldate = {2022-02-09},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering},
	author = {Li, Xiaofeng and Xia, Jiahao and Cao, Libo and Zhang, Guanjun and Feng, Xiexing},
	month = sep,
	year = {2021},
	pages = {2699--2711},
	file = {Li et al. - 2021 - Driver fatigue detection based on convolutional ne.pdf:/home/simeon/Zotero/storage/P3N8CDU6/Li et al. - 2021 - Driver fatigue detection based on convolutional ne.pdf:application/pdf},
}

@inproceedings{abtahi_driver_2011,
	address = {Hangzhou, China},
	title = {Driver drowsiness monitoring based on yawning detection},
	isbn = {978-1-4244-7933-7},
	url = {http://ieeexplore.ieee.org/document/5944101/},
	doi = {10.1109/IMTC.2011.5944101},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2011 {IEEE} {International} {Instrumentation} and {Measurement} {Technology} {Conference}},
	publisher = {IEEE},
	author = {Abtahi, Shabnam and Hariri, Behnoosh and Shirmohammadi, Shervin},
	month = may,
	year = {2011},
	pages = {1--4},
	file = {Abtahi et al. - 2011 - Driver drowsiness monitoring based on yawning dete.pdf:/home/simeon/Zotero/storage/VGFM6SAD/Abtahi et al. - 2011 - Driver drowsiness monitoring based on yawning dete.pdf:application/pdf},
}

@article{guede-fernandez_driver_2019,
	title = {Driver {Drowsiness} {Detection} {Based} on {Respiratory} {Signal} {Analysis}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8744224/},
	doi = {10.1109/ACCESS.2019.2924481},
	abstract = {Drowsy driving is a prevalent and serious public health issue that deserves attention. Recent studies estimate around 20\% of car crashes have been caused by drowsy drivers. Nowadays, one of the main goals in the development of new advanced driver assistance systems is the trustworthy drowsiness detection. In this paper, a drowsiness detection method based on changes in the respiratory signal is proposed. The respiratory signal, which has been obtained using an inductive plethysmography belt, has been processed in real-time in order to classify the driver’s state of alertness as drowsy or awake. The proposed algorithm is based on the analysis of the respiratory rate variability (RRV) in order to detect the ﬁght against to fall asleep. Moreover, a method to provide a quality level of the respiratory signal is also proposed. Both methods have been combined to reduce false alarms due to changes of measured RRV associated not to drowsiness but body movements. A driving simulator cabin has been used to perform the validation tests and external observers have rated the drivers’ state of alertness in order to evaluate the algorithm performance. It has been achieved a speciﬁcity of 96.6\%, sensitivity of 90.3\% and Cohen’s Kappa agreement score of 0.75 on average across all subjects through a leave-one-subject-out cross-validation. A novel algorithm for driver’s state of alertness monitoring through the identiﬁcation of the ﬁght against to fall asleep has been validated. The proposed algorithm may be a valuable vehicle safety system to alert drowsiness while driving.},
	language = {en},
	urldate = {2022-02-09},
	journal = {IEEE Access},
	author = {Guede-Fernandez, Federico and Fernandez-Chimeno, Mireya and Ramos-Castro, Juan and Garcia-Gonzalez, Miguel A.},
	year = {2019},
	pages = {81826--81838},
	file = {Guede-Fernandez et al. - 2019 - Driver Drowsiness Detection Based on Respiratory S.pdf:/home/simeon/Zotero/storage/ZFTBJ3F4/Guede-Fernandez et al. - 2019 - Driver Drowsiness Detection Based on Respiratory S.pdf:application/pdf},
}

@inproceedings{nakamura_detection_2013,
	address = {Naha, Japan},
	title = {Detection of {Driver}'s {Drowsy} {Facial} {Expression}},
	isbn = {978-1-4799-2190-4},
	url = {http://ieeexplore.ieee.org/document/6778424/},
	doi = {10.1109/ACPR.2013.176},
	abstract = {We propose a method for the estimation of the degree of a driver’s drowsiness on basis of changes in facial expressions captured by an IR camera. Typically, drowsiness is accompanied by falling of eyelids. Therefore, most of the related studies have focused on tracking eyelid movement by monitoring facial feature points. However, textural changes that arise from frowning are also very important and sensitive features in the initial stage of drowsiness, and it is difficult to detect such changes solely using facial feature points. In this paper, we propose a more precise drowsiness-degree estimation method considering wrinkles change by calculating local edge intensity on faces that expresses drowsiness more directly in the initial stage.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2013 2nd {IAPR} {Asian} {Conference} on {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Nakamura, Taro and Maejima, Akinobu and Morishima, Shigeo},
	month = nov,
	year = {2013},
	pages = {749--753},
	file = {Nakamura et al. - 2013 - Detection of Driver's Drowsy Facial Expression.pdf:/home/simeon/Zotero/storage/D6UGCDPS/Nakamura et al. - 2013 - Detection of Driver's Drowsy Facial Expression.pdf:application/pdf},
}

@article{lee_video-based_2019,
	title = {Video-{Based} {Contactless} {Heart}-{Rate} {Detection} and {Counting} via {Joint} {Blind} {Source} {Separation} with {Adaptive} {Noise} {Canceller}},
	volume = {9},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/20/4349},
	doi = {10.3390/app9204349},
	abstract = {Driver assistance systems are a major focus of the automotive industry. Although technological functions that help drivers are improving, the monitoring of driver state functions receives less attention. In this respect, the human heart rate (HR) is one of the most important bio-signals, and it can be detected remotely using consumer-grade cameras. Based on this, a video-based driver state monitoring system using HR signals is proposed in this paper. In a practical automotive environment, monitoring the HR is very challenging due to changes in illumination, vibrations, and human motion. In order to overcome these problems, source separation strategies were employed using joint blind source separation, and feature combination was adopted to maximize HR variation. Noise-assisted data analysis was then adopted using ensemble empirical mode decomposition to extract the pure HR. Finally, power spectral density analysis was conducted in the frequency domain, and a post-processing smoothing filter was applied. The performance of the proposed approach was tested based on commonly employed metrics using the MAHNOB-HCI public dataset and compared with recently proposed competing methods. The experimental results proved that our method is robust for a variety of driving conditions based on testing using a driving dataset and static indoor environments.},
	language = {en},
	number = {20},
	urldate = {2022-02-09},
	journal = {Applied Sciences},
	author = {Lee, Kanghyu and Lee, Junmuk and Ha, Changwoo and Han, Minseok and Ko, Hanseok},
	month = oct,
	year = {2019},
	pages = {4349},
	file = {Lee et al. - 2019 - Video-Based Contactless Heart-Rate Detection and C.pdf:/home/simeon/Zotero/storage/CBQP7CXE/Lee et al. - 2019 - Video-Based Contactless Heart-Rate Detection and C.pdf:application/pdf},
}

@article{bakheet_framework_2021,
	title = {A {Framework} for {Instantaneous} {Driver} {Drowsiness} {Detection} {Based} on {Improved} {HOG} {Features} and {Naïve} {Bayesian} {Classification}},
	volume = {11},
	issn = {2076-3425},
	url = {https://www.mdpi.com/2076-3425/11/2/240},
	doi = {10.3390/brainsci11020240},
	abstract = {Due to their high distinctiveness, robustness to illumination and simple computation, Histogram of Oriented Gradient (HOG) features have attracted much attention and achieved remarkable success in many computer vision tasks. In this paper, an innovative framework for driver drowsiness detection is proposed, where an adaptive descriptor that possesses the virtue of distinctiveness, robustness and compactness is formed from an improved version of HOG features based on binarized histograms of shifted orientations. The ﬁnal HOG descriptor generated from binarized HOG features is fed to the trained Naïve Bayes (NB) classiﬁer to make the ﬁnal driver drowsiness determination. Experimental results on the publicly available NTHU-DDD dataset verify that the proposed framework has the potential to be a strong contender for several state-of-the-art baselines, by achieving a competitive detection accuracy of 85.62\%, without loss of efﬁciency or stability.},
	language = {en},
	number = {2},
	urldate = {2022-02-09},
	journal = {Brain Sciences},
	author = {Bakheet, Samy and Al-Hamadi, Ayoub},
	month = feb,
	year = {2021},
	pages = {240},
	file = {Bakheet and Al-Hamadi - 2021 - A Framework for Instantaneous Driver Drowsiness De.pdf:/home/simeon/Zotero/storage/EZWNHJKW/Bakheet and Al-Hamadi - 2021 - A Framework for Instantaneous Driver Drowsiness De.pdf:application/pdf},
}

@inproceedings{azmi_lbp-based_2011,
	address = {Ottawa, ON, Canada},
	title = {{LBP}-based driver fatigue monitoring system with the adoption of haptic warning scheme},
	isbn = {978-1-61284-888-4},
	url = {http://ieeexplore.ieee.org/document/6053852/},
	doi = {10.1109/VECIMS.2011.6053852},
	abstract = {Sleepiness and fatigued driving are amongst the major causes of roadway accidents. Eye closure and blink frequency are two of the principle evidences of driver fatigue. In this research, we surveilled operator’s eye closure over a period of time with the purpose of alerting her/him in a nonobtrusive manner. We propose a real time and automatic method to analyze vehicle operator’s drowsiness by using a CCD camera. Our developed system delivered an accuracy rate of 96\% in eye states recognition that we leveraged to deduce multi-level driver drowsiness states. We considered an online progressive haptic alerting scheme (similar to silent mobile vibration alert) to warn the drowsy operator in order to prevent major road accidents.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2011 {IEEE} {International} {Conference} on {Virtual} {Environments}, {Human}-{Computer} {Interfaces} and {Measurement} {Systems} {Proceedings}},
	publisher = {IEEE},
	author = {Azmi, Niloufar and Rahman, A S M Mahfujur and Shirmohammadi, Shervin and Saddik, Abdulmotaleb El},
	month = sep,
	year = {2011},
	pages = {1--4},
	file = {Azmi et al. - 2011 - LBP-based driver fatigue monitoring system with th.pdf:/home/simeon/Zotero/storage/AU354N6I/Azmi et al. - 2011 - LBP-based driver fatigue monitoring system with th.pdf:application/pdf},
}

@article{sunagawa_comprehensive_2020,
	title = {Comprehensive {Drowsiness} {Level} {Detection} {Model} {Combining} {Multimodal} {Information}},
	volume = {20},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {https://ieeexplore.ieee.org/document/8933427/},
	doi = {10.1109/JSEN.2019.2960158},
	abstract = {This paper presents a drowsiness detection model that is capable of sensing the entire range of stages of drowsiness, from weak to strong. The key assumption underlying our approach is that the sitting posture-related index can indicate weak drowsiness that drivers themselves do not notice. We ﬁrst determined the sensitivity of the posture index and conventional indices for the stages of drowsiness. Then, we designed a drowsiness detection model combining several indices sensitive to weak drowsiness and to strong drowsiness, to cover all drowsiness stages. Subsequently, the model was trained and evaluated on a dataset comprised of data collected from approximately 50 drivers in simulated driving experiments. The results indicated that posture information improved the accuracy of weak drowsiness detection, and our proposed model using the driver’s blink and posture information covered all stages of drowsiness (F1-score 53.6\%, root mean square error 0.620). Future applications of this model include not only warning systems for dangerously drowsy drivers but also systems which can take action before their drivers become drowsy. Since measuring the information requires no restrictive equipment such as on-body electrodes, the model presented here based on blink and posture information can be used in several practical applications.},
	language = {en},
	number = {7},
	urldate = {2022-02-09},
	journal = {IEEE Sensors Journal},
	author = {Sunagawa, Mika and Shikii, Shin-ichi and Nakai, Wataru and Mochizuki, Makoto and Kusukame, Koichi and Kitajima, Hiroki},
	month = apr,
	year = {2020},
	pages = {3709--3717},
	file = {Sunagawa et al. - 2020 - Comprehensive Drowsiness Level Detection Model Com.pdf:/home/simeon/Zotero/storage/8BQ4DIV6/Sunagawa et al. - 2020 - Comprehensive Drowsiness Level Detection Model Com.pdf:application/pdf},
}

@inproceedings{rana_remote_2018,
	address = {London, UK},
	title = {Remote {Vital} {Sign} {Recognition} through {Machine} {Learning} augmented {UWB}},
	isbn = {978-1-78561-816-1},
	url = {https://digital-library.theiet.org/content/conferences/10.1049/cp.2018.0978},
	doi = {10.1049/cp.2018.0978},
	abstract = {This paper describes an experimental demonstration of machine learning (ML) techniques supplementing radar to distinguish and detect vital signs of users in a domestic environment. This work augments an intelligent location awareness system previously proposed by the authors. That research employed Ultra-Wide Band (UWB) radar complemented by supervised machine learning techniques to remotely identify a persons room location via ﬂoor plan training and time stamp correlations. Here, the remote breathing and heartbeat signals are analyzed through Short Term Fourier Transformation (STFT) to determine the Micro-Doppler signature of those vital signs in different room locations. Then, Multi-Class Support Vector Machine (MC-SVM) is implemented to train the system to intelligently distinguish between vital signs during different activities. Statistical analysis of the experimental results supports the proposed algorithm. This work could be used to further understand, for example, how active older people are by engaging in typical domestic activities.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {12th {European} {Conference} on {Antennas} and {Propagation} ({EuCAP} 2018)},
	publisher = {Institution of Engineering and Technology},
	author = {Rana, S.P. and Dey, M. and Brown, R. and Siddiqui, H.U. and Dudley, S.},
	year = {2018},
	pages = {619 (5 pp.)--619 (5 pp.)},
	file = {Rana et al. - 2018 - Remote Vital Sign Recognition through Machine Lear.pdf:/home/simeon/Zotero/storage/XC3PBL5N/Rana et al. - 2018 - Remote Vital Sign Recognition through Machine Lear.pdf:application/pdf},
}

@article{lenskiy_drivers_2012,
	title = {Driver’s eye blinking detection using novel color and texture segmentation algorithms},
	volume = {10},
	issn = {1598-6446, 2005-4092},
	url = {http://link.springer.com/10.1007/s12555-012-0212-0},
	doi = {10.1007/s12555-012-0212-0},
	abstract = {In this paper we propose a system that measures eye blinking rate and eye closure duration. The system consists of skin-color segmentation, facial features segmentation, iris positioning and blink detection. The proposed skin-segmentation procedure is based on a neural network approximation of a RGB skin-color histogram. This method is robust and adaptive to any skin-color training set. The largest remaining skin-color region among skin-color segmentation results is further segmented into open/closed eyes, lips, nose, eyebrows, and the remaining facial regions using a novel texture segmentation algorithm. The segmentation algorithm classifies pixels according to the highest probability among the estimated facial feature class probability density functions (PDFs). The segmented eye regions are analyzed with the Circular Hough transform with the purpose of finding iris candidates. The finial iris position is selected according to the location of the maximum correlation value obtained from correlation with a predefined mask. The positions of irises and eye states are monitored through time to estimate eye blinking frequency and eye closure duration. The method of the driver drowsiness detection using these parameters is illustrated. The proposed system is tested on CCD and CMOS cameras under different environmental conditions and the experimental results show high system performance.},
	language = {en},
	number = {2},
	urldate = {2022-02-09},
	journal = {International Journal of Control, Automation and Systems},
	author = {Lenskiy, Artem A. and Lee, Jong-Soo},
	month = apr,
	year = {2012},
	pages = {317--327},
	file = {Lenskiy and Lee - 2012 - Driver’s eye blinking detection using novel color .pdf:/home/simeon/Zotero/storage/L8C4JE8P/Lenskiy and Lee - 2012 - Driver’s eye blinking detection using novel color .pdf:application/pdf},
}

@inproceedings{ghourabi_driver_2020,
	address = {Cluj-Napoca, Romania},
	title = {Driver {Drowsiness} {Detection} {Based} on {Joint} {Monitoring} of {Yawning}, {Blinking} and {Nodding}},
	isbn = {978-1-72819-080-8},
	url = {https://ieeexplore.ieee.org/document/9266160/},
	doi = {10.1109/ICCP51029.2020.9266160},
	abstract = {Deaths and injuries resulting from road trafﬁc crashes remain a serious problem globally and current trends suggest that this will continue to be the case in the foreseeable future. In this paper, we propose a reliable method towards drowsiness detection by analyzing images of the driver’s face. In fact, the shadows caused by wearing glasses and/or bad light conditions may, in particular, decrease the accuracy rate of the blinking detection. In addition, drowsiness symptoms are not just restricted to the frequency of blinking, as most of existing works do, but also include yawning and nodding. Thus, instead of using a single facial feature to predict the drowsiness state, we jointly combine eye closure and yawning by measuring the eye and the mouth aspect ratios, and head pose which is estimated by analyzing the optical ﬂow. Then, we investigate the multilayer perceptron and the K-nearest neighbors as two classiﬁcation techniques. The proposed method has been tested on the challenging private NTHU-DDD benchmark video dataset, and the preliminary experimental results show the effectiveness of the proposed automated method.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2020 {IEEE} 16th {International} {Conference} on {Intelligent} {Computer} {Communication} and {Processing} ({ICCP})},
	publisher = {IEEE},
	author = {Ghourabi, Aicha and Ghazouani, Haythem and Barhoumi, Walid},
	month = sep,
	year = {2020},
	pages = {407--414},
	file = {Ghourabi et al. - 2020 - Driver Drowsiness Detection Based on Joint Monitor.pdf:/home/simeon/Zotero/storage/7FNBXL45/Ghourabi et al. - 2020 - Driver Drowsiness Detection Based on Joint Monitor.pdf:application/pdf},
}

@inproceedings{haisong_gu_automated_2004,
	address = {Seoul, Korea},
	title = {An automated face reader for fatigue detection},
	isbn = {978-0-7695-2122-0},
	url = {http://ieeexplore.ieee.org/document/1301517/},
	doi = {10.1109/AFGR.2004.1301517},
	abstract = {An automated system for facial expression recognition is always desirable. However, it is a challenging issue due to the richness and ambiguities with daily facial expressions. This paper presents an efﬁcient approach to recognition of facial expressions of interest. By integrating Dynamic Bayesian Network (DBN) with the general facial expression language (FACS), a task-oriented stochastic and temporal framework is constructed to systematically represent and recognize facial expressions. Based on the DBN, analysis results from previous periods and prior knowledge of the application domain can be integrated both spatially and temporally. With the top-down inference, the system can make dynamic and active selection among multiple sensing channels so as to achieve efﬁcient recognition. With the bottom-up inference from observed evidences, the current facial expression can be classiﬁed with a desired conﬁdent level via belief propagation. We apply this task-oriented framework to fatigue facial expression analysis. Experimental results verify the high efﬁciency of our approach.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {Sixth {IEEE} {International} {Conference} on {Automatic} {Face} and {Gesture} {Recognition}, 2004. {Proceedings}.},
	publisher = {IEEE},
	author = {{Haisong Gu} and {Qiang Ji}},
	year = {2004},
	pages = {111--116},
	file = {Haisong Gu and Qiang Ji - 2004 - An automated face reader for fatigue detection.pdf:/home/simeon/Zotero/storage/K3AI7TMP/Haisong Gu and Qiang Ji - 2004 - An automated face reader for fatigue detection.pdf:application/pdf},
}

@article{hari_driver_2021,
	title = {Driver distraction analysis using face pose cues},
	volume = {179},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421004772},
	doi = {10.1016/j.eswa.2021.115036},
	abstract = {Vehicle driver distraction is one of the major reasons for road accidents. Involvement with a co-passenger, use of in-vehicle devices or phone leads to a situation where the driver head pose varies and the eye is off the road. A low cost early warning system should reduce the distracted driving instances, thus making our roads safer. Face pose information forms an important cue to determine driver distraction. The main objective of this work is to analyse the distractions of the driver based on his/her face pose cues. A straight pose or slight variation would indicate a non-distracted driver, while a large pose variation from the center would indicate a high probability for a distracted driver. Face pose database of vehicle drivers is developed and is bench-marked. A clustered two layer approach on Gabor features is proposed. A five layer convolutional network with three fully connected layers is also used to bench-mark the data. The proposed clustered two-layer approach with Gabor features and SVM classifier provides better results in driver distraction analysis when compared to the deep learning approach and other manifold approaches. The improved accuracy could be attributed to the improved modeling of manifold in our approach, better class discrimination of the Gabor features together with better classification provided by the SVM classifier.},
	language = {en},
	urldate = {2022-02-09},
	journal = {Expert Systems with Applications},
	author = {Hari, C.V. and Sankaran, Praveen},
	month = oct,
	year = {2021},
	pages = {115036},
	file = {Hari and Sankaran - 2021 - Driver distraction analysis using face pose cues.pdf:/home/simeon/Zotero/storage/HEQE4JXD/Hari and Sankaran - 2021 - Driver distraction analysis using face pose cues.pdf:application/pdf},
}

@inproceedings{tayibnapis_novel_2016,
	address = {Bandung, Indonesia},
	title = {A novel driver fatigue monitoring using optical imaging of face on safe driving system},
	isbn = {978-1-5090-0744-8},
	url = {http://ieeexplore.ieee.org/document/7814994/},
	doi = {10.1109/ICCEREC.2016.7814994},
	abstract = {One of the global main goal of the safety driving system is protecting the driver, passenger(s), car, and surrounding environment against accident which are caused by external and internal factors. Driver fatigue, one of the major internal factors, is a leading reason of vehicle breakdown according to a survey done by National Highway Traffic Safety Administration (NHTSA). Thus, it is necessary to build driver fatigue monitoring system. We, then, propose a technique based on optical imaging through digital camera that installed on the car dashboard. The camera detects and tracks the driver face. From the driver face, we can apply non-contact photoplesthymography (PPG) in order to get multiple physiological signals such as brainwave, cardiac and respiration pulses. Those physiological signals can be utilized to measure fatigue level. Alteration in facial features like eyes, mouth, and head, can be used to observe the driver fatigue as well. We propose to use supervised descent method (SDM) with scaleinvariant feature transform (SIFT) to excerpt information from the facial features. To classify the fatigue level from those multiple parameters, support vector machine (SVM) will be implemented.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2016 {International} {Conference} on {Control}, {Electronics}, {Renewable} {Energy} and {Communications} ({ICCEREC})},
	publisher = {IEEE},
	author = {Tayibnapis, Iman Rahmansyah and Koo, Dong-Young and Choi, Min-Kook and Kwon, Soon},
	month = sep,
	year = {2016},
	pages = {115--120},
	file = {Tayibnapis et al. - 2016 - A novel driver fatigue monitoring using optical im.pdf:/home/simeon/Zotero/storage/99K82GBC/Tayibnapis et al. - 2016 - A novel driver fatigue monitoring using optical im.pdf:application/pdf},
}

@inproceedings{wang_fatigue_2017,
	address = {Guangzhou},
	title = {Fatigue detection of vehicular driver through skin conductance, pulse oximetry and respiration: {A} random forest classifier},
	isbn = {978-1-5090-3822-0},
	shorttitle = {Fatigue detection of vehicular driver through skin conductance, pulse oximetry and respiration},
	url = {http://ieeexplore.ieee.org/document/8230293/},
	doi = {10.1109/ICCSN.2017.8230293},
	abstract = {Since the 1990s, fatigue driving has been one of the two main causes of traffic accidents. In order to reduce traffic accidents, many models are applied in the detection of the driver’s fatigue. This paper introduces a new model for detecting fatigue driving. This model employs the HilbertHuang transforms and the Random Forest Classifier algorithm for the analysis of the three factors, namely, skin conductance, oximetry pulse and respiration signals, and uses these parameters Accurate Rate, MSE, ROC, F1\_score, Precision, and Recall for the evaluation of the model. It turns out that the new model improves the prediction accuracy of fatigue driving in comparison with MLP and SVC.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2017 {IEEE} 9th {International} {Conference} on {Communication} {Software} and {Networks} ({ICCSN})},
	publisher = {IEEE},
	author = {Wang, Dong and Shen, Peng and Wang, Ting and Xiao, Zhu},
	month = may,
	year = {2017},
	pages = {1162--1166},
	file = {Wang et al. - 2017 - Fatigue detection of vehicular driver through skin.pdf:/home/simeon/Zotero/storage/FCNZ7VGN/Wang et al. - 2017 - Fatigue detection of vehicular driver through skin.pdf:application/pdf},
}

@article{naous_stochasticity_2016,
	title = {Stochasticity {Modeling} in {Memristors}},
	volume = {15},
	issn = {1536-125X, 1941-0085},
	url = {http://ieeexplore.ieee.org/document/7305797/},
	doi = {10.1109/TNANO.2015.2493960},
	abstract = {Diverse models have been proposed over the past years to explain the exhibiting behavior of memristors, the fourth fundamental circuit element. The models varied in complexity ranging from a description of physical mechanisms to a more generalized mathematical modeling. Nonetheless, stochasticity, a widespread observed phenomenon, has been immensely overlooked from the modeling perspective. This inherent variability within the operation of the memristor is a vital feature for the integration of this nonlinear device into the stochastic electronics realm of study. In this paper, experimentally observed innate stochasticity is modeled in a circuit compatible format. The model proposed is generic and could be incorporated into variants of threshold-based memristor models in which apparent variations in the output hysteresis convey the switching threshold shift. Further application as a noise injection alternative paves the way for novel approaches in the ﬁelds of neuromorphic engineering circuits design. On the other hand, extra caution needs to be paid to variability intolerant digital designs based on nondeterministic memristor logic.},
	language = {en},
	number = {1},
	urldate = {2022-02-09},
	journal = {IEEE Transactions on Nanotechnology},
	author = {Naous, Rawan and Al-Shedivat, Maruan and Salama, Khaled Nabil},
	month = jan,
	year = {2016},
	pages = {15--28},
	file = {Naous et al. - 2016 - Stochasticity Modeling in Memristors.pdf:/home/simeon/Zotero/storage/9S4B7PA2/Naous et al. - 2016 - Stochasticity Modeling in Memristors.pdf:application/pdf},
}

@inproceedings{bhowmick_detection_2009,
	address = {Kuala Lumpur, Malaysia},
	title = {Detection and classification of eye state in {IR} camera for driver drowsiness identification},
	isbn = {978-1-4244-5560-7},
	url = {http://ieeexplore.ieee.org/document/5478674/},
	doi = {10.1109/ICSIPA.2009.5478674},
	abstract = {An eye detection and eye state (open/close) classiﬁcation methodology for driver drowsiness identiﬁcation using IR camera has been presented in this paper. In this proposed methodology, otsu thresholding is used to extract face region. Eye localization is done by locating facial landmarks such as eyebrow and possible face center. Morphological operation and K-means is used for accurate eye segmentation. A hierarchial noise removal procedure is applied on the segmented image to get proper eye shape. Then a set of shape features are calculated and trained using nonlinear SVM to get the status of the eye. Experiment shows that the proposed methodology gives excellent segmentation results for both open eyes(both bright and dark pupil) and closed eyes and also classiﬁes correctly.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2009 {IEEE} {International} {Conference} on {Signal} and {Image} {Processing} {Applications}},
	publisher = {IEEE},
	author = {Bhowmick, Brojeshwar and Chidanand Kumar, K S},
	year = {2009},
	pages = {340--345},
	file = {Bhowmick and Chidanand Kumar - 2009 - Detection and classification of eye state in IR ca.pdf:/home/simeon/Zotero/storage/Y5LJK6ZM/Bhowmick and Chidanand Kumar - 2009 - Detection and classification of eye state in IR ca.pdf:application/pdf},
}

@inproceedings{leicht_physiobelt_2017,
	address = {Vienna, Austria},
	title = {The {PhysioBelt}: {A} safety belt integrated sensor system for heart activity and respiration},
	isbn = {978-1-5090-5677-4},
	shorttitle = {The {PhysioBelt}},
	url = {http://ieeexplore.ieee.org/document/7991924/},
	doi = {10.1109/ICVES.2017.7991924},
	abstract = {In this work, a sensor system for physiological driver state monitoring is presented which is integrated onto a safety belt. The system incorporates two different sensor concepts: An optical system intended for heart activity monitoring and a magnetic induction (MI) system for respiration monitoring. The optical sensor system emits infrared (IR) light from LEDs towards the body of the driver. A part of the light passes through the clothing of the driver, is reﬂected in the body and detected by a photosensor in the optical sensor system. Light reﬂection varies during heart beat intervals and can hence be used for heart beat detection. The MI system is composed of a high-frequency oscillator incorporating an embroidered coil on the safety belt. During inspiration, the orientation of the driver changes with respect to the coil, which, due to a change in permittivity, results in a frequency change. Hence, respiration can be detected by observing the oscillator frequency. The belt-integrated sensor system has been evaluated in a laboratory experiment. Using a reference ECG as heart beat reference and a piezoelectric sensor belt strapped around the thorax as a respiration reference, the feasibility of the sensor system was investigated. First results showed a readily apparent respiratory signal and a good heart beat signal. It was shown that the monitoring of heart and breath activity is indeed possible.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2017 {IEEE} {International} {Conference} on {Vehicular} {Electronics} and {Safety} ({ICVES})},
	publisher = {IEEE},
	author = {Leicht, Lennart and Vetter, Pascal and Leonhardt, Steffen and Teichmann, Daniel},
	month = jun,
	year = {2017},
	pages = {191--195},
	file = {Leicht et al. - 2017 - The PhysioBelt A safety belt integrated sensor sy.pdf:/home/simeon/Zotero/storage/CSWPDTD3/Leicht et al. - 2017 - The PhysioBelt A safety belt integrated sensor sy.pdf:application/pdf},
}

@inproceedings{babaeian_real_2016,
	address = {Long Beach, CA, USA},
	title = {Real time driver drowsiness detection using a logistic-regression-based machine learning algorithm},
	isbn = {978-1-5090-2294-6},
	url = {http://ieeexplore.ieee.org/document/7790075/},
	doi = {10.1109/IGESC.2016.7790075},
	abstract = {The number of car accidents due to driver drowsiness is very steep. An automated non-contact system that can detect driver’s drowsiness early could be lifesaving. Motivated by this dire need, we propose a novel method that can detect driver’s drowsiness at an early stage by computing heart rate variation using advanced logistic regression based machine learning algorithm. Our developed technique has been tested with human subjects and it can detect drowsiness in a minimum amount of time, with an accuracy above 90\%.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2016 {IEEE} {Green} {Energy} and {Systems} {Conference} ({IGSEC})},
	publisher = {IEEE},
	author = {Babaeian, Mohsen and Bhardwaj, Nitish and Esquivel, Bianca and Mozumdar, Mohammad},
	month = nov,
	year = {2016},
	pages = {1--6},
	file = {Babaeian et al. - 2016 - Real time driver drowsiness detection using a logi.pdf:/home/simeon/Zotero/storage/6583IHKK/Babaeian et al. - 2016 - Real time driver drowsiness detection using a logi.pdf:application/pdf},
}

@inproceedings{lopez_detecting_2017,
	address = {Montreal, QC},
	title = {Detecting exercise-induced fatigue using thermal imaging and deep learning},
	isbn = {978-1-5386-1842-4},
	url = {http://ieeexplore.ieee.org/document/8310151/},
	doi = {10.1109/IPTA.2017.8310151},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2017 {Seventh} {International} {Conference} on {Image} {Processing} {Theory}, {Tools} and {Applications} ({IPTA})},
	publisher = {IEEE},
	author = {Lopez, Miguel Bordallo and del-Blanco, Carlos R. and Garcia, Narciso},
	month = nov,
	year = {2017},
	pages = {1--6},
	file = {Lopez et al. - 2017 - Detecting exercise-induced fatigue using thermal i.pdf:/home/simeon/Zotero/storage/Y2NKUYYJ/Lopez et al. - 2017 - Detecting exercise-induced fatigue using thermal i.pdf:application/pdf},
}

@inproceedings{zhiwei_zhu_real_2004,
	address = {Washington, WA, USA},
	title = {Real time and non-intrusive driver fatigue monitoring},
	isbn = {978-0-7803-8500-9},
	url = {http://ieeexplore.ieee.org/document/1398979/},
	doi = {10.1109/ITSC.2004.1398979},
	abstract = {This paper describes a real-time non-intrusive prototype driver fatigue monitor. It uses remotely located CCD cameras equipped with active IR illuminators to acquire video images of the driver. Various visual cues typically characterizing the alertness of the driver are extracted in real time and systematically combined to infer the fatigue level of the driver. The visual cues employed characterize eyelid movement, gaze movement, head movement, and facial expression. A probabilistic model is developed to model human fatigue and to predict fatigue based on the observed visual cues and the available contextual information. The simultaneous use of multiple visual cues and their systematic combination yields a much more robust and accurate fatigue characterization than using a single visual cue. The feasibility of our system is demonstrated using synthetic data. Further validation of our system under real life fatigue conditions with human subjects shows that it was reasonably robust, reliable and accurate in fatigue characterization.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {Proceedings. {The} 7th {International} {IEEE} {Conference} on {Intelligent} {Transportation} {Systems} ({IEEE} {Cat}. {No}.{04TH8749})},
	publisher = {IEEE},
	author = {{Zhiwei Zhu} and {Qiang Ji}},
	year = {2004},
	pages = {657--662},
	file = {Zhiwei Zhu and Qiang Ji - 2004 - Real time and non-intrusive driver fatigue monitor.pdf:/home/simeon/Zotero/storage/RAJGD3BA/Zhiwei Zhu and Qiang Ji - 2004 - Real time and non-intrusive driver fatigue monitor.pdf:application/pdf;Zhiwei Zhu and Qiang Ji - 2004 - Real time and non-intrusive driver fatigue monitor.pdf:/home/simeon/Zotero/storage/HEFPRXAS/Zhiwei Zhu and Qiang Ji - 2004 - Real time and non-intrusive driver fatigue monitor.pdf:application/pdf},
}

@article{jo_detecting_2014,
	title = {Detecting driver drowsiness using feature-level fusion and user-specific classification},
	volume = {41},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417413006106},
	doi = {10.1016/j.eswa.2013.07.108},
	abstract = {Accurate classiﬁcation of eye state is a prerequisite for preventing automobile accidents due to driver drowsiness. Previous methods of classiﬁcation, based on features extracted for a single eye, are vulnerable to eye localization errors and visual obstructions, and most use a ﬁxed threshold for classiﬁcation, irrespective of variations in the driver’s eye shape and texture. To address these deﬁciencies, we propose a new method for eye state classiﬁcation that combines three innovations: (1) extraction and fusion of features from both eyes, (2) initialization of driver-speciﬁc thresholds to account for differences in eye shape and texture, and (3) modeling of driver-speciﬁc blinking patterns for normal (non-drowsy) driving. Experimental results show that the proposed method achieves signiﬁcant improvements in detection accuracy.},
	language = {en},
	number = {4},
	urldate = {2022-02-09},
	journal = {Expert Systems with Applications},
	author = {Jo, Jaeik and Lee, Sung Joo and Park, Kang Ryoung and Kim, Ig-Jae and Kim, Jaihie},
	month = mar,
	year = {2014},
	pages = {1139--1152},
	file = {Jo et al. - 2014 - Detecting driver drowsiness using feature-level fu.pdf:/home/simeon/Zotero/storage/U5WXFLAA/Jo et al. - 2014 - Detecting driver drowsiness using feature-level fu.pdf:application/pdf},
}

@article{moujahid_efficient_2021,
	title = {Efficient and compact face descriptor for driver drowsiness detection},
	volume = {168},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417420310241},
	doi = {10.1016/j.eswa.2020.114334},
	abstract = {Current advances in driver drowsiness detection consist of a variety of innovative technologies generally based on driver state monitoring systems. Extracting eﬀective and relevant features to characterize drowsy symptoms in images and videos is still an open topic. In this work, we introduce a face monitoring system based on a compact face texture descriptor able to cover the most discriminant drowsy features. The compactness has been achieved by both a multi-scale pyramidal face representation that capture the main characteristics of local and global information, and the feature selection process applied on the raw extracted features. The proposed framework is rolled out in four phases: (i) face detection and alignment; (ii) Pyramid-Multi Level (PML) face representation; (iii) face description using a multi-level multi scale feature extraction; and (vi) feature subset selection and classiﬁcation. Experiments conducted on the public dataset NTH Drowsy Driver Detection (NTHUDDD) show the eﬀectiveness of the proposed face descriptor and the associated selection schemes. The results show that the proposed method compares favorably with several approaches including those based on deep Convolutional Neural Networks.},
	language = {en},
	urldate = {2022-02-09},
	journal = {Expert Systems with Applications},
	author = {Moujahid, Abdelmalik and Dornaika, Fadi and Arganda-Carreras, Ignacio and Reta, Jorge},
	month = apr,
	year = {2021},
	pages = {114334},
	file = {Moujahid et al. - 2021 - Efficient and compact face descriptor for driver d.pdf:/home/simeon/Zotero/storage/SN492XDT/Moujahid et al. - 2021 - Efficient and compact face descriptor for driver d.pdf:application/pdf},
}

@article{kacete_estimation_nodate,
	title = {Estimation du regard avec une caméra {RGB}-{D} dans des environnements utilisateur non-contraints},
	language = {fr},
	author = {Kacete, Amine},
	pages = {129},
	file = {Kacete - Estimation du regard avec une caméra RGB-D dans de.pdf:/home/simeon/Zotero/storage/9RLEQY78/Kacete - Estimation du regard avec une caméra RGB-D dans de.pdf:application/pdf},
}

@inproceedings{kurylyak_infrared_2011,
	address = {Bari, Italy},
	title = {The infrared camera-based system to evaluate the human sleepiness},
	isbn = {978-1-4244-9336-4},
	url = {http://ieeexplore.ieee.org/document/5966778/},
	doi = {10.1109/MeMeA.2011.5966778},
	abstract = {The eye’s blinking is a significant indicator of the sleepiness. The existing systems of blink detection and sleepiness analysis require usually to fix camera on spectacle frame or a special helmet that is not convenient and can affect the obtained result. In this paper, the infrared camera-based contact-less system is proposed to evaluate the human’s sleepiness. The infrared light switching is used to detect the pupil in each frame and, as a result, the blink event. The active pan-tilt unit is used to make possible free head movements. The algorithm is pointed out to process the camera frames in order to distinguish the involuntary blinks from voluntary ones. Preliminary experimental tests are shown with the intent to validate the proposed hardware and software system pointed out.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Medical} {Measurements} and {Applications}},
	publisher = {IEEE},
	author = {Kurylyak, Yuriy and Lamonaca, Francesco and Mirabelli, Giovanni and Boumbarov, Ognian and Panev, Stanislav},
	month = may,
	year = {2011},
	pages = {253--256},
	file = {Kurylyak et al. - 2011 - The infrared camera-based system to evaluate the h.pdf:/home/simeon/Zotero/storage/DZR3GC3A/Kurylyak et al. - 2011 - The infrared camera-based system to evaluate the h.pdf:application/pdf},
}

@inproceedings{kurylyak_detection_2012,
	address = {Budapest, Hungary},
	title = {Detection of the eye blinks for human's fatigue monitoring},
	isbn = {978-1-4673-0882-3 978-1-4673-0880-9 978-1-4673-0881-6},
	url = {http://ieeexplore.ieee.org/document/6226666/},
	doi = {10.1109/MeMeA.2012.6226666},
	abstract = {This paper presents a non-intrusive vision based system for eye blinks detection and fatigue level monitoring. It uses a web camera positioned in front of the face. A cascade of boosted classifiers based on Haar-like features is used for fast detection of the eyes region. The frames differencing in combination with the thresholding are applied to detect the eyes closure and opening. The frame processing algorithm is pointed out in order to distinguish the involuntary blinks from the voluntary ones. Experimental tests are shown that validate the proposed system.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2012 {IEEE} {International} {Symposium} on {Medical} {Measurements} and {Applications} {Proceedings}},
	publisher = {IEEE},
	author = {Kurylyak, Yuriy and Lamonaca, Francesco and Mirabelli, Giovanni},
	month = may,
	year = {2012},
	pages = {1--4},
	file = {Kurylyak et al. - 2012 - Detection of the eye blinks for human's fatigue mo.pdf:/home/simeon/Zotero/storage/B8466GK5/Kurylyak et al. - 2012 - Detection of the eye blinks for human's fatigue mo.pdf:application/pdf},
}

@article{petrova_for_nodate,
	title = {For {Information}, {Contact}:},
	language = {en},
	author = {Petrova, Olga and Yin, Lijun},
	pages = {2},
	file = {Petrova and Yin - For Information, Contact.pdf:/home/simeon/Zotero/storage/QHXTCA8I/Petrova and Yin - For Information, Contact.pdf:application/pdf},
}

@article{dai_coatnet_nodate,
	title = {{CoAtNet}: {Marrying} {Convolution} and {Attention} for {All} {Data} {Sizes}},
	abstract = {Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks. In this work, we show that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, we present CoAtNets (pronounced “coat” nets), a family of hybrid models built from two key insights: (1) depthwise Convolution and self-Attention can be naturally uniﬁed via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efﬁciency. Experiments show that our CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets: Without extra data, CoAtNet achieves 86.0\% ImageNet top-1 accuracy; When pre-trained with 13M images from ImageNet-21K, our CoAtNet achieves 88.56\% top-1 accuracy, matching ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data; Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88\% top-1 accuracy on ImageNet, establishing a new state-of-the-art result.},
	language = {en},
	author = {Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
	pages = {13},
	file = {Dai et al. - CoAtNet Marrying Convolution and Attention for Al.pdf:/home/simeon/Zotero/storage/LDAQFXA9/Dai et al. - CoAtNet Marrying Convolution and Attention for Al.pdf:application/pdf},
}

@inproceedings{ngxande_driver_2017,
	address = {Bloemfontein, South Africa},
	title = {Driver drowsiness detection using behavioral measures and machine learning techniques: {A} review of state-of-art techniques},
	isbn = {978-1-5386-2314-5},
	shorttitle = {Driver drowsiness detection using behavioral measures and machine learning techniques},
	url = {http://ieeexplore.ieee.org/document/8261140/},
	doi = {10.1109/RoboMech.2017.8261140},
	abstract = {This paper presents a literature review of driver drowsiness detection based on behavioral measures using machine learning techniques. Faces contain information that can be used to interpret levels of drowsiness. There are many facial features that can be extracted from the face to infer the level of drowsiness. These include eye blinks, head movements and yawning. However, the development of a drowsiness detection system that yields reliable and accurate results is a challenging task as it requires accurate and robust algorithms. A wide range of techniques has been examined to detect driver drowsiness in the past. The recent rise of deep learning requires that these algorithms be revisited to evaluate their accuracy in detection of drowsiness. As a result, this paper reviews machine learning techniques which include support vector machines, convolutional neural networks and hidden Markov models in the context of drowsiness detection. Furthermore, a meta-analysis is conducted on 25 papers that use machine learning techniques for drowsiness detection. The analysis reveals that support vector machine technique is the most commonly used technique to detect drowsiness, but convolutional neural networks performed better than the other two techniques. Finally, this paper lists publicly available datasets that can be used as benchmarks for drowsiness detection.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2017 {Pattern} {Recognition} {Association} of {South} {Africa} and {Robotics} and {Mechatronics} ({PRASA}-{RobMech})},
	publisher = {IEEE},
	author = {Ngxande, Mkhuseli and Tapamo, Jules-Raymond and Burke, Michael},
	month = nov,
	year = {2017},
	pages = {156--161},
	file = {Ngxande et al. - 2017 - Driver drowsiness detection using behavioral measu.pdf:/home/simeon/Zotero/storage/4JPP3RAR/Ngxande et al. - 2017 - Driver drowsiness detection using behavioral measu.pdf:application/pdf},
}

@inproceedings{savas_real_2018,
	address = {Istanbul, Turkey},
	title = {Real {Time} {Driver} {Fatigue} {Detection} {Based} on {SVM} {Algorithm}},
	isbn = {978-1-5386-7641-7},
	url = {https://ieeexplore.ieee.org/document/8751886/},
	doi = {10.1109/CEIT.2018.8751886},
	abstract = {Among the causes of the traffic accidents driver drowsiness comes at one of the first places. According to the literature some work has been done in driver fatigue detection. This paper proposes a Real Time Driver Fatigue Detection Based on Support Vector Machine (SVM) Algorithm. Fatigue detection mainly focuses on drivers’ face expressions and behaviors. OpenCV and Dlib libraries were utilized to detect the expressions of drivers’ faces. The proposed system has five stages: PERCLOS, count of yawn, internal zone of the mouth opening, count of eye blinking and head detection to extract attributes from real time video. Subsequently, facial expressions were trained with SVM. In this study an SVM-based driver fatigue detection is recommended and the tests showed that the accuracy rate of fatigue detection is up to 97.93\%.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2018 6th {International} {Conference} on {Control} {Engineering} \& {Information} {Technology} ({CEIT})},
	publisher = {IEEE},
	author = {Savas, Burcu Kir and Becerikli, Yasar},
	month = oct,
	year = {2018},
	pages = {1--4},
	file = {Savas and Becerikli - 2018 - Real Time Driver Fatigue Detection Based on SVM Al.pdf:/home/simeon/Zotero/storage/FWPDDGHV/Savas and Becerikli - 2018 - Real Time Driver Fatigue Detection Based on SVM Al.pdf:application/pdf},
}

@inproceedings{liu_practical_2010,
	address = {Shanghai, China},
	title = {A practical driver fatigue detection algorithm based on eye state},
	isbn = {978-1-4244-6735-8},
	url = {http://ieeexplore.ieee.org/document/5604919/},
	doi = {10.1109/PRIMEASIA.2010.5604919},
	abstract = {Fatigue driving is an important reason of traffic accidents. This paper proposes a practical algorithm to detect eye closure using an infrared camera to monitor and recognize driver dozing. Face and eye of the driver are first localized and then marked in every frame. After extracting the eye region, the proposed algorithm can detect eye corners, and with the eye corners restrictions, eyelids movement can be detected precisely and whether the eye closed or not can also be classified. An alarm is generated if the eye is closed for more than a specified period of time. The accuracy of the algorithm is demonstrated using real data under day and night with different drivers.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2010 {Asia} {Pacific} {Conference} on {Postgraduate} {Research} in {Microelectronics} and {Electronics} ({PrimeAsia})},
	publisher = {IEEE},
	author = {Liu, Ang and Li, Zhichao and Wang, Lang and Zhao, Yong},
	month = sep,
	year = {2010},
	pages = {235--238},
	file = {Liu et al. - 2010 - A practical driver fatigue detection algorithm bas.pdf:/home/simeon/Zotero/storage/35N9BIGS/Liu et al. - 2010 - A practical driver fatigue detection algorithm bas.pdf:application/pdf},
}

@incollection{kushida_psychomotor_2004,
	edition = {1},
	title = {Psychomotor {Vigilance} {Performance}: {Neurocognitive} {Assay} {Sensitive} to {Sleep} {Loss}},
	isbn = {978-0-429-22525-3},
	shorttitle = {Psychomotor {Vigilance} {Performance}},
	url = {https://www.taylorfrancis.com/books/9780203998007/chapters/10.3109/9780203998007-4},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {Sleep {Deprivation}},
	publisher = {CRC Press},
	author = {Dorrian, Jillian and Rogers, Naomi L. and Dinges, David F.},
	editor = {Kushida, Clete A.},
	collaborator = {Kushida, Clete A.},
	month = nov,
	year = {2004},
	doi = {10.3109/9780203998007-4},
	pages = {39--70},
	file = {Dorrian et al. - 2004 - Psychomotor Vigilance Performance Neurocognitive .pdf:/home/simeon/Zotero/storage/833PSWST/Dorrian et al. - 2004 - Psychomotor Vigilance Performance Neurocognitive .pdf:application/pdf},
}

@article{quddus_using_2021,
	title = {Using long short term memory and convolutional neural networks for driver drowsiness detection},
	volume = {156},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S000145752100138X},
	doi = {10.1016/j.aap.2021.106107},
	abstract = {Fatigue negatively affects the safety and performance of drivers on the road. In fact, drowsiness and fatigue are the cause of a substantial number of motor vehicle accidents. Drowsiness among the drivers can be detected using variety of modalities, including electroencephalogram (EEG), eye movement, and vehicle driving dy­ namics. Among these EEG is highly accurate but very intrusive and cumbersome. On the other hand, vehicle driving dynamics are very easy to acquire but accuracy is not very high. Eye movement based approach is very attractive in terms of balance between these two extremes. However, eye movement based techniques normally require an eye tracking device which consists of high speed camera with sophisticated algorithm to extract eye movement related parameters such as blinking, eye closure, saccades, fixation etc. This makes eye tracking based drowsiness detection difficult to implement as a practical system, especially on an embedded platform.},
	language = {en},
	urldate = {2022-02-09},
	journal = {Accident Analysis \& Prevention},
	author = {Quddus, Azhar and Shahidi Zandi, Ali and Prest, Laura and Comeau, Felix J.E.},
	month = jun,
	year = {2021},
	pages = {106107},
	file = {Quddus et al. - 2021 - Using long short term memory and convolutional neu.pdf:/home/simeon/Zotero/storage/35CC8945/Quddus et al. - 2021 - Using long short term memory and convolutional neu.pdf:application/pdf},
}

@inproceedings{nowara_sparseppg_2018,
	address = {Salt Lake City, UT},
	title = {{SparsePPG}: {Towards} {Driver} {Monitoring} {Using} {Camera}-{Based} {Vital} {Signs} {Estimation} in {Near}-{Infrared}},
	isbn = {978-1-5386-6100-0},
	shorttitle = {{SparsePPG}},
	url = {https://ieeexplore.ieee.org/document/8575330/},
	doi = {10.1109/CVPRW.2018.00174},
	abstract = {Camera-based measurement of the heartbeat signal from minute changes in the appearance of a person’s skin is known as remote photoplethysmography (rPPG). Methods for rPPG have improved considerably in recent years, making possible its integration into applications such as telemedicine. Driver monitoring using in-car cameras is another potential application of this emerging technology. Unfortunately, there are several challenges unique to the driver monitoring context that must be overcome. First, there are drastic illumination changes on the driver’s face, both during the day (as sun ﬁlters in and out of overhead trees, etc.) and at night (from streetlamps and oncoming headlights), which current rPPG algorithms cannot account for. We argue that these variations are signiﬁcantly reduced by narrow-bandwidth near-infrared (NIR) active illumination at 940 nm, with matching bandpass ﬁlter on the camera. Second, the amount of motion during driving is signiﬁcant. We perform a preliminary analysis of the motion magnitude and argue that any in-car solution must provide better robustness to motion artifacts. Third, low signal-tonoise ratio (SNR) and false peaks due to motion have the potential to confound the rPPG signal. To address these challenges, we develop a novel rPPG signal tracking and denoising algorithm (sparsePPG) based on Robust Principal Components Analysis and sparse frequency spectrum estimation. We release a new dataset of face videos collected simultaneously in RGB and NIR. We demonstrate that in each of these frequency ranges, our new method performs as well as or better than current state-of-the-art rPPG algorithms. Overall, our preliminary study indicates that while driver vital signs monitoring using cameras is promising, much work needs to be done in terms of improving robustness to motion artifacts before it becomes practical.},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Nowara, Ewa Magdalena and Marks, Tim K. and Mansour, Hassan and Veeraraghavan, Ashok},
	month = jun,
	year = {2018},
	pages = {1353--135309},
	file = {Nowara et al. - 2018 - SparsePPG Towards Driver Monitoring Using Camera-.pdf:/home/simeon/Zotero/storage/ESHNYQSE/Nowara et al. - 2018 - SparsePPG Towards Driver Monitoring Using Camera-.pdf:application/pdf},
}

@article{ji_real-time_2002,
	title = {Real-{Time} {Eye}, {Gaze}, and {Face} {Pose} {Tracking} for {Monitoring} {Driver} {Vigilance}},
	volume = {8},
	issn = {10772014},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1077201402902792},
	doi = {10.1006/rtim.2002.0279},
	language = {en},
	number = {5},
	urldate = {2022-02-09},
	journal = {Real-Time Imaging},
	author = {Ji, Q},
	month = oct,
	year = {2002},
	pages = {357--377},
	file = {Ji - 2002 - Real-Time Eye, Gaze, and Face Pose Tracking for Mo.pdf:/home/simeon/Zotero/storage/CENYCEPJ/Ji - 2002 - Real-Time Eye, Gaze, and Face Pose Tracking for Mo.pdf:application/pdf;Ji - 2002 - Real-Time Eye, Gaze, and Face Pose Tracking for Mo.pdf:/home/simeon/Zotero/storage/QIAASSQC/Ji - 2002 - Real-Time Eye, Gaze, and Face Pose Tracking for Mo.pdf:application/pdf},
}

@article{monteiro_investigating_2020,
	title = {Investigating an {Integrated} {Sensor} {Fusion} {System} for {Mental} {Fatigue} {Assessment} for {Demanding} {Maritime} {Operations}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/9/2588},
	doi = {10.3390/s20092588},
	abstract = {Human-related issues are currently the most signiﬁcant factor in maritime causalities, especially in demanding operations that require coordination between two or more vessels and/or other maritime structures. Some of these human-related issues include incorrect, incomplete, or nonexistent following of procedures; lack of situational awareness; and physical or mental fatigue. Among these, mental fatigue is especially dangerous, due to its capacity to reduce reaction time, interfere in the decision-making process, and affect situational awareness. Mental fatigue is also especially hard to identify and quantify. Self-assessment of mental fatigue may not be reliable and few studies have assessed mental fatigue in maritime operations, especially in real time. In this work we propose an integrated sensor fusion system for mental fatigue assessment using physiological sensors and convolutional neural networks. We show, by using a simulated navigation experiment, how data from different sensors can be fused into a robust mental fatigue assessment tool, capable of achieving up to 100\% detection accuracy for single-subject classiﬁcation. Additionally, the use of different sensors seems to favor the representation of the transition between mental fatigue states.},
	language = {en},
	number = {9},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Monteiro, Thiago Gabriel and Li, Guoyuan and Skourup, Charlotte and Zhang, Houxiang},
	month = may,
	year = {2020},
	pages = {2588},
	file = {Monteiro et al. - 2020 - Investigating an Integrated Sensor Fusion System f.pdf:/home/simeon/Zotero/storage/79985EZ2/Monteiro et al. - 2020 - Investigating an Integrated Sensor Fusion System f.pdf:application/pdf},
}

@article{paracchini_biometric_2020,
	title = {Biometric {Signals} {Estimation} {Using} {Single} {Photon} {Camera} and {Deep} {Learning}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/21/6102},
	doi = {10.3390/s20216102},
	abstract = {The problem of performing remote biomedical measurements using just a video stream of a subject face is called remote photoplethysmography (rPPG). The aim of this work is to propose a novel method able to perform rPPG using single-photon avalanche diode (SPAD) cameras. These are extremely accurate cameras able to detect even a single photon and are already used in many other applications. Moreover, a novel method that mixes deep learning and traditional signal analysis is proposed in order to extract and study the pulse signal. Experimental results show that this system achieves accurate results in the estimation of biomedical information such as heart rate, respiration rate, and tachogram. Lastly, thanks to the adoption of the deep learning segmentation method and dependability checks, this method could be adopted in non-ideal working conditions—for example, in the presence of partial facial occlusions.},
	language = {en},
	number = {21},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Paracchini, Marco and Marcon, Marco and Villa, Federica and Zappa, Franco and Tubaro, Stefano},
	month = oct,
	year = {2020},
	pages = {6102},
	file = {Paracchini et al. - 2020 - Biometric Signals Estimation Using Single Photon C.pdf:/home/simeon/Zotero/storage/QWDSSSCJ/Paracchini et al. - 2020 - Biometric Signals Estimation Using Single Photon C.pdf:application/pdf},
}

@article{jiang_data-driven_2021,
	title = {A {Data}-{Driven} {Approach} to {Predict} {Fatigue} in {Exercise} {Based} on {Motion} {Data} from {Wearable} {Sensors} or {Force} {Plate}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/4/1499},
	doi = {10.3390/s21041499},
	abstract = {Fatigue increases the risk of injury during sports training and rehabilitation. Early detection of fatigue during exercises would help adapt the training in order to prevent over-training and injury. This study lays the foundation for a data-driven model to automatically predict the onset of fatigue and quantify consequent fatigue changes using a force plate (FP) or inertial measurement units (IMUs). The force plate and body-worn IMUs were used to capture movements associated with exercises (squats, high knee jacks, and corkscrew toe-touch) to estimate participant-speciﬁc fatigue levels in a continuous fashion using random forest (RF) regression and convolutional neural network (CNN) based regression models. Analysis of unseen data showed high correlation (up to 89\%, 93\%, and 94\% for the squat, jack, and corkscrew exercises, respectively) between the predicted fatigue levels and self-reported fatigue levels. Predictions using force plate data achieved similar performance as those with IMU data; the best results in both cases were achieved with a convolutional neural network. The displacement of the center of pressure (COP) was found to be correlated with fatigue compared to other commonly used features of the force plate. Bland–Altman analysis also conﬁrmed that the predicted fatigue levels were close to the true values. These results contribute to the ﬁeld of human motion recognition by proposing a deep neural network model that can detect fairly small changes of motion data in a continuous process and quantify the movement. Based on the successful ﬁndings with three different exercises, the general nature of the methodology is potentially applicable to a variety of other forms of exercises, thereby contributing to the future adaptation of exercise programs and prevention of over-training and injury as a result of excessive fatigue.},
	language = {en},
	number = {4},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Jiang, Yanran and Hernandez, Vincent and Venture, Gentiane and Kulić, Dana and K. Chen, Bernard},
	month = feb,
	year = {2021},
	pages = {1499},
	file = {Jiang et al. - 2021 - A Data-Driven Approach to Predict Fatigue in Exerc.pdf:/home/simeon/Zotero/storage/5CGL4VVG/Jiang et al. - 2021 - A Data-Driven Approach to Predict Fatigue in Exerc.pdf:application/pdf},
}

@article{ni_review_2021,
	title = {A {Review} of {Deep} {Learning}-{Based} {Contactless} {Heart} {Rate} {Measurement} {Methods}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/11/3719},
	doi = {10.3390/s21113719},
	abstract = {The interest in contactless or remote heart rate measurement has been steadily growing in healthcare and sports applications. Contactless methods involve the utilization of a video camera and image processing algorithms. Recently, deep learning methods have been used to improve the performance of conventional contactless methods for heart rate measurement. After providing a review of the related literature, a comparison of the deep learning methods whose codes are publicly available is conducted in this paper. The public domain UBFC dataset is used to compare the performance of these deep learning methods for heart rate measurement. The results obtained show that the deep learning method PhysNet generates the best heart rate measurement outcome among these methods, with a mean absolute error value of 2.57 beats per minute and a mean square error value of 7.56 beats per minute.},
	language = {en},
	number = {11},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Ni, Aoxin and Azarang, Arian and Kehtarnavaz, Nasser},
	month = may,
	year = {2021},
	pages = {3719},
	file = {Ni et al. - 2021 - A Review of Deep Learning-Based Contactless Heart .pdf:/home/simeon/Zotero/storage/WTHMCULU/Ni et al. - 2021 - A Review of Deep Learning-Based Contactless Heart .pdf:application/pdf},
}

@article{siddiqui_non-invasive_2021,
	title = {Non-{Invasive} {Driver} {Drowsiness} {Detection} {System}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/14/4833},
	doi = {10.3390/s21144833},
	abstract = {Drowsiness when in command of a vehicle leads to a decline in cognitive performance that affects driver behavior, potentially causing accidents. Drowsiness-related road accidents lead to severe trauma, economic consequences, impact on others, physical injury and/or even death. Realtime and accurate driver drowsiness detection and warnings systems are necessary schemes to reduce tiredness-related driving accident rates. The research presented here aims at the classiﬁcation of drowsy and non-drowsy driver states based on respiration rate detection by non-invasive, non-touch, impulsive radio ultra-wideband (IR-UWB) radar. Chest movements of 40 subjects were acquired for 5 m using a lab-placed IR-UWB radar system, and respiration per minute was extracted from the resulting signals. A structured dataset was obtained comprising respiration per minute, age and label (drowsy/non-drowsy). Different machine learning models, namely, Support Vector Machine, Decision Tree, Logistic regression, Gradient Boosting Machine, Extra Tree Classiﬁer and Multilayer Perceptron were trained on the dataset, amongst which the Support Vector Machine shows the best accuracy of 87\%. This research provides a ground truth for veriﬁcation and assessment of UWB to be used effectively for driver drowsiness detection based on respiration.},
	language = {en},
	number = {14},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Siddiqui, Hafeez Ur Rehman and Saleem, Adil Ali and Brown, Robert and Bademci, Bahattin and Lee, Ernesto and Rustam, Furqan and Dudley, Sandra},
	month = jul,
	year = {2021},
	pages = {4833},
	file = {Siddiqui et al. - 2021 - Non-Invasive Driver Drowsiness Detection System.pdf:/home/simeon/Zotero/storage/753WNN6R/Siddiqui et al. - 2021 - Non-Invasive Driver Drowsiness Detection System.pdf:application/pdf},
}

@article{russell_predicting_2021,
	title = {Predicting {Fatigue} in {Long} {Duration} {Mountain} {Events} with a {Single} {Sensor} and {Deep} {Learning} {Model}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/16/5442},
	doi = {10.3390/s21165442},
	abstract = {Aim: To determine whether an AI model and single sensor measuring acceleration and ECG could model cognitive and physical fatigue for a self-paced trail run. Methods: A ﬁeld-based protocol of continuous fatigue repeated hourly induced physical ({\textasciitilde}45 min) and cognitive ({\textasciitilde}10 min) fatigue on one healthy participant. The physical load was a 3.8 km, 200 m vertical gain, trail run, with acceleration and electrocardiogram (ECG) data collected using a single sensor. Cognitive load was a Multi Attribute Test Battery (MATB) and separate assessment battery included the Finger Tap Test (FTT), Stroop, Trail Making A and B, Spatial Memory, Paced Visual Serial Addition Test (PVSAT), and a vertical jump. A fatigue prediction model was implemented using a Convolutional Neural Network (CNN). Results: When the fatigue test battery results were compared for sensitivity to the protocol load, FTT right hand (R2 0.71) and Jump Height (R2 0.78) were the most sensitive while the other tests were less sensitive (R2 values Stroop 0.49, Trail Making A 0.29, Trail Making B 0.05, PVSAT 0.03, spatial memory 0.003). The best prediction results were achieved with a rolling average of 200 predictions (102.4 s), during set activity types, mean absolute error for ‘walk up’ (MAE200 12.5\%), and range of absolute error for ‘run down’ (RAE200 16.7\%). Conclusions: We were able to measure cognitive and physical fatigue using a single wearable sensor during a practical ﬁeld protocol, including contextual factors in conjunction with a neural network model. This research has practical application to fatigue research in the ﬁeld.},
	language = {en},
	number = {16},
	urldate = {2022-02-09},
	journal = {Sensors},
	author = {Russell, Brian and McDaid, Andrew and Toscano, William and Hume, Patria},
	month = aug,
	year = {2021},
	pages = {5442},
	file = {Russell et al. - 2021 - Predicting Fatigue in Long Duration Mountain Event.pdf:/home/simeon/Zotero/storage/KYZ9V5FI/Russell et al. - 2021 - Predicting Fatigue in Long Duration Mountain Event.pdf:application/pdf},
}

@article{wu_io_2015,
	title = {An {I}/{O} {Efficient} {Model} {Checking} {Algorithm} for {Large}-{Scale} {Systems}},
	volume = {23},
	issn = {1063-8210, 1557-9999},
	url = {https://ieeexplore.ieee.org/document/6850009},
	doi = {10.1109/TVLSI.2014.2330061},
	abstract = {Model checking is a powerful approach for the formal veriﬁcation of hardware and software systems. However, this approach suffers from the state space explosion problem, which limits its application to large-scale systems due to space shortage. To overcome this drawback, one of the most effective solutions is to use external memory algorithms. In this paper, we propose an I/O efﬁcient model checking algorithm for large-scale systems. To lower I/O complexity and improve time efﬁciency, we combine three new techniques: 1) a linear hashsorting technique; 2) a cached duplicate detection technique; and 3) a dynamic path management technique. We show that the new algorithm has a lower I/O complexity than state-of-the-art I/O efﬁcient model checking algorithms, including detect accepting cycle, maximal accepting predecessors, and iterative-deepening depth-ﬁrst search. In addition, the experiments show that our algorithm obviously outperforms these three algorithms on the selected representative benchmarks in terms of performance.},
	language = {en},
	number = {5},
	urldate = {2022-02-09},
	journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	author = {Wu, Lijun and Huang, Huijia and Su, Kaile and Cai, Shaowei and Zhang, Xiaosong},
	month = may,
	year = {2015},
	pages = {905--915},
	file = {Wu et al. - 2015 - An IO Efficient Model Checking Algorithm for Larg.pdf:/home/simeon/Zotero/storage/VNKQGGVT/Wu et al. - 2015 - An IO Efficient Model Checking Algorithm for Larg.pdf:application/pdf},
}

@article{mehta_real-time_2019,
	title = {Real-{Time} {Driver} {Drowsiness} {Detection} {System} {Using} {Eye} {Aspect} {Ratio} and {Eye} {Closure} {Ratio}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3356401},
	doi = {10.2139/ssrn.3356401},
	language = {en},
	urldate = {2022-02-09},
	journal = {SSRN Electronic Journal},
	author = {Mehta, Sukrit and Dadhich, Sharad and Gumber, Sahil and Jadhav Bhatt, Arpita},
	year = {2019},
	file = {Mehta et al. - 2019 - Real-Time Driver Drowsiness Detection System Using.pdf:/home/simeon/Zotero/storage/9HUQFBXL/Mehta et al. - 2019 - Real-Time Driver Drowsiness Detection System Using.pdf:application/pdf;Mehta et al. - 2019 - Real-Time Driver Drowsiness Detection System Using.pdf:/home/simeon/Zotero/storage/MD445EVJ/Mehta et al. - 2019 - Real-Time Driver Drowsiness Detection System Using.pdf:application/pdf},
}

@inproceedings{dalton_vista_2006,
	address = {Orlando, Florida , USA},
	title = {The {VISTA} infrared camera},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.670018},
	doi = {10.1117/12.670018},
	abstract = {We describe the integration and test phase of the construction of the VISTA Infrared Camera, a 64 Megapixel, 1.65 degree field of view 0.9-2.4 micron camera which will soon be operating at the cassegrain focus of the 4m VISTA telescope. The camera incorporates sixteen IR detectors and six CCD detectors which are used to provide autoguiding and wavefront sensing information to the VISTA telescope control system.},
	language = {en},
	urldate = {2022-02-09},
	author = {Dalton, G. B. and Caldwell, M. and Ward, A. K. and Whalley, M. S. and Woodhouse, G. and Edeson, R. L. and Clark, P. and Beard, S. M. and Gallie, A. M. and Todd, S. P. and Strachan, J. M. D. and Bezawada, N. N. and Sutherland, W. J. and Emerson, J. P.},
	editor = {McLean, Ian S. and Iye, Masanori},
	month = jun,
	year = {2006},
	pages = {62690X},
	file = {Dalton et al. - 2006 - The VISTA infrared camera.pdf:/home/simeon/Zotero/storage/ABX4LWJR/Dalton et al. - 2006 - The VISTA infrared camera.pdf:application/pdf},
}

@article{qiu_evm-cnn_2019,
	title = {{EVM}-{CNN}: {Real}-{Time} {Contactless} {Heart} {Rate} {Estimation} {From} {Facial} {Video}},
	volume = {21},
	issn = {1520-9210, 1941-0077},
	shorttitle = {{EVM}-{CNN}},
	url = {https://ieeexplore.ieee.org/document/8552438/},
	doi = {10.1109/TMM.2018.2883866},
	abstract = {With the increase in health consciousness, noninvasive body monitoring has aroused interest among researchers. As one of the most important pieces of physiological information, researchers have remotely estimated the heart rate from facial videos in recent years. Although progress has been made over the past few years, there are still some limitations, like the processing time increasing with accuracy and the lack of comprehensive and challenging datasets for use and comparison. Recently, it was shown that heart rate information can be extracted from facial videos by spatial decomposition and temporal ﬁltering. Inspired by this, a new framework is introduced in this paper for remotely estimating the heart rate under realistic conditions by combining spatial and temporal ﬁltering and a convolutional neural network. Our proposed approach shows better performance compared with the benchmark on the MMSE-HR dataset in terms of both the average heart rate estimation and short-time heart rate estimation. High consistency in short-time heart rate estimation is observed between our method and the ground truth.},
	language = {en},
	number = {7},
	urldate = {2022-02-09},
	journal = {IEEE Transactions on Multimedia},
	author = {Qiu, Ying and Liu, Yang and Arteaga-Falconi, Juan and Dong, Haiwei and Saddik, Abdulmotaleb El},
	month = jul,
	year = {2019},
	pages = {1778--1787},
	file = {Qiu et al. - 2019 - EVM-CNN Real-Time Contactless Heart Rate Estimati.pdf:/home/simeon/Zotero/storage/F2GZEHMB/Qiu et al. - 2019 - EVM-CNN Real-Time Contactless Heart Rate Estimati.pdf:application/pdf},
}

@article{phillips_review_2015,
	title = {A review of definitions of fatigue – {And} a step towards a whole definition},
	volume = {29},
	issn = {13698478},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1369847815000091},
	doi = {10.1016/j.trf.2015.01.003},
	abstract = {Despite its importance to health and safety, there is a long history of disagreement about how to operationalize fatigue when studying exertion in human transport operators. The current article reviews existing deﬁnitions, and consequently proposes a new deﬁnition as a step forward. A consideration of everyday use of the term ﬁnds that people often seem to use fatigue to describe a sensation related to exertion. Formal deﬁnitions of fatigue can be divided into a few broad deﬁnitions, capturing experiential, physiological and performance aspects of the construct, and many narrow deﬁnitions, focusing only on one or two of these aspects. Most existing deﬁnitions do not account explicitly for the role of sleep drives and sleepiness. They also fail to account for a wide range of factors associated with transport operator exertion, such as motivation and individual, organizational and environmental factors. Each of these points is assimilated in the derivation of a new ‘‘whole deﬁnition’’ of fatigue, in which the experience of human operator fatigue is a central aspect of the fatigue process. Although multidimensional and diffuse, the evolved deﬁnition does not detract from the measurement and study of limited aspects of fatigue. Rather, by describing the dynamic complexity of fatigue, it may help make explicit what different studies do or do not measure or account for in terms of the different aspects of fatigue. It is claimed that the proposed deﬁnition could be used to help harmonise attempts to study and tackle fatigue in transport health and safety contexts.},
	language = {en},
	urldate = {2022-02-22},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Phillips, Ross O.},
	month = feb,
	year = {2015},
	pages = {48--56},
	file = {Phillips - 2015 - A review of definitions of fatigue – And a step to.pdf:/home/simeon/Zotero/storage/NT5XS6AH/Phillips - 2015 - A review of definitions of fatigue – And a step to.pdf:application/pdf;Phillips - 2015 - A review of definitions of fatigue – And a step to.pdf:/home/simeon/Zotero/storage/CKQKZ3GT/Phillips - 2015 - A review of definitions of fatigue – And a step to.pdf:application/pdf},
}

@article{li_human_nodate,
	title = {Human skin characterization and analysis based on hyperspectral reflectance using machine learning},
	language = {en},
	author = {Li, Shiwei},
	pages = {144},
	file = {Li - Human skin characterization and analysis based on .pdf:/home/simeon/Zotero/storage/QBR39EX4/Li - Human skin characterization and analysis based on .pdf:application/pdf},
}

@article{laurent_detection_nodate,
	title = {Détection de la fatigue mentale à partir de données électrophysiologiques},
	language = {fr},
	author = {Laurent, François},
	pages = {128},
	file = {Laurent - Détection de la fatigue mentale à partir de donnée.pdf:/home/simeon/Zotero/storage/GW7EKBDV/Laurent - Détection de la fatigue mentale à partir de donnée.pdf:application/pdf},
}

@inproceedings{ishimaru_cognitive_2017,
	address = {Kyoto},
	title = {Cognitive {State} {Measurement} on {Learning} {Materials} by {Utilizing} {Eye} {Tracker} and {Thermal} {Camera}},
	isbn = {978-1-5386-3586-5},
	url = {http://ieeexplore.ieee.org/document/8270330/},
	doi = {10.1109/ICDAR.2017.378},
	abstract = {We demonstrate how information derived from pervasive sensors can quantify cognitive states of learners while they are reading a textbook. Eye tracking is one of the most effective approaches to measuring reading behavior. For example, high ﬁxation duration represents a reader’s attention on a document. However, it is still a challenging task to predict the reason for the attention (i.e., is it because of his/her interest or trouble of understanding?). In this paper, we utilize additional sensing modality to solve the problem. On the dataset of 12 high school students’ reading behaviors, we have found that the changing of pupil diameter and nose temperature are highly correlated with their cognitive states including their interests and efforts for reading/solving tasks on learning materials in Physics.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {2017 14th {IAPR} {International} {Conference} on {Document} {Analysis} and {Recognition} ({ICDAR})},
	publisher = {IEEE},
	author = {Ishimaru, Shoya and Jacob, Soumy and Roy, Apurba and Bukhari, Syed Saqib and Heisel, Carina and GroBmann, Nicolas and Thees, Michael and Kuhn, Jochen and Dengel, Andreas},
	month = nov,
	year = {2017},
	pages = {32--36},
	file = {Ishimaru et al. - 2017 - Cognitive State Measurement on Learning Materials .pdf:/home/simeon/Zotero/storage/RI5VPAHA/Ishimaru et al. - 2017 - Cognitive State Measurement on Learning Materials .pdf:application/pdf},
}

@article{salih_study_2017,
	title = {Study of {Video} based {Facial} {Expression} and {Emotions} {Recognition} {Methods}},
	abstract = {In real life scenario, facial expressions and emotions are nothing but responses to the external and internal events of human being. In human computer interaction, recognition of end user’s expressions and emotions from the video streaming plays very important role. In such systems it is required to track the dynamic changes in human face movements quickly in order to deliver the required response system. The one real time application is physical fatigue detection based on facial detection and expressions such as driver fatigue detection in order to prevent the accidents on road. Face expression based physical fatigue analysis or detection is out of scope of this paper, but this paper reveal study on different methods those are presented recently for facial expression and/or emotions recognition using video. This paper presenting the methodologies in terms of feature extraction and classification used in facial expression and/or emotion recognition methods with their comparative study. The comparative study is done based on accuracy, implementation tool, advantages and disadvantages. The outcome of this paper is the current research gap and research challenges those are still open to solve for video based facial detection and recognition systems. The survey on recent methods is appropriately presented throughout this paper by considering future research works.},
	language = {en},
	author = {Salih, Husam},
	year = {2017},
	pages = {5},
	file = {Salih - 2017 - Study of Video based Facial Expression and Emotion.pdf:/home/simeon/Zotero/storage/H8MI8LMV/Salih - 2017 - Study of Video based Facial Expression and Emotion.pdf:application/pdf},
}

@article{shen_high-precision_2021,
	title = {A high-precision feature extraction network of fatigue speech from air traffic controller radiotelephony based on improved deep learning},
	volume = {7},
	issn = {24059595},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405959521000023},
	doi = {10.1016/j.icte.2021.01.002},
	abstract = {Air traffic controller (ATC) fatigue is receiving considerable attention in recent studies because it represents a major cause of air traffic incidences. Research has revealed that the presence of fatigue can be detected by analysing speech utterances. However, constructing a complete labelled fatigue data set is very time-consuming. Moreover, a manually constructed speech collection will often contain only little key information to be used effectively in fatigue recognition, while multilevel deep models based on such speech materials often have overfitting problems due to an explosive increase of model parameters. To address these problems, a novel deep learning framework is proposed in this study to integrate active learning (AL) into complex speech features selected from a large set of unlabelled speech data in order to overcome the loss of information. A shallow feature set is first extracted using stacked sparse autoencoder networks, in which fatigue state challenge features from a manually selected speaker set of are exploited as the input vector. A densely connected convolutional autoencoder (DCAE) is then proposed to learn advanced features automatically from spectrograms of the selected data to supplement the fatigue features. The network can be effectively trained using a relatively small number of labelled samples with the help of AL sampling strategies, and the addition of a dense block to the convolutional automatic encoder can decrease the number of parameters and make the model easier to fit. Finally, the two above-mentioned features are combined using multiple kernel learning with a support-vector-machine classifier. A series of comparative experiments using the Civil Aviation Administration of China radiotelephony corpus demonstrates that the proposed method provides a significant improvement in the detection precision compared to current state-of-the-art approaches.},
	language = {en},
	number = {4},
	urldate = {2022-02-23},
	journal = {ICT Express},
	author = {Shen, Zhiyuan and Wei, Yitao},
	month = dec,
	year = {2021},
	pages = {403--413},
	file = {Shen and Wei - 2021 - A high-precision feature extraction network of fat.pdf:/home/simeon/Zotero/storage/95GTRD25/Shen and Wei - 2021 - A high-precision feature extraction network of fat.pdf:application/pdf},
}

@article{chaudhuri_fatigue_2004,
	title = {Fatigue in neurological disorders},
	volume = {363},
	issn = {01406736},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673604157942},
	doi = {10.1016/S0140-6736(04)15794-2},
	language = {en},
	number = {9413},
	urldate = {2022-02-23},
	journal = {The Lancet},
	author = {Chaudhuri, Abhijit and Behan, Peter O},
	month = mar,
	year = {2004},
	pages = {978--988},
	file = {Chaudhuri and Behan - 2004 - Fatigue in neurological disorders.pdf:/home/simeon/Zotero/storage/BQRBD3QW/Chaudhuri and Behan - 2004 - Fatigue in neurological disorders.pdf:application/pdf},
}

@article{ren_noncontact_2015,
	title = {Noncontact {Multiple} {Heartbeats} {Detection} and {Subject} {Localization} {Using} {UWB} {Impulse} {Doppler} {Radar}},
	volume = {25},
	issn = {1531-1309, 1558-1764},
	url = {http://ieeexplore.ieee.org/document/7194855/},
	doi = {10.1109/LMWC.2015.2463214},
	abstract = {In this letter, a phase-based algorithm based on a logarithmic method, applicable to UWB radars and suitable to real-time monitoring, is proposed to detect the phase variations of reﬂected pulses caused by the tiny cardiac motions. Compared with conventional FFT vital signs detection method, this algorithm demonstrates advantage in respiration harmonics suppression and avoidance of intermodulation between respiration and heartbeat signals. Furthermore, it is experimentally shown that UWB Doppler radar is capable of multiple heartbeats detection and subject identiﬁcation/localization.},
	language = {en},
	number = {10},
	urldate = {2022-02-23},
	journal = {IEEE Microwave and Wireless Components Letters},
	author = {Ren, Lingyun and Koo, Yun Seo and Wang, Haofei and Wang, Yazhou and Liu, Quanhua and Fathy, Aly E.},
	month = oct,
	year = {2015},
	pages = {690--692},
	file = {Ren et al. - 2015 - Noncontact Multiple Heartbeats Detection and Subje.pdf:/home/simeon/Zotero/storage/AHY6DQD5/Ren et al. - 2015 - Noncontact Multiple Heartbeats Detection and Subje.pdf:application/pdf},
}

@article{duan_non-contact_2019,
	title = {Non-{Contact} {Detection} of {Vital} {Signs} {Using} a {UWB} {Radar} {Sensor}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8581412/},
	doi = {10.1109/ACCESS.2018.2886825},
	abstract = {The ultra-wide band (UWB) radar sensor is useful in the ﬁeld of mission critical sensors and sensor networks due to its short detection time, high penetration, and low energy consumption. To support critical missions such as search and rescue, this paper designs a non-contact detection system based on a UWB radar sensor module to obtain vital signs of human beings. There are noise and clutter due to non-contact detection, and therefore the coherent background noise removal and moving target display ﬁlter are applied. Then, the variational mode decomposition (VMD) algorithm is used to extract heartbeat signals and respiratory signals. In addition, the Hilbert transform is applied to heartbeat signals and respiratory signals to obtain the time-frequency information. The electrocardiogram is also employed to compare the results of the UWB radar sensor. We also detect the human target through-the-wall. It turns out that the system can obtain respiratory and heartbeat characteristics simultaneously in one measurement, saving cost with high accuracy.},
	language = {en},
	urldate = {2022-02-23},
	journal = {IEEE Access},
	author = {Duan, Zhenzhen and Liang, Jing},
	year = {2019},
	pages = {36888--36895},
	file = {Duan and Liang - 2019 - Non-Contact Detection of Vital Signs Using a UWB R.pdf:/home/simeon/Zotero/storage/QJQQK3KY/Duan and Liang - 2019 - Non-Contact Detection of Vital Signs Using a UWB R.pdf:application/pdf},
}

@article{miyauchi_human_2009,
	title = {Human brain activity time-locked to rapid eye movements during {REM} sleep},
	volume = {192},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-008-1579-2},
	doi = {10.1007/s00221-008-1579-2},
	language = {en},
	number = {4},
	urldate = {2022-02-23},
	journal = {Experimental Brain Research},
	author = {Miyauchi, Satoru and Misaki, Masaya and Kan, Shigeyuki and Fukunaga, Takahide and Koike, Takahiko},
	month = feb,
	year = {2009},
	pages = {657--667},
	file = {Miyauchi et al. - 2009 - Human brain activity time-locked to rapid eye move.pdf:/home/simeon/Zotero/storage/GKP2Q99X/Miyauchi et al. - 2009 - Human brain activity time-locked to rapid eye move.pdf:application/pdf},
}

@inproceedings{jian_detection_2014,
	address = {The Hague, Netherlands},
	title = {Detection of breathing and heartbeat by using a simple {UWB} radar system},
	isbn = {978-88-907018-4-9},
	url = {http://ieeexplore.ieee.org/document/6902477/},
	doi = {10.1109/EuCAP.2014.6902477},
	abstract = {We present the development on an ultra-wideband (UWB) radar system and its signal processing algorithms for detecting human breathing and heartbeat in the paper. The UWB radar system consists of two (Tx and Rx) antennas and one compact CMOS UWB transceiver. Several signal processing techniques are developed for the application. The system has been tested by real measurements.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {The 8th {European} {Conference} on {Antennas} and {Propagation} ({EuCAP} 2014)},
	publisher = {IEEE},
	author = {Jian, Qiuchi and Yang, Jian and Yu, Yinan and Bjorkholm, Peter and McKelvey, Tomas},
	month = apr,
	year = {2014},
	pages = {3078--3081},
	file = {Jian et al. - 2014 - Detection of breathing and heartbeat by using a si.pdf:/home/simeon/Zotero/storage/UIV5UNRW/Jian et al. - 2014 - Detection of breathing and heartbeat by using a si.pdf:application/pdf},
}

@article{liu_wireless_2020,
	title = {Wireless {Sensing} for {Human} {Activity}: {A} {Survey}},
	volume = {22},
	issn = {1553-877X, 2373-745X},
	shorttitle = {Wireless {Sensing} for {Human} {Activity}},
	url = {https://ieeexplore.ieee.org/document/8794643/},
	doi = {10.1109/COMST.2019.2934489},
	abstract = {With the advancement of wireless technologies and sensing methodologies, many studies have shown the success of re-using wireless signals (e.g., WiFi) to sense human activities and thereby realize a set of emerging applications, ranging from intrusion detection, daily activity recognition, gesture recognition to vital signs monitoring and user identiﬁcation involving even ﬁner-grained motion sensing. These applications arguably can brace various domains for smart home and ofﬁce environments, including safety protection, well-being monitoring/management, smart healthcare and smart-appliance interaction. The movements of the human body impact the wireless signal propagation (e.g., reﬂection, diffraction and scattering), which provide great opportunities to capture human motions by analyzing the received wireless signals. Researchers take the advantage of the existing wireless links among mobile/smart devices (e.g., laptops, smartphones, smart thermostats, smart refrigerators and virtual assistance systems) by either extracting the ready-to-use signal measurements or adopting frequency modulated signals to detect the frequency shift. Due to the low-cost and non-intrusive sensing nature, wireless-based human activity sensing has drawn considerable attention and become a prominent research ﬁeld over the past decade. In this paper, we survey the existing wireless sensing systems in terms of their basic principles, techniques and system structures. Particularly, we describe how the wireless signals could be utilized to facilitate an array of applications including intrusion detection, room occupancy monitoring, daily activity recognition, gesture recognition, vital signs monitoring, user identiﬁcation and indoor localization. The future research directions and limitations of using wireless signals for human activity sensing are also discussed.},
	language = {en},
	number = {3},
	urldate = {2022-02-23},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Liu, Jian and Liu, Hongbo and Chen, Yingying and Wang, Yan and Wang, Chen},
	year = {2020},
	pages = {1629--1645},
	file = {Liu et al. - 2020 - Wireless Sensing for Human Activity A Survey.pdf:/home/simeon/Zotero/storage/VTPFIUSH/Liu et al. - 2020 - Wireless Sensing for Human Activity A Survey.pdf:application/pdf},
}

@article{kim_detection_2015,
	title = {Detection of {Eye} {Blinking} {Using} {Doppler} {Sensor} {With} {Principal} {Component} {Analysis}},
	volume = {14},
	issn = {1536-1225, 1548-5757},
	url = {http://ieeexplore.ieee.org/document/6899608/},
	doi = {10.1109/LAWP.2014.2357340},
	abstract = {We propose the detection of human eye blinking using a Doppler sensor. Eye blinking is one of the most common and convenient human activities that can be used as an input modality for computer devices, a simple communication methodology, and fatigue diagnostics. The reflected wave from the blinking eye has a unique Doppler signature. To investigate this signature, several measurements were performed with/without the noise caused by human movement when the sensor was placed near the eyes. We analyzed the Doppler signal in the joint time–frequency domain. It was found that the Doppler frequency produced by eye blinking is approximately 115 Hz. Further, unconscious and conscious eye blinking exhibited different Doppler characteristics. In order to classify these characteristics, we employed a principal component analysis to extract the features. The truncated eigenvectors were multiplied with an image of eye blinking, and the resulting coefficients were used for classification. The proposed method successfully differentiated conscious eye blinking in the presence of noise from human motion in diverse scenarios.},
	language = {en},
	urldate = {2022-02-23},
	journal = {IEEE Antennas and Wireless Propagation Letters},
	author = {Kim, Youngwook},
	year = {2015},
	pages = {123--126},
	file = {Kim - 2015 - Detection of Eye Blinking Using Doppler Sensor Wit.pdf:/home/simeon/Zotero/storage/ZRNYWH9J/Kim - 2015 - Detection of Eye Blinking Using Doppler Sensor Wit.pdf:application/pdf},
}

@incollection{miesenberger_acoustic_2008,
	address = {Berlin, Heidelberg},
	title = {An {Acoustic} {Framework} for {Detecting} {Fatigue} in {Speech} {Based} {Human}-{Computer}-{Interaction}},
	volume = {5105},
	isbn = {978-3-540-70539-0 978-3-540-70540-6},
	url = {http://link.springer.com/10.1007/978-3-540-70540-6_7},
	abstract = {This article describes a general framework for detecting accidentprone fatigue states based on prosody, articulation and speech quality related speech characteristics. The advantages of this real-time measurement approach are that obtaining speech data is non obtrusive, and free from sensor application and calibration efforts. The main part of the feature computation is the combination of frame level based speech features and high level contour descriptors resulting in over 8,500 features per speech sample. In general the measurement process follows the speech adapted steps of pattern recognition: (a) recording speech, (b) preprocessing (segmenting speech units of interest), (c) feature computation (using perceptual and signal processing related features, as e.g. fundamental frequency, intensity, pause patterns, formants, cepstral coefficients), (d) dimensionality reduction (filter and wrapper based feature subset selection, (un-)supervised feature transformation), (e) classification (e.g. SVM, K-NN classifier), and (f) evaluation (e.g. 10-fold cross validation). The validity of this approach is briefly discussed by summarizing the empirical results of a sleep deprivation study.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {Computers {Helping} {People} with {Special} {Needs}},
	publisher = {Springer Berlin Heidelberg},
	author = {Krajewski, Jarek and Wieland, Rainer and Batliner, Anton},
	editor = {Miesenberger, Klaus and Klaus, Joachim and Zagler, Wolfgang and Karshmer, Arthur},
	year = {2008},
	doi = {10.1007/978-3-540-70540-6_7},
	note = {ISSN: 0302-9743, 1611-3349
Series Title: Lecture Notes in Computer Science},
	pages = {54--61},
	file = {Krajewski et al. - 2008 - An Acoustic Framework for Detecting Fatigue in Spe.pdf:/home/simeon/Zotero/storage/WDSBWMLU/Krajewski et al. - 2008 - An Acoustic Framework for Detecting Fatigue in Spe.pdf:application/pdf},
}

@article{ed-doughmi_real-time_2020,
	title = {Real-{Time} {System} for {Driver} {Fatigue} {Detection} {Based} on a {Recurrent} {Neuronal} {Network}},
	volume = {6},
	issn = {2313-433X},
	url = {https://www.mdpi.com/2313-433X/6/3/8},
	doi = {10.3390/jimaging6030008},
	abstract = {In recent years, the rise of car accident fatalities has grown signiﬁcantly around the world. Hence, road security has become a global concern and a challenging problem that needs to be solved. The deaths caused by road accidents are still increasing and currently viewed as a signiﬁcant general medical issue. The most recent developments have made in advancing knowledge and scientiﬁc capacities of vehicles, enabling them to see and examine street situations to counteract mishaps and secure travelers. Therefore, the analysis of driver’s behaviors on the road has become one of the leading research subjects in recent years, particularly drowsiness, as it grants the most elevated factor of mishaps and is the primary source of death on roads. This paper presents a way to analyze and anticipate driver drowsiness by applying a Recurrent Neural Network over a sequence frame driver’s face. We used a dataset to shape and approve our model and implemented repetitive neural network architecture multi-layer model-based 3D Convolutional Networks to detect driver drowsiness. After a training session, we obtained a promising accuracy that approaches a 92\% acceptance rate, which made it possible to develop a real-time driver monitoring system to reduce road accidents.},
	language = {en},
	number = {3},
	urldate = {2022-02-23},
	journal = {Journal of Imaging},
	author = {Ed-Doughmi, Younes and Idrissi, Najlae and Hbali, Youssef},
	month = mar,
	year = {2020},
	pages = {8},
	file = {Ed-Doughmi et al. - 2020 - Real-Time System for Driver Fatigue Detection Base.pdf:/home/simeon/Zotero/storage/AAKFNV2N/Ed-Doughmi et al. - 2020 - Real-Time System for Driver Fatigue Detection Base.pdf:application/pdf},
}

@article{gurubhagavatula_guiding_2021,
	title = {Guiding principles for determining work shift duration and addressing the effects of work shift duration on performance, safety, and health: guidance from the {American} {Academy} of {Sleep} {Medicine} and the {Sleep} {Research} {Society}},
	volume = {17},
	issn = {1550-9389, 1550-9397},
	shorttitle = {Guiding principles for determining work shift duration and addressing the effects of work shift duration on performance, safety, and health},
	url = {http://jcsm.aasm.org/doi/10.5664/jcsm.9512},
	doi = {10.5664/jcsm.9512},
	language = {en},
	number = {11},
	urldate = {2022-02-23},
	journal = {Journal of Clinical Sleep Medicine},
	author = {Gurubhagavatula, Indira and Barger, Laura K. and Barnes, Christopher M. and Basner, Mathias and Boivin, Diane B. and Dawson, Drew and Drake, Christopher L. and Flynn-Evans, Erin E. and Mysliwiec, Vincent and Patterson, P. Daniel and Reid, Kathryn J. and Samuels, Charles and Shattuck, Nita Lewis and Kazmi, Uzma and Carandang, Gerard and Heald, Jonathan L. and Van Dongen, Hans P.A.},
	month = nov,
	year = {2021},
	pages = {2283--2306},
	file = {Gurubhagavatula et al. - 2021 - Guiding principles for determining work shift dura.pdf:/home/simeon/Zotero/storage/ID7SVKJR/Gurubhagavatula et al. - 2021 - Guiding principles for determining work shift dura.pdf:application/pdf},
}

@article{hu_driver_2009,
	title = {Driver drowsiness detection with eyelid related parameters by {Support} {Vector} {Machine}},
	volume = {36},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417408006714},
	doi = {10.1016/j.eswa.2008.09.030},
	abstract = {Various investigations show that drivers’ drowsiness is one of the main causes of trafﬁc accidents. Thus, countermeasure device is currently required in many ﬁelds for sleepiness related accident prevention. This paper intends to perform the drowsiness prediction by employing Support Vector Machine (SVM) with eyelid related parameters extracted from EOG data collected in a driving simulator provided by EU Project SENSATION. The dataset is ﬁrstly divided into three incremental drowsiness levels, and then a paired t-test is done to identify how the parameters are associated with drivers’ sleepy condition. With all the features, a SVM drowsiness detection model is constructed. The validation results show that the drowsiness detection accuracy is quite high especially when the subjects are very sleepy.},
	language = {en},
	number = {4},
	urldate = {2022-02-23},
	journal = {Expert Systems with Applications},
	author = {Hu, Shuyan and Zheng, Gangtie},
	month = may,
	year = {2009},
	pages = {7651--7658},
	file = {Hu and Zheng - 2009 - Driver drowsiness detection with eyelid related pa.pdf:/home/simeon/Zotero/storage/9X565L8N/Hu and Zheng - 2009 - Driver drowsiness detection with eyelid related pa.pdf:application/pdf},
}

@article{bergasa_weal-time_nodate,
	title = {Weal-{Time} {System} for {Monitoring} {Driver} {Vigilance}},
	abstract = {In this paper we present a non-intrusive prototype computer vision system for real-time monitoring driver’s vigilance.It is based on a hardware system,for real time acquisition of driver’s images using an active IR illuminator, and their sofiare implementation for monitoring some visual behaviours that characterize a driver’s level of vigilance. These are the eyelid movements and the pose face. The system has been tested with different sequences recorded on night and day driving conditions in a motorway and with different users. We show some experimental results and some conclusions about the perjormance of the system.},
	language = {en},
	author = {Bergasa, Luis M and Nuevo, Jesus and Sotelo, Miguel A and Vhzquez, Manuel},
	pages = {6},
	file = {Bergasa et al. - Weal-Time System for Monitoring Driver Vigilance.pdf:/home/simeon/Zotero/storage/T9EZAZ5R/Bergasa et al. - Weal-Time System for Monitoring Driver Vigilance.pdf:application/pdf},
}

@inproceedings{daza_drowsiness_2011,
	address = {Washington, DC, USA},
	title = {Drowsiness monitoring based on driver and driving data fusion},
	isbn = {978-1-4577-2197-7 978-1-4577-2198-4 978-1-4577-2196-0},
	url = {http://ieeexplore.ieee.org/document/6082907/},
	doi = {10.1109/ITSC.2011.6082907},
	abstract = {This paper presents a non-intrusive approach for monitoring driver drowsiness, based on driver and driving data fusion. The Percentage of Eye Closure (PERCLOS) is used to estimate the driver’s state. The PERCLOS is computed on real time using a stereo vision-based system. The driving information used is the lateral position, the steering wheel angle and the heading error provided by the CAN bus. These three signals have been studied in the time and frequency domain. A multilayer perceptron neural network has been trained to fetch an optimal performance score. This system was installed in a naturalistic driving simulator. For evaluation purposes, several experiments were designed by psychologists and carried out with professional drivers. As ground truth, subjective experts’ manual annotation of the driver video sequences and driving signals was used. A detection rate of 70\% using individual indicators was raised up to 94\% with the combination of indicators. An explanation about these results and some conclusion are presented.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {2011 14th {International} {IEEE} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE},
	author = {Daza, I. G. and Hernandez, N. and Bergasa, L. M. and Parra, I. and Yebes, J. J. and Gavilan, M. and Quintero, R. and Llorca, D. F. and Sotelo, M. A.},
	month = oct,
	year = {2011},
	pages = {1199--1204},
	file = {Daza et al. - 2011 - Drowsiness monitoring based on driver and driving .pdf:/home/simeon/Zotero/storage/6AWFUJPV/Daza et al. - 2011 - Drowsiness monitoring based on driver and driving .pdf:application/pdf},
}

@article{gorbach_intraoperative_2003,
	title = {Intraoperative infrared functional imaging of human brain},
	volume = {54},
	issn = {0364-5134, 1531-8249},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ana.10646},
	doi = {10.1002/ana.10646},
	language = {en},
	number = {3},
	urldate = {2022-02-23},
	journal = {Annals of Neurology},
	author = {Gorbach, Alexander M. and Heiss, John and Kufta, Conrad and Sato, Susumo and Fedio, Paul and Kammerer, William A. and Solomon, Jeffrey and Oldfield, Edward H.},
	month = sep,
	year = {2003},
	pages = {297--309},
	file = {Gorbach et al. - 2003 - Intraoperative infrared functional imaging of huma.pdf:/home/simeon/Zotero/storage/MAAQDUWZ/Gorbach et al. - 2003 - Intraoperative infrared functional imaging of huma.pdf:application/pdf},
}

@article{haque_facial_2016,
	title = {Facial video‐based detection of physical fatigue for maximal muscle activity},
	volume = {10},
	issn = {1751-9640, 1751-9640},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2015.0215},
	doi = {10.1049/iet-cvi.2015.0215},
	abstract = {Physical fatigue reveals the health condition of a person at, for example, health checkup, fitness assessment, or rehabilitation training. This study presents an efficient non-contact system for detecting non-localised physical fatigue from maximal muscle activity using facial videos acquired in a realistic environment with natural lighting where subjects were allowed to voluntarily move their head, change their facial expression, and vary their pose. The proposed method utilises a facial feature point tracking method by combining a ‘good feature to track’ and a ‘supervised descent method’ to address the challenges that originate from realistic scenario. A face quality assessment system was also incorporated in the proposed system to reduce erroneous results by discarding low quality faces that occurred in a video sequence due to problems in realistic lighting, head motion, and pose variation. Experimental results show that the proposed system outperforms video-based existing system for physical fatigue detection.},
	language = {en},
	number = {4},
	urldate = {2022-02-23},
	journal = {IET Computer Vision},
	author = {Haque, Mohammad A. and Irani, Ramin and Nasrollahi, Kamal and Moeslund, Thomas B.},
	month = jun,
	year = {2016},
	pages = {323--330},
	file = {Haque et al. - 2016 - Facial video‐based detection of physical fatigue f.pdf:/home/simeon/Zotero/storage/89ISIPM7/Haque et al. - 2016 - Facial video‐based detection of physical fatigue f.pdf:application/pdf},
}

@article{rosler_reducing_2021,
	title = {Reducing {Videoconferencing} {Fatigue} through {Facial} {Emotion} {Recognition}},
	volume = {13},
	issn = {1999-5903},
	url = {https://www.mdpi.com/1999-5903/13/5/126},
	doi = {10.3390/fi13050126},
	abstract = {In the last 14 months, COVID-19 made face-to-face meetings impossible and this has led to rapid growth in videoconferencing. As highly social creatures, humans strive for direct interpersonal interaction, which means that in most of these video meetings the webcam is switched on and people are “looking each other in the eyes”. However, it is far from clear what the psychological consequences of this shift to virtual face-to-face communication are and if there are methods to alleviate “videoconferencing fatigue”. We have studied the inﬂuence of emotions of meeting participants on the perceived outcome of video meetings. Our experimental setting consisted of 35 participants collaborating in eight teams over Zoom in a one semester course on Collaborative Innovation Networks in bi-weekly video meetings, where each team presented its progress. Emotion was tracked through Zoom face video snapshots using facial emotion recognition that recognized six emotions (happy, sad, fear, anger, neutral, and surprise). Our dependent variable was a score given after each presentation by all participants except the presenter. We found that the happier the speaker is, the happier and less neutral the audience is. More importantly, we found that the presentations that triggered wide swings in “fear” and “joy” among the participants are correlated with a higher rating. Our ﬁndings provide valuable input for online video presenters on how to conduct better and less tiring meetings; this will lead to a decrease in “videoconferencing fatigue”.},
	language = {en},
	number = {5},
	urldate = {2022-02-23},
	journal = {Future Internet},
	author = {Rößler, Jannik and Sun, Jiachen and Gloor, Peter},
	month = may,
	year = {2021},
	pages = {126},
	file = {Rößler et al. - 2021 - Reducing Videoconferencing Fatigue through Facial .pdf:/home/simeon/Zotero/storage/LYFBEUWX/Rößler et al. - 2021 - Reducing Videoconferencing Fatigue through Facial .pdf:application/pdf},
}

@article{pattyn_bridging_2018,
	title = {Bridging {Exercise} {Science}, {Cognitive} {Psychology}, and {Medical} {Practice}: {Is} “{Cognitive} {Fatigue}” a {Remake} of “{The} {Emperor}’s {New} {Clothes}”?},
	volume = {9},
	issn = {1664-1078},
	shorttitle = {Bridging {Exercise} {Science}, {Cognitive} {Psychology}, and {Medical} {Practice}},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.01246/full},
	doi = {10.3389/fpsyg.2018.01246},
	abstract = {Fatigue is such a multifaceted construct it has sprouted speciﬁc research ﬁelds and experts in domains as different as exercise physiology, cognitive psychology, human factors and engineering, and medical practice. It lacks a consensus deﬁnition: it is an experimental concept, a symptom, a risk, a cause (e.g., of performance decrement) and a consequence (e.g., of sleep deprivation). This fragmentation of knowledge leads to slower dissemination of novel insights, and thus to a poorer research. Indeed, what may seem as a novel result in one ﬁeld, may very well be old news in another, hence leading to this “innovation” being a scientiﬁc equivalent to the emperor’s new clothes. The current paper aims to describe the common denominator in the different areas of expertise where fatigue is investigated. Indeed, rather than focusing on the differences in semantics and conceptualization, we hope that identifying common concepts may be inductive of easier multidisciplinary research. Considering the vastness of fatigue research in all areas identiﬁed as relevant-cognitive science, exercise physiology, and medical practice, this analysis has not the ambition to be an exhaustive review in all domains. We have reviewed the fatigue concepts and research in these areas and report the ones that are used to describe the proposed common model to be further investigated. The most promising common feature to cognitive science, exercise physiology and clinical practice is the notion of “perceived effort.” This allows to account for interindividual differences, as well as for the situational variations in fatigue. It is applicable to both mental and physical constructs. It integrates motivational and emotional dimensions. It overcomes current polemics in various research ﬁelds, and it does not draw on any semantic ambiguity. We thus suggest a new model of fatigue and performance, whether this performance is mental or physical; and whether it is in a clinical range or relates to optimal functioning.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Frontiers in Psychology},
	author = {Pattyn, Nathalie and Van Cutsem, Jeroen and Dessy, Emilie and Mairesse, Olivier},
	month = sep,
	year = {2018},
	pages = {1246},
	file = {Pattyn et al. - 2018 - Bridging Exercise Science, Cognitive Psychology, a.pdf:/home/simeon/Zotero/storage/MSPTSDG2/Pattyn et al. - 2018 - Bridging Exercise Science, Cognitive Psychology, a.pdf:application/pdf},
}

@article{andre_integrative_2019,
	title = {An {Integrative} {Model} of {Effortful} {Control}},
	volume = {13},
	issn = {1662-5137},
	url = {https://www.frontiersin.org/article/10.3389/fnsys.2019.00079/full},
	doi = {10.3389/fnsys.2019.00079},
	language = {en},
	urldate = {2022-02-23},
	journal = {Frontiers in Systems Neuroscience},
	author = {André, Nathalie and Audiffren, Michel and Baumeister, Roy F.},
	month = dec,
	year = {2019},
	pages = {79},
	file = {André et al. - 2019 - An Integrative Model of Effortful Control.pdf:/home/simeon/Zotero/storage/NBTHY5V4/André et al. - 2019 - An Integrative Model of Effortful Control.pdf:application/pdf},
}

@article{guo_evaluation_2018,
	title = {Evaluation of {Teaching} {Effectiveness} based on {Classroom} {Micro}-{Expression} {Recognition}},
	url = {http://www.ijpe-online.com/EN/10.23940/ijpe.18.11.p33.28772885},
	doi = {10.23940/ijpe.18.11.p33.28772885},
	abstract = {The improvement of teaching quality has been a persistent theme in education. To improve the quality of teaching in the classroom, teachers need to interact with students, pay attention to each student’s emotional changes, and closely follow each student’s changes in learning status, so as to make effective adjustments for teaching content. However, students’ responses often cannot be captured in time due to the limitations of the teacher in the classroom. Advances in computer and Internet technology as well as the development and maturation of image processing and artificial intelligence have provided technical support for the evaluation system of facial expression recognition in intelligent classrooms. In this paper, we propose an effective method to evaluate teaching effectiveness based on facial micro-expression recognition. An evaluation system is also designed and realized based on analyzing the change of classroom microexpressions and the concentration of students. In such an evaluation system, face detection, tracking, and micro-expression recognition technology are applied to analyze the emotional changes during the learning process. Then students’ attention in class will be timely fed back to teachers, which can help teachers adjust teaching methods and strategies in a timely manner to improve teaching quality. In an informational teaching environment with general monitoring equipment, our proposed system can automatically track and analyze the degree of student’s concentration in the teaching process. Furthermore, it can also track the specified objects and analyze the change of their learning status in a certain period of time, which can help teachers conduct expediently multi-dimensional evaluation and guidance.},
	language = {en},
	urldate = {2022-02-23},
	journal = {International Journal of Performability Engineering},
	author = {Guo, Xiaoxu},
	year = {2018},
	file = {Guo - 2018 - Evaluation of Teaching Effectiveness based on Clas.pdf:/home/simeon/Zotero/storage/JI63LVPT/Guo - 2018 - Evaluation of Teaching Effectiveness based on Clas.pdf:application/pdf},
}

@inproceedings{greeley_detecting_2006,
	address = {Vancouver, BC, Canada},
	title = {Detecting {Fatigue} {From} {Voice} {Using} {Speech} {Recognition}},
	isbn = {978-0-7803-9754-5 978-0-7803-9753-8},
	url = {http://ieeexplore.ieee.org/document/4042307/},
	doi = {10.1109/ISSPIT.2006.270865},
	abstract = {Military and civilian experience has shown that longduration assignments present increased risk of performance failures as the mission progresses. This is due to interruption of normal sleep cycles and psychological pressures of the work environment. There continues to be a need for a non-intrusive fatigue assessment system to successfully monitor the level of alertness of personnel during critical missions and activities. Experimental results on human voice show that specific phones have a predictable dependence on fatigue. Hence, precise phonetic identification and alignment are important to voice-based fatigue detection. This paper explores techniques for detecting fatigue from voice using speech recognition to obtain phonetic alignments. A confidence measure was used to filter out less likely word hypotheses from the ASR’s output. In this paper we restricted our analysis to dealing with out-of-vocabulary words. The results obtained from voice show strong correlation with other standardized tests such as Sleep Onset Latency and Sleep, Activity, Fatigue, and Task Effectiveness.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {2006 {IEEE} {International} {Symposium} on {Signal} {Processing} and {Information} {Technology}},
	publisher = {IEEE},
	author = {Greeley, H.P. and Friets, E. and Wilson, J.P. and Raghavan, S. and Picone, J. and Berg, J.},
	month = aug,
	year = {2006},
	pages = {567--571},
	file = {Greeley et al. - 2006 - Detecting Fatigue From Voice Using Speech Recognit.pdf:/home/simeon/Zotero/storage/W2M53YXM/Greeley et al. - 2006 - Detecting Fatigue From Voice Using Speech Recognit.pdf:application/pdf},
}

@article{abdelrahman_cognitive_2017,
	title = {Cognitive {Heat}: {Exploring} the {Usage} of {Thermal} {Imaging} to {Unobtrusively} {Estimate} {Cognitive} {Load}},
	volume = {1},
	issn = {2474-9567},
	shorttitle = {Cognitive {Heat}},
	url = {https://dl.acm.org/doi/10.1145/3130898},
	doi = {10.1145/3130898},
	language = {en},
	number = {3},
	urldate = {2022-02-23},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Abdelrahman, Yomna and Velloso, Eduardo and Dingler, Tilman and Schmidt, Albrecht and Vetere, Frank},
	month = sep,
	year = {2017},
	pages = {1--20},
	file = {Abdelrahman et al. - 2017 - Cognitive Heat Exploring the Usage of Thermal Ima.pdf:/home/simeon/Zotero/storage/PV4P6DIS/Abdelrahman et al. - 2017 - Cognitive Heat Exploring the Usage of Thermal Ima.pdf:application/pdf},
}

@inproceedings{chen_construction_2017,
	address = {Penang, Malaysia},
	title = {Construction of corpus for learning fatigue detection from speech},
	isbn = {978-1-5090-1184-1},
	url = {http://ieeexplore.ieee.org/document/8064953/},
	doi = {10.1109/CSPA.2017.8064953},
	abstract = {Fatigue, which belongs to human body's natural response and self-regulation for protection, is a complex physiological and mental phenomena. In recent years, a large amount of researchers from both speech signal processing and machine learning domains have already proved that fatigue detection from speech can be carried out automatically. However, the main researches concentrate on driving fatigue detection which contribute for people under work force. Besides, no one pay attention to students in school regardless of the truth of that learning fatigue is becoming more and more indispensable for its positive significance in students' school life experience, the efficiency of learning, even their physical and mental health. Although there are many methods to detect fatigue, detection from speech is a more convenient assumption. So, the corpus is the foundation of researches in detecting learning fatigue from speech. While there are several corpora about fatigue detection, few of them focus on learning fatigue (which is mainly caused by brain activities) and proving the authority and reliability of these corpora. In this paper, we construct the Soochow University Speech Processing Researches-Learning Fatigue Detection (SUSP-LFD) corpus to implement learning fatigue detection from speech. In order to solve the issues among existing corpora, we use heart rate and mean arterial blood pressure to evaluate our corpus. We first describe the construction approach in detail, and then we verify and evaluate the applicability of the corpus.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {2017 {IEEE} 13th {International} {Colloquium} on {Signal} {Processing} \& its {Applications} ({CSPA})},
	publisher = {IEEE},
	author = {Chen, Shuxi and Zhao, Heming and Chen, Xueqin},
	month = mar,
	year = {2017},
	pages = {214--218},
	file = {Chen et al. - 2017 - Construction of corpus for learning fatigue detect.pdf:/home/simeon/Zotero/storage/FULWRM75/Chen et al. - 2017 - Construction of corpus for learning fatigue detect.pdf:application/pdf},
}

@article{kumar_distanceppg_2015,
	title = {{DistancePPG}: {Robust} non-contact vital signs monitoring using a camera},
	volume = {6},
	issn = {2156-7085, 2156-7085},
	shorttitle = {{DistancePPG}},
	url = {https://opg.optica.org/abstract.cfm?URI=boe-6-5-1565},
	doi = {10.1364/BOE.6.001565},
	abstract = {Vital signs such as pulse rate and breathing rate are currently measured using contact probes. But, non-contact methods for measuring vital signs are desirable both in hospital settings (e.g. in NICU) and for ubiquitous in-situ health tracking (e.g. on mobile phone and computers with webcams). Recently, camera-based non-contact vital sign monitoring have been shown to be feasible. However, camera-based vital sign monitoring is challenging for people with darker skin tone, under low lighting conditions, and/or during movement of an individual in front of the camera. In this paper, we propose distancePPG, a new camera-based vital sign estimation algorithm which addresses these challenges. DistancePPG proposes a new method of combining skin-color change signals from different tracked regions of the face using a weighted average, where the weights depend on the blood perfusion and incident light intensity in the region, to improve the signal-to-noise ratio (SNR) of camera-based estimate. One of our key contributions is a new automatic method for determining the weights based only on the video recording of the subject. The gains in SNR of camera-based PPG estimated using distancePPG translate into reduction of the error in vital sign estimation, and thus expand the scope of camera-based vital sign monitoring to potentially challenging scenarios. Further, a dataset will be released, comprising of synchronized video recordings of face and pulse oximeter based ground truth recordings from the earlobe for people with different skin tones, under different lighting conditions and for various motion scenarios.},
	language = {en},
	number = {5},
	urldate = {2022-02-23},
	journal = {Biomedical Optics Express},
	author = {Kumar, Mayank and Veeraraghavan, Ashok and Sabharwal, Ashutosh},
	month = may,
	year = {2015},
	pages = {1565},
	file = {Kumar et al. - 2015 - DistancePPG Robust non-contact vital signs monito.pdf:/home/simeon/Zotero/storage/KSSAG6SV/Kumar et al. - 2015 - DistancePPG Robust non-contact vital signs monito.pdf:application/pdf},
}

@article{ren_noncontact_nodate,
	title = {Noncontact {Heartbeat} {Detection} using {UWB} {Impulse} {Doppler} {Radar}},
	abstract = {Ultra-wide band (UWB) pulse Doppler radars provide range-time-frequency information which enables the target localization and vital sign monitoring of a subject. One challenge for UWB radar systems is accurately detecting the heartbeat of a subject, i.e. recording the small displacements of thorax caused by heartbeat due to its poor S/N ratio. Given that the phase-based algorithms are more robust against noise in heartbeat detection so it could lead to better demodulation of micro displacements. In this paper, two algorithms based on complex signal demodulation and arctangent method are extended here to UWB radars to detect the phase variation of reflected pulses caused by cardiac motions, results will be presented.},
	language = {en},
	author = {Ren, Lingyun and Koo, Yun Seo and Wang, Yazhou and Fathy, Aly E},
	pages = {3},
	file = {Ren et al. - Noncontact Heartbeat Detection using UWB Impulse D.pdf:/home/simeon/Zotero/storage/KLMPKSWH/Ren et al. - Noncontact Heartbeat Detection using UWB Impulse D.pdf:application/pdf},
}

@article{lin_microwave_1992,
	title = {Microwave sensing of physiological movement and volume change: {A} review},
	volume = {13},
	issn = {0197-8462, 1521-186X},
	shorttitle = {Microwave sensing of physiological movement and volume change},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bem.2250130610},
	doi = {10.1002/bem.2250130610},
	language = {en},
	number = {6},
	urldate = {2022-02-23},
	journal = {Bioelectromagnetics},
	author = {Lin, James C.},
	year = {1992},
	pages = {557--565},
	file = {Lin - 1992 - Microwave sensing of physiological movement and vo.pdf:/home/simeon/Zotero/storage/X6RIX9NB/Lin - 1992 - Microwave sensing of physiological movement and vo.pdf:application/pdf},
}

@incollection{jawahar_universal_2019,
	address = {Cham},
	title = {Universal {Bounding} {Box} {Regression} and {Its} {Applications}},
	volume = {11366},
	isbn = {978-3-030-20875-2 978-3-030-20876-9},
	url = {http://link.springer.com/10.1007/978-3-030-20876-9_24},
	abstract = {Bounding-box regression is a popular technique to reﬁne or predict localization boxes in recent object detection approaches. Typically, bounding-box regressors are trained to regress from either region proposals or ﬁxed anchor boxes to nearby bounding boxes of a pre-deﬁned target object classes. This paper investigates whether the technique is generalizable to unseen classes and is transferable to other tasks beyond supervised object detection. To this end, we propose a class-agnostic and anchor-free box regressor, dubbed Universal Bounding-Box Regressor (UBBR), which predicts a bounding box of the nearest object from any given box. Trained on a relatively small set of annotated images, UBBR successfully generalizes to unseen classes, and can be used to improve localization in many vision problems. We demonstrate its eﬀectivenss on weakly supervised object detection and object discovery.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {Computer {Vision} – {ACCV} 2018},
	publisher = {Springer International Publishing},
	author = {Lee, Seungkwan and Kwak, Suha and Cho, Minsu},
	editor = {Jawahar, C.V. and Li, Hongdong and Mori, Greg and Schindler, Konrad},
	year = {2019},
	doi = {10.1007/978-3-030-20876-9_24},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {373--387},
	file = {Lee et al. - 2019 - Universal Bounding Box Regression and Its Applicat.pdf:/home/simeon/Zotero/storage/R4RRNNP4/Lee et al. - 2019 - Universal Bounding Box Regression and Its Applicat.pdf:application/pdf},
}

@article{viola_robust_2003,
	title = {Robust {Real}-{Time} {Face} {Detection}},
	abstract = {This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The ﬁrst is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efﬁcient classiﬁer which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classiﬁers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
	language = {en},
	author = {Viola, Paul and Jones, Michael J},
	month = jun,
	year = {2003},
	pages = {19},
	file = {Viola and Jones - Robust Real-Time Face Detection.pdf:/home/simeon/Zotero/storage/V5QD2HVL/Viola and Jones - Robust Real-Time Face Detection.pdf:application/pdf},
}

@article{obeid_doppler_2011,
	title = {Doppler {Radar} for {Heartbeat} {Rate} and {Heart} {Rate} {Variability} {Extraction}},
	abstract = {This paper presents a Doppler radar system used to detect the heartbeat signal from a d√istance of one meter. The proposed system is based on using a vector network analyzer and two antennas. Measurements are performed at 16 GHz for different power levels between 0 and -25 dBm. Both heartbeat rate and heart rate variability are extracted and compared to a simultaneous ECG signal.},
	language = {en},
	author = {Obeid, Dany and Sadek, Sawsan and Zaharia, Gheorghe and Zein, Ghaïs El},
	year = {2011},
	pages = {5},
	file = {Obeid et al. - 2011 - Doppler Radar for Heartbeat Rate and Heart Rate Va.pdf:/home/simeon/Zotero/storage/K55FUJGE/Obeid et al. - 2011 - Doppler Radar for Heartbeat Rate and Heart Rate Va.pdf:application/pdf},
}

@article{yan_high-efficiency_2021,
	title = {A {High}-{Efficiency} {Fatigued} {Speech} {Feature} {Selection} {Method} for {Air} {Traffic} {Controllers} {Based} on {Improved} {Compressed} {Sensing}},
	volume = {2021},
	issn = {2040-2309, 2040-2295},
	url = {https://www.hindawi.com/journals/jhe/2021/2292710/},
	doi = {10.1155/2021/2292710},
	abstract = {Air traffic controller fatigue has recently received considerable attention from researchers because it is one of the main causes of air traffic incidents. Numerous research studies have been conducted to extract speech features related to fatigue, and their practical utilization has achieved some positive detection results. However, there are still challenges associated with the applied speech features usually being of high dimension, which leads to computational complexity and inefficient fatigue detection. This situation makes it meaningful to reduce the dimensionality and select only a few efficient features. This paper addresses these problems by proposing a high-efficiency fatigued speech selection method based on improved compressed sensing. For adapting a method to the specific field of fatigued speech, we propose an improved compressed sensing construction algorithm to decrease the reconstruction error and achieve superior sparse coding. The proposed feature selection method is then applied to optimize the high-dimension fatigued speech features based on the fractal dimension. Finally, a support vector machine classifier is applied to a series of comparative experiments using the Civil Aviation Administration of China radiotelephony corpus to demonstrate that the proposed method provides a significant improvement in the precision of fatigue detection compared with current state-of-the-art approaches.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Journal of Healthcare Engineering},
	author = {Yan, Yonggang and Mao, Yi and Shen, Zhiyuan and Wei, Yitao and Pan, Guozhuang and Zhu, Jinfu},
	editor = {Lin, Qiu-Hua},
	month = sep,
	year = {2021},
	pages = {1--10},
	file = {Yan et al. - 2021 - A High-Efficiency Fatigued Speech Feature Selectio.pdf:/home/simeon/Zotero/storage/WFTGA3Y7/Yan et al. - 2021 - A High-Efficiency Fatigued Speech Feature Selectio.pdf:application/pdf},
}

@inproceedings{colbert_thermal_2014,
	address = {Baltimore, Maryland, USA},
	title = {Thermal camera used for the assessment of metabolism and functions of the rat brain},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2049807},
	doi = {10.1117/12.2049807},
	abstract = {Motivation to undertake research on brain surface temperature in clinical practice is based on a strong conviction that the enormous progress in thermal imaging techniques and camera design has a great application potential. Intraoperative imaging of pathological changes and functionally important areas of the brain is not yet fully resolved in neurosurgery and remains a challenge. Extensive knowledge of the complex mechanisms controlling homeostasis (thermodynamic status of an organism being a part of it ) and laws of physics (which are the foundations of thermography), make this method very good and a simple imaging tool in comparison with other modern techniques, such as computed tomography, magnetic resonance imaging and angiography. Measurements of temperature distribution across the brain surface were performed on four rats (Wistar strain) weighing approximately 300 g each. Animals have remained under general anesthesia typically conducted using isoflurane. The brain was unveiled (the dura mater remained untouched) through the skin incision and removal of the bone cranial vault. Cerebrocortical microflow was measured using laser-Doppler flow meter. Arterial blood pressure was also measured in rat femoral artery. From the above data the cerebrovascular resistance index was calculated. Cerebral flow was modified by increasing the CO2 concentration in the inspired air to 5\% for the duration of 6 minutes. Another change in cerebral flow was induced by periodic closing of right middle cerebral artery. Artery occlusion was performed by introducing a filament for a period of 15 minutes, then an artery was opened again. Measurements were carried out before, during and after the artery occlusion. Paper presents results and methodology of measurements.},
	language = {en},
	urldate = {2022-02-23},
	author = {Kastek, Mariusz and Piatkowski, Tadeusz and Polakowski, Henryk and Kaczmarska, Katarzyna and Czernicki, Zbigniew and Koźniewska, Ewa and Przykaza, Lukasz},
	editor = {Colbert, Fred P. and Hsieh, Sheng-Jen (Tony)},
	month = may,
	year = {2014},
	pages = {910507},
	file = {Kastek et al. - 2014 - Thermal camera used for the assessment of metaboli.pdf:/home/simeon/Zotero/storage/R6CKML9M/Kastek et al. - 2014 - Thermal camera used for the assessment of metaboli.pdf:application/pdf},
}

@inproceedings{borza_automatic_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Automatic {Skin} {Tone} {Extraction} for {Visagism} {Applications}:},
	isbn = {978-989-758-290-5},
	shorttitle = {Automatic {Skin} {Tone} {Extraction} for {Visagism} {Applications}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006711104660473},
	doi = {10.5220/0006711104660473},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {Proceedings of the 13th {International} {Joint} {Conference} on {Computer} {Vision}, {Imaging} and {Computer} {Graphics} {Theory} and {Applications}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Borza, Diana and Darabant, Adrian and Danescu, Radu},
	year = {2018},
	pages = {466--473},
	file = {Borza et al. - 2018 - Automatic Skin Tone Extraction for Visagism Applic.pdf:/home/simeon/Zotero/storage/W3IC9Z7Z/Borza et al. - 2018 - Automatic Skin Tone Extraction for Visagism Applic.pdf:application/pdf},
}

@article{shen_respiration_2018,
	title = {Respiration and {Heartbeat} {Rates} {Measurement} {Based} on {Autocorrelation} {Using} {IR}-{UWB} {Radar}},
	volume = {65},
	issn = {1549-7747, 1558-3791},
	url = {https://ieeexplore.ieee.org/document/8421066/},
	doi = {10.1109/TCSII.2018.2860015},
	abstract = {Respiration rate (RR) and heartbeat rate (HR) are important physiological parameters for a person. Impulse radio ultra-wideband (IR-UWB) is a promising technology for noncontact sensing and monitoring. This brief presents a new method based on autocorrelation to measure the RR and HR using IRUWB radar. The correlation coefﬁcient waveform contains the vital sign signals, overcoming the effect of noise and clutter. Applying fast Fourier transform, the respiration frequency can be acquired easily. A clever method also based on autocorrelation is proposed to locate the subject. The receive signal matrix is divided into a set of bins in the direction of fast time. By removing one block from the matrix each time and re-applying the autocorrelation, the removed block resulting the smallest correlations is corresponding to the location of a subject. Moreover, variational mode decomposition algorithm is adopted to successfully separate the respiration and heartbeat signals. Experiments are carried out using a PulsOn410 UWB radar. The results show that the proposed low-complexity algorithm has high accuracy.},
	language = {en},
	number = {10},
	urldate = {2022-02-23},
	journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
	author = {Shen, Hongming and Xu, Chen and Yang, Yongjie and Sun, Ling and Cai, Zhitian and Bai, Lin and Clancy, Edward and Huang, Xinming},
	month = oct,
	year = {2018},
	pages = {1470--1474},
	file = {Shen et al. - 2018 - Respiration and Heartbeat Rates Measurement Based .pdf:/home/simeon/Zotero/storage/RT59W447/Shen et al. - 2018 - Respiration and Heartbeat Rates Measurement Based .pdf:application/pdf},
}

@inproceedings{happy_automated_2013,
	address = {Kharagpur, India},
	title = {Automated {Alertness} and {Emotion} {Detection} for {Empathic} {Feedback} during e-{Learning}},
	isbn = {978-0-7695-5141-8},
	url = {http://ieeexplore.ieee.org/document/6751058/},
	doi = {10.1109/T4E.2013.19},
	abstract = {In the context of education technology, empathic interaction with the user and feedback by the learning system using multiple inputs such as video, voice and text inputs is an important area of research. In this paper, a non-intrusive, standalone model for intelligent assessment of alertness and emotional state as well as generation of appropriate feedback has been proposed. Using the non-intrusive visual cues, the system classifies emotion and alertness state of the user, and provides appropriate feedback according to the detected cognitive state using facial expressions, ocular parameters, postures, and gestures. Assessment of alertness level using ocular parameters such as PERCLOS and saccadic parameters, emotional state from facial expression analysis, and detection of both relevant cognitive and emotional states from upper body gestures and postures has been proposed. Integration of such a system in e-learning environment is expected to enhance students’ performance through interaction, feedback, and positive mood induction.},
	language = {en},
	urldate = {2022-02-23},
	booktitle = {2013 {IEEE} {Fifth} {International} {Conference} on {Technology} for {Education} (t4e 2013)},
	publisher = {IEEE},
	author = {Happy, S. L. and Dasgupta, Anirban and Patnaik, Priyadarshi and Routray, Aurobinda},
	month = dec,
	year = {2013},
	pages = {47--50},
	file = {Happy et al. - 2013 - Automated Alertness and Emotion Detection for Empa.pdf:/home/simeon/Zotero/storage/NDHFJSDE/Happy et al. - 2013 - Automated Alertness and Emotion Detection for Empa.pdf:application/pdf},
}

@article{lazaro_analysis_2010,
	title = {{ANALYSIS} {OF} {VITAL} {SIGNS} {MONITORING} {USING} {AN} {IR}-{UWB} {RADAR}},
	volume = {100},
	issn = {1559-8985},
	url = {http://www.jpier.org/PIER/pier.php?paper=09120302},
	doi = {10.2528/PIER09120302},
	abstract = {Ultra-wide Band (UWB) technology is a new, useful and safe technology in the ﬁeld of wireless body networks. This paper focuses on the feasibility of estimating vital signs — speciﬁcally breathing rate and heartbeat frequency — from the spectrum of recorded waveforms, using an impulse-radio (IR) UWB radar. To this end, an analytical model is developed to perform and interpret the spectral analysis. Both the harmonics and the intermodulation between respiration and heart signals are addressed. Simulations have been performed to demonstrate how they aﬀect the detection of vital signs and also to analyze the inﬂuence of the pulse waveform. A ﬁlter to cancel out breathing harmonics is also proposed to improve heart rate detection. The results of the experiments are presented under diﬀerent scenarios which demonstrate the accuracy of the proposed technique for determining respiration and heartbeat rates. It has been shown that an IR-UWB radar can meet the requirements of typical biomedical applications such as non-invasive heart and respiration rate monitoring.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Progress In Electromagnetics Research},
	author = {Lazaro, Antonio and Girbau, David and Villarino, Ramon},
	year = {2010},
	pages = {265--284},
	file = {Lazaro et al. - 2010 - ANALYSIS OF VITAL SIGNS MONITORING USING AN IR-UWB.pdf:/home/simeon/Zotero/storage/TRDDHQIB/Lazaro et al. - 2010 - ANALYSIS OF VITAL SIGNS MONITORING USING AN IR-UWB.pdf:application/pdf},
}

@article{liu_vital_2019,
	title = {Vital {Signs} {Monitoring} with {RFID}: {Opportunities} and {Challenges}},
	volume = {33},
	issn = {0890-8044, 1558-156X},
	shorttitle = {Vital {Signs} {Monitoring} with {RFID}},
	url = {https://ieeexplore.ieee.org/document/8782887/},
	doi = {10.1109/MNET.2019.1800014},
	abstract = {Vital signs monitoring plays an important role in health assessing, especially for elderly healthcare. Traditional vital signs monitoring systems are intrusive. They require the users to wear or attach dedicated sensors and thus are inconvenient to use. Although recently developed contactless vital signs monitoring approaches (e.g., those based on WiFi sensing) become friendly, they cannot differentiate multiple target users. This article envisions the opportunity of utilizing the radio frequency identification (RFID) technology to perform accurate vital signs monitoring, which can combine the merit of contactless convenience as well as the advantage in distinguishing different users. We introduce the basic ideas of using RFID to perform vital signs monitoring and discuss the challenges to be addressed before the ideas can be put into practice. With commodity RFID devices, we implement a breath monitoring prototype that can accurately monitor the user’s breath even when the user is moving. The prototype achieves over 97 percent accuracy in estimating breath rate and below 8 percent error in estimating individual breath length.},
	language = {en},
	number = {4},
	urldate = {2022-02-23},
	journal = {IEEE Network},
	author = {Liu, Xuan and Yin, Jiangjin and Liu, Yangyang and Zhang, Shigeng and Guo, Song and Wang, Kun},
	month = jul,
	year = {2019},
	pages = {126--132},
	file = {Liu et al. - 2019 - Vital Signs Monitoring with RFID Opportunities an.pdf:/home/simeon/Zotero/storage/8Y5M6QYW/Liu et al. - 2019 - Vital Signs Monitoring with RFID Opportunities an.pdf:application/pdf},
}

@article{tarnowski_emotion_2017,
	title = {Emotion recognition using facial expressions},
	volume = {108},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050917305264},
	doi = {10.1016/j.procs.2017.05.025},
	language = {en},
	urldate = {2022-02-23},
	journal = {Procedia Computer Science},
	author = {Tarnowski, Paweł and Kołodziej, Marcin and Majkowski, Andrzej and Rak, Remigiusz J.},
	year = {2017},
	pages = {1175--1184},
	file = {Tarnowski et al. - 2017 - Emotion recognition using facial expressions.pdf:/home/simeon/Zotero/storage/3D442KYU/Tarnowski et al. - 2017 - Emotion recognition using facial expressions.pdf:application/pdf},
}

@article{ye_identification_2022,
	title = {Identification of mental fatigue levels in a language understanding task based on multi-domain {EEG} features and an ensemble convolutional neural network},
	volume = {72},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809421009575},
	doi = {10.1016/j.bspc.2021.103360},
	abstract = {In this paper, electroencephalogram (EEG) is used to assess mental fatigue of operators in a human-computer system aiming at preventing increasing risk of human operator performance degradation. We present an experimental design for fatigue identification in a language understanding task. The EEG signals of 14 channels from 15 healthy participants were collected via a wireless brain computer interface device to indicate instan­ taneous fatigue level. By extracting EEG features as temporal statistics, power spectral density and entropy in­ dicators, we build four different spatial feature maps that restructure feature vectors. Further, a bootstrapaggregating ensemble convolutional neural network of multi-domain features (ensCNN-MD) is proposed to improve the fatigue recognition accuracy. By examining seven different feature combinations, ensCNN-MD is significantly superior to classical shallow and deep classifiers. The highest classification accuracy under participant-specific training and testing paradigm is achieved at 87.69\%. The results demonstrate both the effectiveness of experimental design and the ensCNN-MD of learning high-level spatial feature abstractions related to mental fatigue variations.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Biomedical Signal Processing and Control},
	author = {Ye, Chunhua and Yin, Zhong and Zhao, Mengyuan and Tian, Ying and Sun, Zhanquan},
	month = feb,
	year = {2022},
	pages = {103360},
	file = {Ye et al. - 2022 - Identification of mental fatigue levels in a langu.pdf:/home/simeon/Zotero/storage/BS5DGRPL/Ye et al. - 2022 - Identification of mental fatigue levels in a langu.pdf:application/pdf},
}

@article{wang_multiple_2020,
	title = {Multiple nonlinear features fusion based driving fatigue detection},
	volume = {62},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809420302317},
	doi = {10.1016/j.bspc.2020.102075},
	language = {en},
	urldate = {2022-02-23},
	journal = {Biomedical Signal Processing and Control},
	author = {Wang, Fei and Wu, Shichao and Zhang, Weiwei and Xu, Zongfeng and Zhang, Yahui and Chu, Hao},
	month = sep,
	year = {2020},
	pages = {102075},
	file = {Wang et al. - 2020 - Multiple nonlinear features fusion based driving f.pdf:/home/simeon/Zotero/storage/8MXYNY4R/Wang et al. - 2020 - Multiple nonlinear features fusion based driving f.pdf:application/pdf},
}

@article{tanaka_supraspinal_2012,
	title = {Supraspinal regulation of physical fatigue},
	volume = {36},
	issn = {01497634},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763411001862},
	doi = {10.1016/j.neubiorev.2011.10.004},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Tanaka, Masaaki and Watanabe, Yasuyoshi},
	month = jan,
	year = {2012},
	pages = {727--734},
	file = {Tanaka and Watanabe - 2012 - Supraspinal regulation of physical fatigue.pdf:/home/simeon/Zotero/storage/I36YNBK2/Tanaka and Watanabe - 2012 - Supraspinal regulation of physical fatigue.pdf:application/pdf},
}

@article{yang_novel_2021,
	title = {A novel method of multiaxial fatigue life prediction based on deep learning},
	volume = {151},
	issn = {01421123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0142112321002164},
	doi = {10.1016/j.ijfatigue.2021.106356},
	abstract = {It is well-known that conventional multiaxial fatigue life prediction models are generally limited to specific materials and loading conditions. To remove this limitation, a novel attempt is proposed in this work based on the deep learning (i.e., an improvement of artificial neural network in machine learning approaches, which is powerful to learn representations of data with multiple levels of abstraction). To comprehensively evaluate the prediction capability of proposed deep learning-based method, six series of existing fatigue data of different materials are, respectively, analyzed, in which the main loading conditions concerned in the low-cycle and highcycle fatigue researches are included, such as loading modes (stress-controlled/strain-controlled modes), loading levels (stress/strain amplitude and mean stress/strain), and loading paths (uniaxial/multiaxial and proportional/ non-proportional paths), as well as for low-cycle and high-cycle fatigue regimes. Comparison of the predicted and experimental results shows that: all the loading conditions mentioned above can be handled satisfactorily by the proposed deep learning-based method; excellent prediction accuracy is achieved, and the predicted lives in each study case fall almost within the scatter band of 1.5 times. In addition, four groups of specifically designed data are used to evaluate the extrapolation capability of the proposed method, and the results show that the extrapolation capability gets weaker if the distinctions between the loading paths involved in the training dataset and test one increase.},
	language = {en},
	urldate = {2022-02-23},
	journal = {International Journal of Fatigue},
	author = {Yang, Jingye and Kang, Guozheng and Liu, Yujie and Kan, Qianhua},
	month = oct,
	year = {2021},
	pages = {106356},
	file = {Yang et al. - 2021 - A novel method of multiaxial fatigue life predicti.pdf:/home/simeon/Zotero/storage/KHMVBRD2/Yang et al. - 2021 - A novel method of multiaxial fatigue life predicti.pdf:application/pdf},
}

@article{matthews_task-induced_2002,
	title = {Task-induced fatigue states and simulated driving performance},
	volume = {55},
	issn = {0272-4987, 1464-0740},
	url = {http://journals.sagepub.com/doi/10.1080/02724980143000505},
	doi = {10.1080/02724980143000505},
	abstract = {States of fatigue are implicated in driver impairment and motor vehicle accidents. This article reports two studies investigating two possible mechanisms for performance impairment: (1) loss of attentional resources; and (2) active regulation of matching effort to task demands. The first hypothesis predicts that fatigue effects will be accentuated by high task demands, but the second hypothesis predicts that fatigue effects will be strongest in “underload” conditions. In two studies, drivers performed a stimulated driving task, in which task demands were manipulated by varying road curvature. In a “fatigue induction” condition, the early part of the drive was occupied by performance of a demanding secondary task concurrently with driving, after which the concurrent task ceased. Post-induction driving performance was compared with a control condition in which drivers were not exposed to the induction. In both studies, the fatigue induction elicited various subjective fatigue and stress symptoms, and also raised reported workload. Fatigue effects on vehicle control and signal detection were assessed during and after the fatigue induction. The fatigue induction increased heading error, reduced steering activity, and, in the second study, reduced perceptual sensitivity on a secondary detection task. These effects were confined to driving on straight rather than on curved road sections, consistent with the effort regulation hypothesis. The second study showed that fatigue effects were moderated by a motivational manipulation. Results are interpreted within a control model, such that task-induced fatigue may reduce awareness of performance impairment, rather than reluctance or inability to mobilize compensatory effort following detection of impairment.},
	language = {en},
	number = {2},
	urldate = {2022-02-23},
	journal = {The Quarterly Journal of Experimental Psychology Section A},
	author = {Matthews, Gerald and Desmond, Paula A.},
	month = apr,
	year = {2002},
	pages = {659--686},
	file = {Matthews and Desmond - 2002 - Task-induced fatigue states and simulated driving .pdf:/home/simeon/Zotero/storage/EJMQW772/Matthews and Desmond - 2002 - Task-induced fatigue states and simulated driving .pdf:application/pdf},
}

@article{li_dsfd_2019,
	title = {{DSFD}: {Dual} {Shot} {Face} {Detector}},
	shorttitle = {{DSFD}},
	url = {http://arxiv.org/abs/1810.10220},
	abstract = {In this paper, we propose a novel face detection network with three novel contributions that address three key aspects of face detection, including better feature learning, progressive loss design and anchor assign based data augmentation, respectively. First, we propose a Feature Enhance Module (FEM) for enhancing the original feature maps to extend the single shot detector to dual shot detector. Second, we adopt Progressive Anchor Loss (PAL) computed by two different sets of anchors to effectively facilitate the features. Third, we use an Improved Anchor Matching (IAM) by integrating novel anchor assign strategy into data augmentation to provide better initialization for the regressor. Since these techniques are all related to the two-stream design, we name the proposed network as Dual Shot Face Detector (DSFD). Extensive experiments on popular benchmarks, WIDER FACE and FDDB, demonstrate the superiority of DSFD over the state-of-the-art face detectors.},
	language = {en},
	urldate = {2022-03-03},
	journal = {arXiv:1810.10220 [cs]},
	author = {Li, Jian and Wang, Yabiao and Wang, Changan and Tai, Ying and Qian, Jianjun and Yang, Jian and Wang, Chengjie and Li, Jilin and Huang, Feiyue},
	month = apr,
	year = {2019},
	note = {arXiv: 1810.10220},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Camera-ready version of DSFD for CVPR 2019. Code is available at: https://github.com/TencentYoutuResearch/FaceDetection-DSFD},
	annote = {Comment: Camera-ready version of DSFD for CVPR 2019. Code is available at: https://github.com/TencentYoutuResearch/FaceDetection-DSFD},
	file = {Li et al. - 2019 - DSFD Dual Shot Face Detector.pdf:/home/simeon/Zotero/storage/KCNSG38Y/Li et al. - 2019 - DSFD Dual Shot Face Detector.pdf:application/pdf;Li et al. - 2019 - DSFD Dual Shot Face Detector.pdf:/home/simeon/Zotero/storage/X5XUBRBT/Li et al. - 2019 - DSFD Dual Shot Face Detector.pdf:application/pdf},
}

@inproceedings{baltrusaitis_constrained_2013,
	address = {Sydney, Australia},
	title = {Constrained {Local} {Neural} {Fields} for {Robust} {Facial} {Landmark} {Detection} in the {Wild}},
	isbn = {978-1-4799-3022-7},
	url = {http://ieeexplore.ieee.org/document/6755919/},
	doi = {10.1109/ICCVW.2013.54},
	abstract = {Facial feature detection algorithms have seen great progress over the recent years. However, they still struggle in poor lighting conditions and in the presence of extreme pose or occlusions. We present the Constrained Local Neural Field model for facial landmark detection. Our model includes two main novelties. First, we introduce a probabilistic patch expert (landmark detector) that can learn non-linear and spatial relationships between the input pixels and the probability of a landmark being aligned. Secondly, our model is optimised using a novel Non-uniform Regularised Landmark Mean-Shift optimisation technique, which takes into account the reliabilities of each patch expert. We demonstrate the beneﬁt of our approach on a number of publicly available datasets over other state-of-the-art approaches when performing landmark detection in unseen lighting conditions and in the wild.},
	language = {en},
	urldate = {2022-03-03},
	booktitle = {2013 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops}},
	publisher = {IEEE},
	author = {Baltrusaitis, Tadas and Robinson, Peter and Morency, Louis-Philippe},
	month = dec,
	year = {2013},
	pages = {354--361},
	file = {Baltrusaitis et al. - 2013 - Constrained Local Neural Fields for Robust Facial .pdf:/home/simeon/Zotero/storage/23HFBB7X/Baltrusaitis et al. - 2013 - Constrained Local Neural Fields for Robust Facial .pdf:application/pdf;Baltrusaitis et al. - 2013 - Constrained Local Neural Fields for Robust Facial .pdf:/home/simeon/Zotero/storage/P2VTVKCJ/Baltrusaitis et al. - 2013 - Constrained Local Neural Fields for Robust Facial .pdf:application/pdf},
}

@article{cootes_combining_1995,
	title = {Combining point distribution models with shape models based on finite element analysis},
	volume = {13},
	abstract = {This paper describes a method of combining two approaches to modelling flexible objects. Modal analysis using finite element methods (FEM) generates a set of vibrational modes for a sing/e shape. Point distribution models (PDM) generate a statistical model of shape and shape variation from a set of example shapes. A new approach is described which generates vibrational modes when few example shapes are available and changes smoothly to using more statistical modes of variation when a large data set is presented. Results are given for both synthetic and real examples. Experiments using the models for image search show that the combined version performs better than either the PDM or FEM models alone.},
	language = {en},
	number = {5},
	author = {Cootes, T F and Taylor, C J},
	year = {1995},
	pages = {7},
	file = {Cootes and Taylor - 1995 - Combining point distribution models with shape mod.pdf:/home/simeon/Zotero/storage/B4VMXCLP/Cootes and Taylor - 1995 - Combining point distribution models with shape mod.pdf:application/pdf;Cootes and Taylor - 1995 - Combining point distribution models with shape mod.pdf:/home/simeon/Zotero/storage/AP8W9E3R/Cootes and Taylor - 1995 - Combining point distribution models with shape mod.pdf:application/pdf},
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	abstract = {The support-vector network is a new leaming machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very highdimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
	language = {en},
	number = {3},
	urldate = {2022-03-03},
	journal = {Machine Learning},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	month = sep,
	year = {1995},
	pages = {273--297},
	file = {Cortes and Vapnik - 1995 - Support-vector networks.pdf:/home/simeon/Zotero/storage/UD35IYX7/Cortes and Vapnik - 1995 - Support-vector networks.pdf:application/pdf;Cortes and Vapnik - 1995 - Support-vector networks.pdf:/home/simeon/Zotero/storage/Z5BCBY32/Cortes and Vapnik - 1995 - Support-vector networks.pdf:application/pdf},
}

@article{hu_squeeze-and-excitation_2019,
	title = {Squeeze-and-{Excitation} {Networks}},
	url = {http://arxiv.org/abs/1709.01507},
	abstract = {The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive ﬁelds at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the “Squeeze-and-Excitation” (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring signiﬁcant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classiﬁcation submission which won ﬁrst place and reduced the top-5 error to 2.251\%, surpassing the winning entry of 2016 by a relative improvement of ∼25\%. Models and code are available at https://github.com/hujie-frank/SENet.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:1709.01507 [cs]},
	author = {Hu, Jie and Shen, Li and Albanie, Samuel and Sun, Gang and Wu, Enhua},
	month = may,
	year = {2019},
	note = {arXiv: 1709.01507},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: journal version of the CVPR 2018 paper, accepted by TPAMI},
	annote = {Comment: journal version of the CVPR 2018 paper, accepted by TPAMI},
	file = {Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:/home/simeon/Zotero/storage/E4LHYPJL/Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:application/pdf;Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:/home/simeon/Zotero/storage/2ZT9YPMC/Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:application/pdf},
}

@article{sandler_mobilenetv2_2019,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	shorttitle = {{MobileNetV2}},
	url = {http://arxiv.org/abs/1801.04381},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efﬁcient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:1801.04381 [cs]},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	month = mar,
	year = {2019},
	note = {arXiv: 1801.04381},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:/home/simeon/Zotero/storage/VNHRLB4X/Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:application/pdf;Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:/home/simeon/Zotero/storage/6TA452P8/Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:application/pdf},
}

@article{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution ﬁlters, which shows that a signiﬁcant improvement on the prior-art conﬁgurations can be achieved by pushing the depth to 16–19 weight layers. These ﬁndings were the basis of our ImageNet Challenge 2014 submission, where our team secured the ﬁrst and the second places in the localisation and classiﬁcation tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	language = {en},
	urldate = {2022-03-04},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:/home/simeon/Zotero/storage/WFUPFWPR/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:/home/simeon/Zotero/storage/N8HS3N8A/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf},
}

@incollection{chen_driver_2017-1,
	address = {Cham},
	title = {Driver {Drowsiness} {Detection} via a {Hierarchical} {Temporal} {Deep} {Belief} {Network}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	url = {http://link.springer.com/10.1007/978-3-319-54526-4_9},
	abstract = {Drowsy driver alert systems have been developed to minimize and prevent car accidents. Existing vision-based systems are usually restricted to using visual cues, depend on tedious parameter tuning, or cannot work under general conditions. One additional crucial issue is the lack of public datasets that can be used to evaluate the performance of diﬀerent methods. In this paper, we introduce a novel hierarchical temporal Deep Belief Network (HTDBN) method for drowsy detection. Our scheme ﬁrst extracts high-level facial and head feature representations and then use them to recognize drowsiness-related symptoms. Two continuous-hidden Markov models are constructed on top of the DBNs. These are used to model and capture the interactive relations between eyes, mouth and head motions. We also collect a large comprehensive dataset containing various ethnicities, genders, lighting conditions and driving scenarios in pursuit of wide variations of driver videos. Experimental results demonstrate the feasibility of the proposed HTDBN framework in detecting drowsiness based on diﬀerent visual cues.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Weng, Ching-Hua and Lai, Ying-Hsiu and Lai, Shang-Hong},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_9},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {117--133},
	file = {Weng et al. - 2017 - Driver Drowsiness Detection via a Hierarchical Tem.pdf:/home/simeon/Zotero/storage/PX9RZ5MS/Weng et al. - 2017 - Driver Drowsiness Detection via a Hierarchical Tem.pdf:application/pdf;Weng et al. - 2017 - Driver Drowsiness Detection via a Hierarchical Tem.pdf:/home/simeon/Zotero/storage/PMLRS3K5/Weng et al. - 2017 - Driver Drowsiness Detection via a Hierarchical Tem.pdf:application/pdf},
}

@incollection{ackerman_differentiation_2011,
	address = {Washington},
	title = {Differentiation of sleepiness and mental fatigue effects.},
	isbn = {978-1-4338-0839-5},
	url = {http://content.apa.org/books/12343-002},
	language = {en},
	urldate = {2022-03-07},
	booktitle = {Cognitive fatigue: {Multidisciplinary} perspectives on current research and future applications.},
	publisher = {American Psychological Association},
	author = {Balkin, Thomas J. and Wesensten, Nancy J.},
	editor = {Ackerman, Phillip L.},
	year = {2011},
	doi = {10.1037/12343-002},
	pages = {47--66},
	file = {Balkin and Wesensten - 2011 - Differentiation of sleepiness and mental fatigue e.pdf:/home/simeon/Zotero/storage/DIPVZ9H4/Balkin and Wesensten - 2011 - Differentiation of sleepiness and mental fatigue e.pdf:application/pdf},
}

@article{schellekens_immediate_2000,
	title = {Immediate and delayed after-effects of long lasting mentally demanding work},
	volume = {53},
	issn = {03010511},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301051100000399},
	doi = {10.1016/S0301-0511(00)00039-9},
	language = {en},
	number = {1},
	urldate = {2022-03-07},
	journal = {Biological Psychology},
	author = {Schellekens, Jan M.H. and Sijtsma, Gelbrich J. and Vegter, Ellen and Meijman, Theo F.},
	month = may,
	year = {2000},
	pages = {37--56},
	file = {Schellekens et al. - 2000 - Immediate and delayed after-effects of long lastin.pdf:/home/simeon/Zotero/storage/PPI6VB85/Schellekens et al. - 2000 - Immediate and delayed after-effects of long lastin.pdf:application/pdf},
}

@article{wesensten_modanil_2004,
	title = {Modaﬁnil vs. {Caffeine}: {Effects} on {Fatigue} {During} {Sleep} {Deprivation}},
	volume = {75},
	abstract = {Introduction: The extent to which modaﬁnil and caffeine reverse fatigue effects (deﬁned as performance decrements with time on task) during total sleep deprivation was investigated. Methods: There were 50 healthy young adults who remained awake for 54.5 h (06:30 day 1 to 13:00 day 3). A 10-min vigilance test was administered bi-hourly from 08:00 day 1 until 22:00 day 2. At 23:55 day 2 (after 41.5 h awake), double-blind administration of one of ﬁve drug doses (placebo; modaﬁnil 100, 200, or 400 mg; or caffeine 600 mg; n ϭ 10 per group) was followed by hourly testing from 00:00 through 12:00 day 3. Response speed (reciprocal of reaction time) across the 10-min task (by 1-min block) was analyzed prior to and after drug administration. Results: A fatigue effect (response speed degradation across the 10-min task) was exacerbated by sleep deprivation and circadian rhythmicity. Prior to the drug, this effect was maximal between 08:00 and 12:00 day 3 (24 –28 h sleep deprivation). Modaﬁnil 400 mg attenuated fatigue in a manner comparable to that seen with caffeine 600 mg; these effects were especially salient during the circadian nadir of performance (06:00 through 10:00); modaﬁnil 200 mg also reversed fatigue, but for a shorter duration (3 min) than modaﬁnil 400 mg (8 min) or caffeine 600 mg (6 min). Discussion and Conclusions: Time-on-task effects contributed to the performance degradation seen during sleep deprivation; effects which were reversed by caffeine and, at appropriate doses, by modaﬁnil. Because the duration of efﬁcacy for reversing time-on-task effects was shorter at lower drug dosages, the latter must be considered when determining the appropriate dose to use during sustained operations.},
	language = {en},
	number = {6},
	author = {Wesensten, Nancy Jo and Belenky, Gregory and Thorne, David R and Kautz, Mary A and Balkin, Thomas J},
	year = {2004},
	pages = {6},
	file = {Wesensten et al. - 2004 - Modaﬁnil vs. Caffeine Effects on Fatigue During S.pdf:/home/simeon/Zotero/storage/7F6M6LHY/Wesensten et al. - 2004 - Modaﬁnil vs. Caffeine Effects on Fatigue During S.pdf:application/pdf},
}

@article{leger_you_2022,
	title = {“{You} look sleepy…” {The} impact of sleep restriction on skin parameters and facial appearance of 24 women},
	volume = {89},
	issn = {13899457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389945721005761},
	doi = {10.1016/j.sleep.2021.11.011},
	abstract = {Background: Total sleep deprivation has a visible impact on subjective facial appearance. However, there is a lack of knowledge on how moderate sleep restriction objectively impairs skin quality and facial aspect.
Methods: Twenty-four healthy good-sleeping women, aged 30e55, volunteered for this study on the impact of sleep restriction (SR) on their facial skin. SR was limited to 3 h per night for 2 consecutive nights. We assessed the following parameters at the same time of day, before and after SR: sebumetry (Sebumeter SM 815), hydration (Corneometer CM 825), trans-epidermal water loss (Tewameter TM 210), biomechanical properties (Cutometer MPA 580), pH (PH-meter 900), desquamation quantiﬁcation (DSquameter and microscopy), and image analysis (ColorFace - Newtone Technologies). We also obtained skin samples (swab) for malondialdehyde quantiﬁcation (MDA).
Results: We observed that some skin parameters are signiﬁcantly associated with SR in both the morning and afternoon, including: lower hydration (p {\textless} 0.001), increased trans-epidermal water loss (PIE) (p {\textless} 0.001), and decreased extensibility (Uf; p ¼ 0.015) and viscosity (Uv; p {\textless} 0.001) of the skin. The average pH increased from 4.8 (±0.2) to 4.9 ± 0.4; p {\textless} 0.001. For face photography, brightness and saturation also signiﬁcantly decreased with SR in mornings and afternoons (p {\textless} 0.001 for all tests). Finally, we observed a signiﬁcant decrease in isolated corneocytes after desquamation associated with SR (p {\textless} 0.001 for all tests). SR was also associated with signiﬁcantly increased MDA levels (p {\textless} 0.001 for all tests).
Conclusions: Two nights of SR signiﬁcantly altered the skin and facial appearances in our test group of typically good-sleeping women. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
	language = {en},
	urldate = {2022-03-07},
	journal = {Sleep Medicine},
	author = {Léger, Damien and Gauriau, Caroline and Etzi, Cécile and Ralambondrainy, Samuel and Heusèle, Catherine and Schnebert, Sylvianne and Dubois, Alexandre and Gomez-Merino, Danielle and Dumas, Marc},
	month = jan,
	year = {2022},
	pages = {97--103},
	file = {Léger et al. - 2022 - “You look sleepy…” The impact of sleep restriction.pdf:/home/simeon/Zotero/storage/J5GKZSGY/Léger et al. - 2022 - “You look sleepy…” The impact of sleep restriction.pdf:application/pdf},
}

@article{chu_fatigue_2013,
	title = {Fatigue {Minimization} {Work} {Shift} {Scheduling} for {Air} {Traffic} {Controllers}},
	volume = {3},
	issn = {2223-9766},
	url = {http://www.ausmt.org/index.php/AUSMT/article/view/185},
	doi = {10.5875/ausmt.v3i2.185},
	abstract = {It is common for Air Traffic Controllers to control air traffic during the night and to experience fatigue. Although fatigue is not the direct cause of aviation accidents, 21 percent of accidents are fatigue-related. Therefore countries and companies have tried to regulate work hours to avoid extreme fatigue, thus decreasing human error resulting from fatigue. However, these regulations may not reflect that actual fatigue variation and fatigue levels can be decreased still more by scheduling appropriately. This paper focuses on optimal work shift scheduling to reduce air traffic controller fatigue. First, a mathematical model is established to describe fatigue levels. The objective function is to reduce the fatigue peak produced by work shifts as much as possible. Various constraints, such as holidays and manpower requirements are considered. The optimization problem is then solved using integer programming. We take a sample schedule and draw conclusions by comparing our results with the original fatigue levels.},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {International Journal of Automation and Smart Technology},
	author = {Chu, Ta-Chung and Wang, Tzu-Yao and Ke, Guo-Chuan},
	month = jun,
	year = {2013},
	pages = {91--99},
	file = {Chu et al. - 2013 - Fatigue Minimization Work Shift Scheduling for Air.pdf:/home/simeon/Zotero/storage/6V62UIMF/Chu et al. - 2013 - Fatigue Minimization Work Shift Scheduling for Air.pdf:application/pdf},
}

@article{lemos_web_2016,
	title = {Web {Service} {Composition}: {A} {Survey} of {Techniques} and {Tools}},
	volume = {48},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Web {Service} {Composition}},
	url = {https://dl.acm.org/doi/10.1145/2831270},
	doi = {10.1145/2831270},
	abstract = {Web services are a consolidated reality of the modern Web with tremendous, increasing impact on everyday computing tasks. They turned the Web into the largest, most accepted, and most vivid distributed computing platform ever. Yet, the use and integration of Web services into composite services or applications, which is a highly sensible and conceptually non-trivial task, is still not unleashing its full magnitude of power. A consolidated analysis framework that advances the fundamental understanding of Web service composition building blocks in terms of concepts, models, languages, productivity support techniques, and tools is required. This framework is necessary to enable effective exploration, understanding, assessing, comparing, and selecting service composition models, languages, techniques, platforms, and tools. This article establishes such a framework and reviews the state of the art in service composition from an unprecedented, holistic perspective.},
	language = {en},
	number = {3},
	urldate = {2022-03-07},
	journal = {ACM Computing Surveys},
	author = {Lemos, Angel Lagares and Daniel, Florian and Benatallah, Boualem},
	month = feb,
	year = {2016},
	pages = {1--41},
	file = {Lemos et al. - 2016 - Web Service Composition A Survey of Techniques an.pdf:/home/simeon/Zotero/storage/UIV4UINU/Lemos et al. - 2016 - Web Service Composition A Survey of Techniques an.pdf:application/pdf},
}

@incollection{hursh_fatigue_2011,
	title = {Fatigue and {Performance} {Modeling}},
	isbn = {978-1-4160-6645-3},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9781416066453000669},
	language = {en},
	urldate = {2022-03-07},
	booktitle = {Principles and {Practice} of {Sleep} {Medicine}},
	publisher = {Elsevier},
	author = {Hursh, Steven R. and Van Dongen, Hans P.A.},
	year = {2011},
	doi = {10.1016/B978-1-4160-6645-3.00066-9},
	pages = {745--752},
	file = {Hursh and Van Dongen - 2011 - Fatigue and Performance Modeling.pdf:/home/simeon/Zotero/storage/K5AK4TS6/Hursh and Van Dongen - 2011 - Fatigue and Performance Modeling.pdf:application/pdf},
}

@article{caldwell_impact_2001,
	title = {The impact of fatigue in air medical and other types of operations: {A} review of fatigue facts and potential countermeasures},
	volume = {20},
	shorttitle = {The impact of fatigue in air medical and other types of operations},
	url = {http://www.mosby.com/scripts/om.dll/serve?action=searchDB&searchDBfor=art&artType=abs&id=a112420},
	doi = {10.1067/mmj.2001.112420},
	abstract = {Because of its effects on productivity and safety, fatigue is receiving increasing attention in a variety of settings, including aviation. Fatigue-related problems cost America an estimated \$18 billion a year in terms of lost productivity, and fatigue-related drowsiness on the highways contributes to more than 1500 fatalities, 100,000 crashes, and 76,000 injuries annually. Furthermore, evidence is mounting that pilot and aircrew fatigue has been a causative factor in several aviation mishaps.},
	language = {en},
	number = {1},
	urldate = {2022-03-07},
	journal = {Air Medical Journal},
	author = {Caldwell, John A.},
	month = feb,
	year = {2001},
	pages = {0025--0032},
	file = {Caldwell - 2001 - The impact of fatigue in air medical and other typ.pdf:/home/simeon/Zotero/storage/KUMSH3CN/Caldwell - 2001 - The impact of fatigue in air medical and other typ.pdf:application/pdf},
}

@article{wang_deep_2020-1,
	title = {Deep learning for tomographic image reconstruction},
	volume = {2},
	issn = {2522-5839},
	url = {http://www.nature.com/articles/s42256-020-00273-z},
	doi = {10.1038/s42256-020-00273-z},
	language = {en},
	number = {12},
	urldate = {2022-03-07},
	journal = {Nature Machine Intelligence},
	author = {Wang, Ge and Ye, Jong Chul and De Man, Bruno},
	month = dec,
	year = {2020},
	pages = {737--748},
	file = {Wang et al. - 2020 - Deep learning for tomographic image reconstruction.pdf:/home/simeon/Zotero/storage/85426KZT/Wang et al. - 2020 - Deep learning for tomographic image reconstruction.pdf:application/pdf},
}

@article{aljasim_e2dr_2022,
	title = {{E2DR}: {A} {Deep} {Learning} {Ensemble}-{Based} {Driver} {Distraction} {Detection} with {Recommendations} {Model}},
	volume = {22},
	issn = {1424-8220},
	shorttitle = {{E2DR}},
	url = {https://www.mdpi.com/1424-8220/22/5/1858},
	doi = {10.3390/s22051858},
	abstract = {The increasing number of car accidents is a signiﬁcant issue in current transportation systems. According to the World Health Organization (WHO), road accidents are the eighth highest top cause of death around the world. More than 80\% of road accidents are caused by distracted driving, such as using a mobile phone, talking to passengers, and smoking. A lot of efforts have been made to tackle the problem of driver distraction; however, no optimal solution is provided. A practical approach to solving this problem is implementing quantitative measures for driver activities and designing a classiﬁcation system that detects distracting actions. In this paper, we have implemented a portfolio of various ensemble deep learning models that have been proven to efﬁciently classify driver distracted actions and provide an in-car recommendation to minimize the level of distractions and increase in-car awareness for improved safety. This paper proposes E2DR, a new scalable model that uses stacking ensemble methods to combine two or more deep learning models to improve accuracy, enhance generalization, and reduce overﬁtting, with real-time recommendations. The highest performing E2DR variant, which included the ResNet50 and VGG16 models, achieved a test accuracy of 92\% as applied to state-of-the-art datasets, including the State Farm Distracted Drivers dataset, using novel data splitting strategies.},
	language = {en},
	number = {5},
	urldate = {2022-03-07},
	journal = {Sensors},
	author = {Aljasim, Mustafa and Kashef, Rasha},
	month = feb,
	year = {2022},
	pages = {1858},
	file = {Aljasim and Kashef - 2022 - E2DR A Deep Learning Ensemble-Based Driver Distra.pdf:/home/simeon/Zotero/storage/6ELYHZ7X/Aljasim and Kashef - 2022 - E2DR A Deep Learning Ensemble-Based Driver Distra.pdf:application/pdf},
}

@inproceedings{maaradji_social_2011,
	address = {Washington, DC, USA},
	title = {Social {Web} {Mashups} {Full} {Completion} via {Frequent} {Sequence} {Mining}},
	isbn = {978-1-4577-0879-4},
	url = {http://ieeexplore.ieee.org/document/6012680/},
	doi = {10.1109/SERVICES.2011.98},
	abstract = {In this paper we address the problem of Web Mashups full completion which consists of predicting the most suitable set of (combined) services that successfully meet the goals of an end-user Mashup, given the current service (or composition of services) initially supplied. We model full completion as a frequent sequence mining problem and we show how existing algorithms can be applied in this context. To overcome some limitations of the frequent sequence mining algorithms, e.g., efﬁciency and recommendation granularity, we propose FESMA, a new and efﬁcient algorithm for computing frequent sequences of services and recommending completions. FESMA also integrates a social dimension, extracted from the transformation of user → service interactions into user → user interactions, building an implicit graph that helps to better predict completions of services in a fashion tailored to individual users. Evaluations show that FESMA is more efﬁcient outperforming the existing algorithms even with the consideration of the social dimension. Our proposal has been implemented in a prototype, SoCo, developed at Bell Labs.},
	language = {en},
	urldate = {2022-03-07},
	booktitle = {2011 {IEEE} {World} {Congress} on {Services}},
	publisher = {IEEE},
	author = {Maaradji, Abderrahmane and Hacid, Hakim and Skraba, Ryan and Vakali, Athena},
	month = jul,
	year = {2011},
	pages = {9--16},
	file = {Maaradji et al. - 2011 - Social Web Mashups Full Completion via Frequent Se.pdf:/home/simeon/Zotero/storage/NSBCV2XR/Maaradji et al. - 2011 - Social Web Mashups Full Completion via Frequent Se.pdf:application/pdf},
}

@article{borbely_two-process_2016,
	title = {The two-process model of sleep regulation: a reappraisal},
	volume = {25},
	issn = {09621105},
	shorttitle = {The two-process model of sleep regulation},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/jsr.12371},
	doi = {10.1111/jsr.12371},
	abstract = {In the last three decades the two-process model of sleep regulation has served as a major conceptual framework in sleep research. It has been applied widely in studies on fatigue and performance and to dissect individual differences in sleep regulation. The model posits that a homeostatic process (Process S) interacts with a process controlled by the circadian pacemaker (Process C), with time-courses derived from physiological and behavioural variables. The model simulates successfully the timing and intensity of sleep in diverse experimental protocols. Electrophysiological recordings from the suprachiasmatic nuclei (SCN) suggest that S and C interact continuously. Oscillators outside the SCN that are linked to energy metabolism are evident in SCN-lesioned arrhythmic animals subjected to restricted feeding or methamphetamine administration, as well as in human subjects during internal desynchronization. In intact animals these peripheral oscillators may dissociate from the central pacemaker rhythm. A sleep/fast and wake/feed phase segregate antagonistic anabolic and catabolic metabolic processes in peripheral tissues. A deﬁciency of Process S was proposed to account for both depressive sleep disturbances and the antidepressant effect of sleep deprivation. The model supported the development of novel non-pharmacological treatment paradigms in psychiatry, based on manipulating circadian phase, sleep and light exposure. In conclusion, the model remains conceptually useful for promoting the integration of sleep and circadian rhythm research. Sleep appears to have not only a short-term, use-dependent function; it also serves to enforce rest and fasting, thereby supporting the optimization of metabolic processes at the appropriate phase of the 24-h cycle.},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {Journal of Sleep Research},
	author = {Borbély, Alexander A. and Daan, Serge and Wirz-Justice, Anna and Deboer, Tom},
	month = apr,
	year = {2016},
	pages = {131--143},
	file = {Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:/home/simeon/Zotero/storage/8U34EJEG/Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:application/pdf;Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:/home/simeon/Zotero/storage/9Y6UXFPU/Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:application/pdf;Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:/home/simeon/Zotero/storage/MKF642K2/Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:application/pdf;Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:/home/simeon/Zotero/storage/9PR5DMM5/Borbély et al. - 2016 - The two-process model of sleep regulation a reapp.pdf:application/pdf},
}

@article{kronauer_commentary_1982,
	title = {Commentary on the mathematical model of the human circadian system by {Kronauer} et al},
	volume = {242},
	issn = {0363-6119, 1522-1490},
	url = {https://www.physiology.org/doi/10.1152/ajpregu.1982.242.1.R17},
	doi = {10.1152/ajpregu.1982.242.1.R17},
	language = {en},
	number = {1},
	urldate = {2022-03-07},
	journal = {American Journal of Physiology-Regulatory, Integrative and Comparative Physiology},
	author = {Kronauer, R. E.},
	month = jan,
	year = {1982},
	pages = {R17--R24},
	file = {Kronauer - 1982 - Commentary on the mathematical model of the human .pdf:/home/simeon/Zotero/storage/HAK7DPMN/Kronauer - 1982 - Commentary on the mathematical model of the human .pdf:application/pdf},
}

@article{borbely_two_nodate,
	title = {A {Two} {Process} {Model} of {Sleep} {Regulation}},
	language = {en},
	author = {Borbely, A A},
	pages = {10},
	file = {Borbely - A Two Process Model of Sleep Regulation.pdf:/home/simeon/Zotero/storage/Z987Q2KB/Borbely - A Two Process Model of Sleep Regulation.pdf:application/pdf;Borbely - A Two Process Model of Sleep Regulation.pdf:/home/simeon/Zotero/storage/GGDLTTBI/Borbely - A Two Process Model of Sleep Regulation.pdf:application/pdf},
}

@article{hursh_fatigue_2004,
	title = {Fatigue {Models} for {Applied} {Research} in {Warﬁghting}},
	volume = {00},
	abstract = {The U.S. Department of Defense (DOD) has long pursued applied research concerning fatigue in sustained and continuous military operations. In 1996, Hursh developed a simple homeostatic fatigue model and programmed the model into an actigraph to give a continuous indication of performance. Based on this initial work, the Army conducted a study of 1-wk of restricted sleep in 66 subjects with multiple measures of performance, termed the Sleep Dose-Response Study (SDR). This study provided numerical estimation of parameters for the Walter Reed Army Institute of Research Sleep Performance Model (SPM) and elucidated the relationships among several sleep-related performance measures (6). Concurrently, Hursh extended the original actigraph modeling structure and software expressions for use in other practical applications. The model became known as the Sleep, Activity, Fatigue, and Task Effectiveness (SAFTE) Model, and Hursh has applied it in the construction of a Fatigue Avoidance Scheduling Tool. This software is designed to help optimize the operational management of aviation ground and ﬂight crews, but is not limited to that application. This paper describes the working fatigue model as it is being developed by the DOD laboratories, using the conceptual framework, vernacular, and notation of the SAFTE Model (16). At speciﬁc points where the SPM may differ from SAFTE, this is discussed. Extensions of the SAFTE Model to incorporate dynamic phase adjustment for both transmeridian relocation and shift work are described. The unexpected persistence of performance effects following chronic sleep restriction found in the SDR study necessitated some revisions of the SAFTE Model that are also described. The paper concludes with a discussion of several important modeling issues that remain to be addressed.},
	language = {en},
	number = {0},
	author = {Hursh, Steven R and Redmond, Daniel P and Johnson, Michael L and Thorne, David R and Belenky, Gregory and Balkin, Thomas J and Storm, William F and Miller, James C and Eddy, Douglas R},
	year = {2004},
	pages = {10},
	file = {Hursh et al. - 2004 - Fatigue Models for Applied Research in Warﬁghting.pdf:/home/simeon/Zotero/storage/SW3QPNJD/Hursh et al. - 2004 - Fatigue Models for Applied Research in Warﬁghting.pdf:application/pdf},
}

@article{reifman_commentary_2004,
	title = {Commentary on the {Three}-{Process} {Model} of {Alertness} and {Broader} {Modeling} {Issues}},
	volume = {75},
	language = {en},
	number = {3},
	author = {Reifman, Jaques and Gander, Philippa},
	year = {2004},
	pages = {5},
	file = {Reifman and Gander - 2004 - Commentary on the Three-Process Model of Alertness.pdf:/home/simeon/Zotero/storage/BEP7Y45F/Reifman and Gander - 2004 - Commentary on the Three-Process Model of Alertness.pdf:application/pdf},
}

@article{rajdev_unified_2013,
	title = {A unified mathematical model to quantify performance impairment for both chronic sleep restriction and total sleep deprivation},
	volume = {331},
	issn = {00225193},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022519313001811},
	doi = {10.1016/j.jtbi.2013.04.013},
	abstract = {Performance prediction models based on the classical two-process model of sleep regulation are reasonably effective at predicting alertness and neurocognitive performance during total sleep deprivation (TSD). However, during sleep restriction (partial sleep loss) performance predictions based on such models have been found to be less accurate. Because most modern operational environments are predominantly characterized by chronic sleep restriction (CSR) rather than by episodic TSD, the practical utility of this class of models has been limited. To better quantify performance during both CSR and TSD, we developed a uniﬁed mathematical model that incorporates extant sleep debt as a function of a known sleep/wake history, with recent history exerting greater inﬂuence. This incorporation of sleep/wake history into the classical two-process model captures an individual's capacity to recover during sleep as a function of sleep debt and naturally bridges the continuum from CSR to TSD by reducing to the classical two-process model in the case of TSD. We validated the proposed uniﬁed model using psychomotor vigilance task data from three prior studies involving TSD, CSR, and sleep extension. We compared and contrasted the ﬁts, within-study predictions, and across-study predictions from the uniﬁed model against predictions generated by two previously published models, and found that the uniﬁed model more accurately represented multiple experimental studies and consistently predicted sleep restriction scenarios better than the existing models. In addition, we found that the model parameters obtained by ﬁtting TSD data could be used to predict performance in other sleep restriction scenarios for the same study populations, and vice versa. Furthermore, this model better accounted for the relatively slow recovery process that is known to characterize CSR, as well as the enhanced performance that has been shown to result from sleep banking.},
	language = {en},
	urldate = {2022-03-07},
	journal = {Journal of Theoretical Biology},
	author = {Rajdev, Pooja and Thorsley, David and Rajaraman, Srinivasan and Rupp, Tracy L. and Wesensten, Nancy J. and Balkin, Thomas J. and Reifman, Jaques},
	month = aug,
	year = {2013},
	pages = {66--77},
	file = {Rajdev et al. - 2013 - A unified mathematical model to quantify performan.pdf:/home/simeon/Zotero/storage/B33ZH6YR/Rajdev et al. - 2013 - A unified mathematical model to quantify performan.pdf:application/pdf},
}

@article{mallis_summary_2004,
	title = {Summary of the {Key} {Features} of {Seven} {Biomathematical} {Models} of {Human} {Fatigue} and {Performance}},
	volume = {75},
	abstract = {Background: Biomathematical models that quantify the effects of circadian and sleep/wake processes on the regulation of alertness and performance have been developed in an effort to predict the magnitude and timing of fatigue-related responses in a variety of contexts (e.g., transmeridian travel, sustained operations, shift work). This paper summarizes key features of seven biomathematical models reviewed as part of the Fatigue and Performance Modeling Workshop held in Seattle, WA, on June 13–14, 2002. The Workshop was jointly sponsored by the National Aeronautics and Space Administration, U.S. Department of Defense, U.S. Army Medical Research and Materiel Command, Ofﬁce of Naval Research, Air Force Ofﬁce of Scientiﬁc Research, and U.S. Department of Transportation. Methods: An invitation was sent to developers of seven biomathematical models that were commonly cited in scientiﬁc literature and/or supported by government funding. On acceptance of the invitation to attend the Workshop, developers were asked to complete a survey of the goals, capabilities, inputs, and outputs of their biomathematical models of alertness and performance. Data from the completed surveys were summarized and juxtaposed to provide a framework for comparing features of the seven models. Results: Survey responses revealed that models varied greatly relative to their reported goals and capabilities. While all modelers reported that circadian factors were key components of their capabilities, they differed markedly with regard to the roles of sleep and work times as input factors for prediction: four of the seven models had work time as their sole input variable(s), while the other three models relied on various aspects of sleep timing for model input. Models also differed relative to outputs: ﬁve sought to predict results from laboratory experiments, ﬁeld, and operational data, while two models were developed without regard to predicting laboratory experimental results. All modelers provided published papers describing their models, with three of the models being proprietary. Conclusions: Although all models appear to have been fundamentally inﬂuenced by the two-process model of sleep regulation by Borbe´ly (6), there is considerable diversity among them in the number and type of input and output variables, and their stated goals and capabilities.},
	language = {en},
	number = {3},
	author = {Mallis, Melissa M and Mejdal, Sig and Nguyen, Tammy T and Dinges, David F},
	year = {2004},
	pages = {11},
	file = {Mallis et al. - 2004 - Summary of the Key Features of Seven Biomathematic.pdf:/home/simeon/Zotero/storage/FXVA4BTN/Mallis et al. - 2004 - Summary of the Key Features of Seven Biomathematic.pdf:application/pdf},
}

@article{kandelaars_review_nodate,
	title = {A {REVIEW} {OF} {BIO}-{MATHEMATICAL} {FATIGUE} {MODELS}: {WHERE} {TO} {FROM} {HERE}?},
	language = {en},
	author = {Kandelaars, Katie J and Dorrian, Jill and Fletcher, Adam and Roach, Gregory D and Dawson, Drew},
	pages = {20},
	file = {Kandelaars et al. - A REVIEW OF BIO-MATHEMATICAL FATIGUE MODELS WHERE.pdf:/home/simeon/Zotero/storage/KIYNNEGP/Kandelaars et al. - A REVIEW OF BIO-MATHEMATICAL FATIGUE MODELS WHERE.pdf:application/pdf},
}

@article{flynn-evans_changes_2020,
	title = {Changes in performance and bio-mathematical model performance predictions during 45 days of sleep restriction in a simulated space mission},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-71929-4},
	doi = {10.1038/s41598-020-71929-4},
	abstract = {Abstract
            Lunar habitation and exploration of space beyond low-Earth orbit will require small crews to live in isolation and confinement while maintaining a high level of performance with limited support from mission control. Astronauts only achieve approximately 6 h of sleep per night, but few studies have linked sleep deficiency in space to performance impairment. We studied crewmembers over 45 days during a simulated space mission that included 5 h of sleep opportunity on weekdays and 8 h of sleep on weekends to characterize changes in performance on the psychomotor vigilance task (PVT) and subjective fatigue ratings. We further evaluated how well bio-mathematical models designed to predict performance changes due to sleep loss compared to objective performance. We studied 20 individuals during five missions and found that objective performance, but not subjective fatigue, declined from the beginning to the end of the mission. We found that bio-mathematical models were able to predict average changes across the mission but were less sensitive at predicting individual-level performance. Our findings suggest that sleep should be prioritized in lunar crews to minimize the potential for performance errors. Bio-mathematical models may be useful for aiding crews in schedule design but not for individual-level fitness-for-duty decisions.},
	language = {en},
	number = {1},
	urldate = {2022-03-07},
	journal = {Scientific Reports},
	author = {Flynn-Evans, Erin E. and Kirkley, Crystal and Young, Millennia and Bathurst, Nicholas and Gregory, Kevin and Vogelpohl, Verena and End, Albert and Hillenius, Steven and Pecena, Yvonne and Marquez, Jessica J.},
	month = dec,
	year = {2020},
	pages = {15594},
	file = {Flynn-Evans et al. - 2020 - Changes in performance and bio-mathematical model .pdf:/home/simeon/Zotero/storage/L42ST9FK/Flynn-Evans et al. - 2020 - Changes in performance and bio-mathematical model .pdf:application/pdf},
}

@article{fletcher_quantitative_2001,
	title = {A quantitative model of work-related fatigue: empirical evaluations},
	volume = {44},
	issn = {0014-0139, 1366-5847},
	shorttitle = {A quantitative model of work-related fatigue},
	url = {https://www.tandfonline.com/doi/full/10.1080/00140130119824},
	doi = {10.1080/00140130119824},
	language = {en},
	number = {5},
	urldate = {2022-03-07},
	journal = {Ergonomics},
	author = {Fletcher, Adam and Dawson, Drew},
	month = apr,
	year = {2001},
	pages = {475--488},
	file = {Fletcher and Dawson - 2001 - A quantitative model of work-related fatigue empi.pdf:/home/simeon/Zotero/storage/I7N7TWKI/Fletcher and Dawson - 2001 - A quantitative model of work-related fatigue empi.pdf:application/pdf},
}

@article{dawson_modelling_2011,
	title = {Modelling fatigue and the use of fatigue models in work settings},
	volume = {43},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457510000059},
	doi = {10.1016/j.aap.2009.12.030},
	abstract = {In recent years, theoretical models of the sleep and circadian system developed in laboratory settings have been adapted to predict fatigue and, by inference, performance. This is typically done using the timing of prior sleep and waking or working hours as the primary input and the time course of the predicted variables as the primary output. The aim of these models is to provide employers, unions and regulators with quantitative information on the likely average level of fatigue, or risk, associated with a given pattern of work and sleep with the goal of better managing the risk of fatigue-related errors and accidents/incidents. The ﬁrst part of this review summarises the variables known to inﬂuence workplace fatigue and draws attention to the considerable variability attributable to individual and task variables not included in current models. The second part reviews the current fatigue models described in the scientiﬁc and technical literature and classiﬁes them according to whether they predict fatigue directly by using the timing of prior sleep and wake (one-step models) or indirectly by using work schedules to infer an average sleep-wake pattern that is then used to predict fatigue (two-step models). The third part of the review looks at the current use of fatigue models in ﬁeld settings by organizations and regulators. Given their limitations it is suggested that the current generation of models may be appropriate for use as one element in a fatigue risk management system. The ﬁnal section of the review looks at the future of these models and recommends a standardised approach for their use as an element of the ‘defenses-in-depth’ approach to fatigue risk management.},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {Accident Analysis \& Prevention},
	author = {Dawson, Drew and Ian Noy, Y. and Härmä, Mikko and Åkerstedt, Torbjorn and Belenky, Gregory},
	month = mar,
	year = {2011},
	pages = {549--564},
	file = {Dawson et al. - 2011 - Modelling fatigue and the use of fatigue models in.pdf:/home/simeon/Zotero/storage/J22EJU88/Dawson et al. - 2011 - Modelling fatigue and the use of fatigue models in.pdf:application/pdf},
}

@article{daan_timing_1984,
	title = {Timing of human sleep: recovery process gated by a circadian pacemaker},
	volume = {246},
	issn = {0363-6119, 1522-1490},
	shorttitle = {Timing of human sleep},
	url = {https://www.physiology.org/doi/10.1152/ajpregu.1984.246.2.R161},
	doi = {10.1152/ajpregu.1984.246.2.R161},
	abstract = {A model for the timing of human sleep is presented. It is based on a sleep-regulating variable (S)--possibly, but not necessarily, associated with a neurochemical substance--which increases during wakefulness and decreases during sleep. Sleep onset is triggered when S approaches an upper threshold (H); awakening occurs when S reaches a lower threshold (L). The thresholds show a circadian rhythm controlled by a single circadian pacemaker. Time constants of the S process were derived from rates of change of electroencephalographic (EEG) power density during regular sleep and during recovery from sleep deprivation. The waveform of the circadian threshold fluctuations was derived from spontaneous wake-up times after partial sleep deprivation. The model allows computer simulations of the main phenomena of human sleep timing, such as 1) internal desynchronization in the absence of time cues, 2) sleep fragmentation during continuous bed rest, and 3) circadian phase dependence of sleep duration during isolation from time cues, recovery from sleep deprivation, and shift work. The model shows that the experimental data are consistent with the concept of a single circadian pacemaker in humans. It has implications for the understanding of sleep as a restorative process and its timing with respect to day and night.},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {American Journal of Physiology-Regulatory, Integrative and Comparative Physiology},
	author = {Daan, S. and Beersma, D. G. and Borbely, A. A.},
	month = feb,
	year = {1984},
	pages = {R161--R183},
	file = {Daan et al. - 1984 - Timing of human sleep recovery process gated by a.pdf:/home/simeon/Zotero/storage/XHSKNKFY/Daan et al. - 1984 - Timing of human sleep recovery process gated by a.pdf:application/pdf},
}

@article{borb_sleep_nodate,
	title = {Sleep {Homeostasis} and {Models} of {Sleep} {Regulation}},
	abstract = {According to the two-process model of sleep regulation, the timing and structure of sleep are determined by the interaction of a homeostatic and a circadian process. The original qualitative model was elaborated to quantitative versions that included the ultradian dynamics of sleep in relation to the non-REM-REM sleep cycle. The time course of EEG slow-wave activity, the major marker of non-REM sleep homeostasis, as well as daytime alertness were simulated successfully for a considerable number of experimental protocols. They include sleep after partial sleep deprivation and daytime napping, sleep in habitual short and long sleepers, and alertness in a forced desynchrony protocol or during an extended photoperiod. Simulations revealed that internal desynchronization can be obtained for different shapes of the thresholds. New developments include the analysis of the waking EEG to delineate homeostatic and circadian processes, studies of REM sleep homeostasis, and recent evidence for local, use-dependent sleep processes. Moreover, nonlinear interactions between homeostatic and circadian processes were identified. In the past two decades, models have contributed considerably to conceptualizing and analyzing the major processes underlying sleep regulation, and they are likely to play an important role in future advances in the field.},
	language = {en},
	author = {Borb, Alexander A and Achermann, Peter},
	pages = {12},
	file = {Borb and Achermann - Sleep Homeostasis and Models of Sleep Regulation.pdf:/home/simeon/Zotero/storage/VS567RVU/Borb and Achermann - Sleep Homeostasis and Models of Sleep Regulation.pdf:application/pdf},
}

@article{achermann_combining_1992,
	title = {Combining different models of sleep regulation},
	volume = {1},
	issn = {09621105, 13652869},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1365-2869.1992.tb00028.x},
	doi = {10.1111/j.1365-2869.1992.tb00028.x},
	abstract = {Different models have been proposed to account for processes underlying the regulation of sleep and alertness. Specific models have addressed sleep homeostasis, the nonREM-REM sleep cycle, the circadian sleep/wake rhythm, and changes of daytime alertness. We show that the different models are not mutually exclusive but that they can be integrated as ‘modules’ in a combined model.},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {Journal of Sleep Research},
	author = {Achermann, Peter and Borbély, Alexander A.},
	month = jun,
	year = {1992},
	pages = {144--147},
	file = {Achermann and Borbély - 1992 - Combining different models of sleep regulation.pdf:/home/simeon/Zotero/storage/WU9GDLVM/Achermann and Borbély - 1992 - Combining different models of sleep regulation.pdf:application/pdf},
}

@article{akerstedt_three-process_1997,
	title = {The {Three}-{Process} {Model} of {Alertness} and {Its} {Extension} to {Performance}, {Sleep} {Latency}, and {Sleep} {Length}},
	volume = {14},
	issn = {0742-0528, 1525-6073},
	url = {http://www.tandfonline.com/doi/full/10.3109/07420529709001149},
	doi = {10.3109/07420529709001149},
	language = {en},
	number = {2},
	urldate = {2022-03-07},
	journal = {Chronobiology International},
	author = {Åkerstedt, Torbjörn and Folkard, Simon},
	month = jan,
	year = {1997},
	pages = {115--123},
	file = {Åkerstedt and Folkard - 1997 - The Three-Process Model of Alertness and Its Exten.pdf:/home/simeon/Zotero/storage/EQXHEAMW/Åkerstedt and Folkard - 1997 - The Three-Process Model of Alertness and Its Exten.pdf:application/pdf},
}

@article{achermann_simulation_nodate,
	title = {Simulation of daytime vigilance by the additive interaction of a homeostatic and a circadian process},
	abstract = {The two-process model of sleep regulation postulates that a homeostatic and a circadian process underlie sleep regulation. The timing of sleep and waking is accounted for by the interaction of these two processes. The assumptions of two separate processes or of a single process resulting from their additive interaction are mathematically equivalent but conceptually different. Based on an additive interaction, subjective alertness ratings in a forced desynchrony protocol and subjective sleepiness ratings in a photoperiod experiment were simulated. The correspondence between empirical and simulated data supports the basic assumption of the model.},
	language = {en},
	author = {Achermann, Peter and Borbly, Alexander A},
	pages = {7},
	file = {Achermann and Borbly - Simulation of daytime vigilance by the additive in.pdf:/home/simeon/Zotero/storage/VE43YR5Y/Achermann and Borbly - Simulation of daytime vigilance by the additive in.pdf:application/pdf;Achermann and Borbly - Simulation of daytime vigilance by the additive in.pdf:/home/simeon/Zotero/storage/GALP8L7J/Achermann and Borbly - Simulation of daytime vigilance by the additive in.pdf:application/pdf},
}

@article{van_dongen_optimization_2007,
	title = {Optimization of {Biomathematical} {Model} {Predictions} for {Cognitive} {Performance} {Impairment} in {Individuals}: {Accounting} for {Unknown} {Traits} and {Uncertain} {States} in {Homeostatic} and {Circadian} {Processes}},
	volume = {30},
	issn = {0161-8105, 1550-9109},
	shorttitle = {Optimization of {Biomathematical} {Model} {Predictions} for {Cognitive} {Performance} {Impairment} in {Individuals}},
	url = {https://academic.oup.com/sleep/article-lookup/doi/10.1093/sleep/30.9.1129},
	doi = {10.1093/sleep/30.9.1129},
	language = {en},
	number = {9},
	urldate = {2022-03-07},
	journal = {Sleep},
	author = {Van Dongen, Hans P. A. and Mott, Christopher G. and Huang, Jen-Kuang and Mollicone, Daniel J. and McKenzie, Frederic D. and Dinges, David F.},
	month = sep,
	year = {2007},
	pages = {1129--1143},
	file = {Van Dongen et al. - 2007 - Optimization of Biomathematical Model Predictions .pdf:/home/simeon/Zotero/storage/DKNVQ8D7/Van Dongen et al. - 2007 - Optimization of Biomathematical Model Predictions .pdf:application/pdf},
}

@article{jewett_interactive_1999,
	title = {Interactive {Mathematical} {Models} of {Subjective} {Alertness} and {Cognitive} {Throughput} in {Humans}},
	volume = {14},
	issn = {0748-7304, 1552-4531},
	url = {http://journals.sagepub.com/doi/10.1177/074873099129000920},
	doi = {10.1177/074873099129000920},
	abstract = {The authors present here mathematical models in which levels of subjective alertness and cognitive throughput are predicted by three components that interact with one another in a nonlinear manner. These components are (1) a homeostatic component (H) that falls in a sigmoidal manner during wake and rises in a saturating exponential manner at a rate that is determined by circadian phase during sleep; (2) a circadian component (C) that is a function of the output of our mathematical model of the effect of light on the circadian pacemaker, with the amplitude further regulated by the level of H; and (3) a sleep inertia component (W) that rises in a saturating exponential manner after waketime. The authors first construct initial models of subjective alertness and cognitive throughput based on the results of sleep inertia studies, sleep deprivation studies initiated across all circadian phases, 28-h forced desynchrony studies, and alertness and performance dose response curves to sleep. These initial models are then refined using data from nearly one hundred fifty 30- to 50-h sleep deprivation studies in which subjects woke at their habitual times. The interactive three-component models presented here are able to predict even the fine details of neurobehavioral data from sleep deprivation studies and, after further validation, may provide a powerful tool for the design of safe shift work and travel schedules, including those in which people are exposed to unusual patterns of light.},
	language = {en},
	number = {6},
	urldate = {2022-03-07},
	journal = {Journal of Biological Rhythms},
	author = {Jewett, Megan E. and Kronauer, Richard E.},
	month = dec,
	year = {1999},
	pages = {588--597},
	file = {Jewett and Kronauer - 1999 - Interactive Mathematical Models of Subjective Aler.pdf:/home/simeon/Zotero/storage/6WMPD26Z/Jewett and Kronauer - 1999 - Interactive Mathematical Models of Subjective Aler.pdf:application/pdf},
}

@article{noauthor_notitle_nodate-2,
}

@misc{noauthor_how_nodate,
	title = {How to cite {OpenCV} - {Cite} {Bay}},
	url = {http://citebay.com/how-to-cite/opencv/},
	language = {en},
	urldate = {2022-03-07},
}

@misc{noauthor_citeopencv_nodate,
	title = {{CiteOpenCV} · opencv/opencv {Wiki}},
	url = {https://github.com/opencv/opencv},
	abstract = {Open Source Computer Vision Library. Contribute to opencv/opencv development by creating an account on GitHub.},
	language = {en},
	urldate = {2022-03-07},
	journal = {GitHub},
	file = {Snapshot:/home/simeon/Zotero/storage/FZV897T5/CiteOpenCV.html:text/html},
}

@article{bradski_opencv_2000,
	title = {The {OpenCV} {Library}},
	journal = {Dr. Dobb's Journal of Software Tools},
	author = {Bradski, G.},
	year = {2000},
	keywords = {bibtex-import},
}

@article{sagonas_300_2016,
	title = {300 {Faces} {In}-{The}-{Wild} {Challenge}: database and results},
	volume = {47},
	issn = {02628856},
	shorttitle = {300 {Faces} {In}-{The}-{Wild} {Challenge}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885616000147},
	doi = {10.1016/j.imavis.2016.01.002},
	abstract = {Computer Vision has recently witnessed great research advance towards automatic facial points detection. Numerous methodologies have been proposed during the last few years that achieve accurate and eﬃcient performance. However, fair comparison between these methodologies is infeasible mainly due to two issues. (a) Most existing databases, captured under both constrained and unconstrained (in-the-wild) conditions have been annotated using different mark-ups and, in most cases, the accuracy of the annotations is low. (b) Most published works report experimental results using different training/testing sets, different error metrics and, of course, landmark points with semantically different locations. In this paper, we aim to overcome the aforementioned problems by (a) proposing a semi-automatic annotation technique that was employed to re-annotate most existing facial databases under a uniﬁed protocol, and (b) presenting the 300 Faces InThe-Wild Challenge (300-W), the ﬁrst facial landmark localization challenge that was organized twice, in 2013 and 2015. To the best of our knowledge, this is the ﬁrst effort towards a uniﬁed annotation scheme of massive databases and a fair experimental comparison of existing facial landmark localization systems. The images and annotations of the new testing database that was used in the 300-W challenge are available from http://ibug.doc.ic.ac.uk/resources/300-W\_IMAVIS/.},
	language = {en},
	urldate = {2022-03-08},
	journal = {Image and Vision Computing},
	author = {Sagonas, Christos and Antonakos, Epameinondas and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
	month = mar,
	year = {2016},
	pages = {3--18},
	file = {Sagonas et al. - 2016 - 300 Faces In-The-Wild Challenge database and resu.pdf:/home/simeon/Zotero/storage/YIV7T55G/Sagonas et al. - 2016 - 300 Faces In-The-Wild Challenge database and resu.pdf:application/pdf},
}

@article{hearst_support_1998,
	title = {Support vector machines},
	volume = {13},
	issn = {1094-7167},
	url = {http://ieeexplore.ieee.org/document/708428/},
	doi = {10.1109/5254.708428},
	number = {4},
	urldate = {2022-03-08},
	journal = {IEEE Intelligent Systems and their Applications},
	author = {Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},
	month = jul,
	year = {1998},
	pages = {18--28},
	file = {Hearst et al_1998_Support vector machines.pdf:/home/simeon/Zotero/storage/3G7VVHWW/Hearst et al_1998_Support vector machines.pdf:application/pdf},
}

@inproceedings{redmon_real-time_2015,
	address = {Seattle, WA, USA},
	title = {Real-time grasp detection using convolutional neural networks},
	isbn = {978-1-4799-6923-4},
	url = {http://ieeexplore.ieee.org/document/7139361/},
	doi = {10.1109/ICRA.2015.7139361},
	abstract = {We present an accurate, real-time approach to robotic grasp detection based on convolutional neural networks. Our network performs single-stage regression to graspable bounding boxes without using standard sliding window or region proposal techniques. The model outperforms state-ofthe-art approaches by 14 percentage points and runs at 13 frames per second on a GPU. Our network can simultaneously perform classiﬁcation so that in a single step it recognizes the object and ﬁnds a good grasp rectangle. A modiﬁcation to this model predicts multiple grasps per object by using a locally constrained prediction mechanism. The locally constrained model performs signiﬁcantly better, especially on objects that can be grasped in a variety of ways.},
	language = {en},
	urldate = {2022-03-08},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Redmon, Joseph and Angelova, Anelia},
	month = may,
	year = {2015},
	pages = {1316--1322},
	file = {Redmon and Angelova - 2015 - Real-time grasp detection using convolutional neur.pdf:/home/simeon/Zotero/storage/4SEPHT8Z/Redmon and Angelova - 2015 - Real-time grasp detection using convolutional neur.pdf:application/pdf;Redmon and Angelova - 2015 - Real-time grasp detection using convolutional neur.pdf:/home/simeon/Zotero/storage/RVT7F4LI/Redmon and Angelova - 2015 - Real-time grasp detection using convolutional neur.pdf:application/pdf},
}

@inproceedings{redmon_you_2016,
	address = {Las Vegas, NV, USA},
	title = {You {Only} {Look} {Once}: {Unified}, {Real}-{Time} {Object} {Detection}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {You {Only} {Look} {Once}},
	url = {http://ieeexplore.ieee.org/document/7780460/},
	doi = {10.1109/CVPR.2016.91},
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
	language = {en},
	urldate = {2022-03-08},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	month = jun,
	year = {2016},
	pages = {779--788},
	file = {Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:/home/simeon/Zotero/storage/77T7EWSD/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf;Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:/home/simeon/Zotero/storage/UXCP5YM6/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf},
}

@inproceedings{albawi_understanding_2017,
	address = {Antalya},
	title = {Understanding of a convolutional neural network},
	isbn = {978-1-5386-1949-0},
	url = {https://ieeexplore.ieee.org/document/8308186/},
	doi = {10.1109/ICEngTechnol.2017.8308186},
	abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers . Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fullyconnected layer. The convolutional and fully- connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing . In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
	language = {en},
	urldate = {2022-03-08},
	booktitle = {2017 {International} {Conference} on {Engineering} and {Technology} ({ICET})},
	publisher = {IEEE},
	author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
	month = aug,
	year = {2017},
	pages = {1--6},
	file = {Albawi et al. - 2017 - Understanding of a convolutional neural network.pdf:/home/simeon/Zotero/storage/YDSIU78U/Albawi et al. - 2017 - Understanding of a convolutional neural network.pdf:application/pdf;Albawi et al. - 2017 - Understanding of a convolutional neural network.pdf:/home/simeon/Zotero/storage/F2CDK7J6/Albawi et al. - 2017 - Understanding of a convolutional neural network.pdf:application/pdf},
}

@inproceedings{tipprasert_method_2019,
	title = {A {Method} of {Driver}’s {Eyes} {Closure} and {Yawning} {Detection} for {Drowsiness} {Analysis} by {Infrared} {Camera}},
	doi = {10.1109/ICA-SYMP.2019.8646001},
	booktitle = {2019 {First} {International} {Symposium} on {Instrumentation}, {Control}, {Artificial} {Intelligence}, and {Robotics} ({ICA}-{SYMP})},
	author = {Tipprasert, Wisaroot and Charoenpong, Theekapun and Chianrabutra, Chamaporn and Sukjamsri, Chamaiporn},
	year = {2019},
	pages = {61--64},
	file = {Tipprasert et al. - 2019 - A Method of Driver’s Eyes Closure and Yawning Dete.pdf:/home/simeon/Zotero/storage/HD9MW8NY/Tipprasert et al. - 2019 - A Method of Driver’s Eyes Closure and Yawning Dete.pdf:application/pdf;Tipprasert et al. - 2019 - A Method of Driver’s Eyes Closure and Yawning Dete.pdf:/home/simeon/Zotero/storage/DG6XCTP4/Tipprasert et al. - 2019 - A Method of Driver’s Eyes Closure and Yawning Dete.pdf:application/pdf},
}

@inproceedings{viola_rapid_2001,
	address = {Kauai, HI, USA},
	title = {Rapid object detection using a boosted cascade of simple features},
	volume = {1},
	isbn = {978-0-7695-1272-3},
	url = {http://ieeexplore.ieee.org/document/990517/},
	doi = {10.1109/CVPR.2001.990517},
	abstract = {This paper describes a machine learning approachfor visual object detection which is capable ofprocessing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introductionof a new image representation called the “Integrallinage” which allows thefeatures used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely eflcient class@ers[5]. The third contribution is a method for combining increasingly more complex classij e r s in a “cascade”which allows background regionsofthe image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specijic focus-of-attention mechanism which unlike previous approachesprovides statistical guaruntees that discarded regions are unlikely to contain the object of interest, In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
	language = {en},
	urldate = {2022-03-14},
	booktitle = {Proceedings of the 2001 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}. {CVPR} 2001},
	publisher = {IEEE Comput. Soc},
	author = {Viola, P. and Jones, M.},
	year = {2001},
	pages = {I--511--I--518},
	file = {Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:/home/simeon/Zotero/storage/LK6AZPZL/Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:application/pdf;Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:/home/simeon/Zotero/storage/YTJXRFZQ/Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:application/pdf},
}

@incollection{maurice_cornea_1962,
	title = {The {Cornea} and {Sclera}},
	isbn = {978-1-4832-3090-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9781483230900500137},
	language = {en},
	urldate = {2022-03-14},
	booktitle = {Vegetative {Physiology} and {Biochemistry}},
	publisher = {Elsevier},
	author = {Maurice, D.M.},
	year = {1962},
	doi = {10.1016/B978-1-4832-3090-0.50013-7},
	pages = {289--368},
	file = {Maurice - 1962 - The Cornea and Sclera.pdf:/home/simeon/Zotero/storage/72YCIJDG/Maurice - 1962 - The Cornea and Sclera.pdf:application/pdf},
}

@inproceedings{azim_automatic_2009,
	address = {Kaohsiung, Taiwan},
	title = {Automatic {Fatigue} {Detection} of {Drivers} through {Pupil} {Detection} and {Yawning} {Analysis}},
	isbn = {978-1-4244-5543-0},
	url = {http://ieeexplore.ieee.org/document/5412643/},
	doi = {10.1109/ICICIC.2009.119},
	abstract = {This paper presents a non-intrusive fatigue detection system based on the video analysis of drivers. The system relies on multiple visual cues to characterize the level of alertness of the driver. The parameters used for detecting fatigue are: eye closure duration measured through eye state information and yawning analyzed through mouth state information. Initially, the face is located through ViolaJones face detection method to ensure the presence of driver in video frame. Then, a mouth window is extracted from the face region, in which lips are searched through spatial fuzzy c-means (s-FCM) clustering. Simultaneously, the pupils are also detected in the upper part of the face window on the basis of radii, inter-pupil distance and angle. The monitored information of eyes and mouth are further passed to SVM (Support Vector Machines) that classify the true state of the driver. The system has been tested using real data, with different sequences recorded in day and night driving conditions, and with users belonging to different race and gender.},
	language = {en},
	urldate = {2022-03-14},
	booktitle = {2009 {Fourth} {International} {Conference} on {Innovative} {Computing}, {Information} and {Control} ({ICICIC})},
	publisher = {IEEE},
	author = {Azim, Tayyaba and Jaffar, M. Arfan and Mirza, Anwar Majid},
	month = dec,
	year = {2009},
	pages = {441--445},
	file = {Azim et al. - 2009 - Automatic Fatigue Detection of Drivers through Pup.pdf:/home/simeon/Zotero/storage/U48RHX58/Azim et al. - 2009 - Automatic Fatigue Detection of Drivers through Pup.pdf:application/pdf},
}

@article{liu_3dcnn-based_2019,
	title = {{3DCNN}-{Based} {Real}-{Time} {Driver} {Fatigue} {Behavior} {Detection} in {Urban} {Rail} {Transit}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8854796/},
	doi = {10.1109/ACCESS.2019.2945136},
	abstract = {With the rapid development of urban rail transit, trafﬁc safety has become the focus of attention and people are paying increasing attention to the prevention of fatigue driving. ‘‘Gesture and oral instructions of urban rail trafﬁc drivers’’ is operational actions of drivers written in the Chinese metro operation speciﬁcation. It is a method to prevent drivers from fatigue driving and ensure safety. However, there is a lack of scientiﬁc detection methods. We combine the standard trafﬁc operational actions with fatigue action to construct a fatigue detection system that is suitable for the urban rail transit industry. The system includes a dynamic tracking model for the large-scale operation of rail transit drivers and a dualinput action discrimination model based on a three-dimensional convolutional neural network (3DCNN). The model sets the skipping frame and continuous frame as two inputs of the model, and extracts ﬁve channels of information from the two inputs. Dual-input multi-channel information enables the model to learn not only the spatial and temporal information of the entire action, but also the subtle changes of the action. First, we trained and validated the dual-input model based on a 3DCNN using the open dataset KTH, which contains several variations. Then, the model trained on KTH was migrated to our data using the transfer learning method, which saved training time and achieves an accuracy of 98.41\%. This transfer learning scheme can also be applied when new categories are encountered in practice. Finally, we discussed and envisaged the future optimization of the system.},
	language = {en},
	urldate = {2022-03-14},
	journal = {IEEE Access},
	author = {Liu, Yiqing and Zhang, Tao and Li, Zhen},
	year = {2019},
	pages = {144648--144662},
	file = {Liu et al. - 2019 - 3DCNN-Based Real-Time Driver Fatigue Behavior Dete.pdf:/home/simeon/Zotero/storage/MTZ4NRUR/Liu et al. - 2019 - 3DCNN-Based Real-Time Driver Fatigue Behavior Dete.pdf:application/pdf},
}

@article{li_face_2020,
	title = {Face {Detection} {Based} on {Receptive} {Field} {Enhanced} {Multi}-{Task} {Cascaded} {Convolutional} {Neural} {Networks}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9195457/},
	doi = {10.1109/ACCESS.2020.3023782},
	abstract = {With the continuous development of deep learning, face detection methods have made the greatest progress. For real-time detection, cascade CNN based on the lightweight model is still the dominant structure that predicts face in a coarse-to-ﬁne manner with strong generalization ability. Compared to other methods, it is not required for a ﬁxed size of the input. However, MTCNN still has poor performance in detecting tiny targets. To improve model generalization ability, we propose a Receptive Field Enhanced Multi-Task Cascaded CNN. This network takes advantage of the Inception-V2 block and receptive ﬁeld block to enhance the feature discriminability and robustness for small targets. The experimental results show that the performance of our network is improved by 1.08\% on the AFW, 2.84\% on the PASCAL FACE, 1.31\% on the FDDB, and 2.3\%, 2.1\%, and 6.6\% on the three sub-datasets of the WIDER FACE benchmark in comparison with MTCNN respectively. Furthermore, our structure uses 16\% fewer parameters.},
	language = {en},
	urldate = {2022-03-14},
	journal = {IEEE Access},
	author = {Li, Xiaochao and Yang, Zhenjie and Wu, Hongwei},
	year = {2020},
	pages = {174922--174930},
	file = {Li et al. - 2020 - Face Detection Based on Receptive Field Enhanced M.pdf:/home/simeon/Zotero/storage/JPR8RJ6P/Li et al. - 2020 - Face Detection Based on Receptive Field Enhanced M.pdf:application/pdf},
}

@article{noauthor_drowsiness_2019,
	title = {Drowsiness {Detection} {Based} on {Eye} {Closure} and {Yawning} {Detection}},
	volume = {8},
	issn = {2277-3878},
	url = {https://www.ijrte.org/wp-content/uploads/papers/v8i4/D9716118419.pdf},
	doi = {10.35940/ijrte.D9716.118419},
	abstract = {The number of major road accidents that occur per day is on a rise and most of them are attributed to being the driver’s fault. According to the survey done in 2015, drivers are held responsible for approximately 78\% of the accidents. To minimize the occurrence of these incidents a monitoring system that alerts the driver when he succumbs to sleep is proposed. This algorithm processes live video feed focused on the driver’s face and tracks his eye and mouth movements to detect eye closure and yawning rates. An alarm sounds if the driver is drowsy or already asleep. Haar-cascade classifiers run parallelly on the extracted facial features to detect eye closure and yawning.},
	language = {en},
	number = {4},
	urldate = {2022-03-14},
	journal = {International Journal of Recent Technology and Engineering},
	month = nov,
	year = {2019},
	pages = {8941--8944},
	file = {2019 - Drowsiness Detection Based on Eye Closure and Yawn.pdf:/home/simeon/Zotero/storage/7C53CI8B/2019 - Drowsiness Detection Based on Eye Closure and Yawn.pdf:application/pdf},
}

@article{ding_evolutionary_2013,
	title = {Evolutionary artificial neural networks: a review},
	volume = {39},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Evolutionary artificial neural networks},
	url = {http://link.springer.com/10.1007/s10462-011-9270-6},
	doi = {10.1007/s10462-011-9270-6},
	abstract = {This paper reviews the use of evolutionary algorithms (EAs) to optimize artiﬁcial neural networks (ANNs). First, we brieﬂy introduce the basic principles of artiﬁcial neural networks and evolutionary algorithms and, by analyzing the advantages and disadvantages of EAs and ANNs, explain the advantages of using EAs to optimize ANNs. We then provide a brief survey on the basic theories and algorithms for optimizing the weights, optimizing the network architecture and optimizing the learning rules, and discuss recent research from these three aspects. Finally, we speculate on new trends in the development of this area.},
	language = {en},
	number = {3},
	urldate = {2022-03-14},
	journal = {Artificial Intelligence Review},
	author = {Ding, Shifei and Li, Hui and Su, Chunyang and Yu, Junzhao and Jin, Fengxiang},
	month = mar,
	year = {2013},
	pages = {251--260},
	file = {Ding et al. - 2013 - Evolutionary artificial neural networks a review.pdf:/home/simeon/Zotero/storage/W2RK7FVJ/Ding et al. - 2013 - Evolutionary artificial neural networks a review.pdf:application/pdf},
}

@article{meireles_comprehensive_2003,
	title = {A comprehensive review for industrial applicability of artificial neural networks},
	volume = {50},
	issn = {0278-0046},
	url = {http://ieeexplore.ieee.org/document/1203011/},
	doi = {10.1109/TIE.2003.812470},
	abstract = {This paper presents a comprehensive review of the industrial applications of artificial neural networks (ANNs), in the last 12 years. Common questions that arise to practitioners and control engineers while deciding how to use NNs for specific industrial tasks are answered. Workable issues regarding implementation details, training and performance evaluation of such algorithms are also discussed, based on a judiciously chronological organization of topologies and training methods effectively used in the past years. The most popular ANN topologies and training methods are listed and briefly discussed, as a reference to the application engineer. Finally, ANN industrial applications are grouped and tabulated by their main functions and what they actually performed on the referenced papers. The authors prepared this paper bearing in mind that an organized and normalized review would be suitable to help industrial managing and operational personnel decide which kind of ANN topology and training method would be adequate for their specific problems.},
	language = {en},
	number = {3},
	urldate = {2022-03-14},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Meireles, M.R.G. and Almeida, P.E.M. and Simoes, M.G.},
	month = jun,
	year = {2003},
	pages = {585--601},
	file = {Meireles et al. - 2003 - A comprehensive review for industrial applicabilit.pdf:/home/simeon/Zotero/storage/HKQA3FY9/Meireles et al. - 2003 - A comprehensive review for industrial applicabilit.pdf:application/pdf},
}

@article{mamdani_experiment_1975,
	title = {An experiment in linguistic synthesis with a fuzzy logic controller},
	volume = {7},
	issn = {0020-7373},
	url = {https://www.sciencedirect.com/science/article/pii/S0020737375800022},
	doi = {https://doi.org/10.1016/S0020-7373(75)80002-2},
	abstract = {This paper describes an experiment on the “linguistic” synthesis of a controller for a model industrial plant (a steam engine), Fuzzy logic is used to convert heuristic control rues stated by a human operator into an automatic control strategy. The experiment was initiated to investigate the possibility of human interaction with a learning controller. However, the control strategy set up linguistically proved to be far better than expected in its own right, and the basic experiment of linguistic control synthesis in a non-learning controller is reported here.},
	number = {1},
	journal = {International Journal of Man-Machine Studies},
	author = {Mamdani, E. H. and Assilian, S.},
	year = {1975},
	pages = {1--13},
	file = {Mamdani_Assilian_1975_An experiment in linguistic synthesis with a fuzzy logic controller.pdf:/home/simeon/Zotero/storage/S48KWXLG/Mamdani_Assilian_1975_An experiment in linguistic synthesis with a fuzzy logic controller.pdf:application/pdf},
}
